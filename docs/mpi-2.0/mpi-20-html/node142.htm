<HTML>
<!-- This file was generated by tohtml from collective-2.tex -->
<!-- with the command
tohtml -default -endpage ../mpi2-forum-tail.htm -basedef ../mpi2defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex mpi2-report.tex 
-->
<TITLE>Intercommunicator Constructors</TITLE>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node142">7.2. Intercommunicator Constructors</a></H1>
<A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node140.htm#Node140"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node143.htm#Node143"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node140.htm#Node140"> Extended Collective Operations</a>
<b>Next: </b><A HREF="node143.htm#Node143"> Extended Collective Operations</a>
<b>Previous: </b><A HREF="node141.htm#Node141"> Introduction</a>
<P>
  
<P> 
  
<P> 
The current  MPI interface provides only two intercommunicator  
construction routines:  
<ul> 
 
<li> MPI_INTERCOMM_CREATE,   
  creates an intercommunicator from two intracommunicators,  
 
<li> MPI_COMM_DUP,  
  duplicates an existing intercommunicator (or intracommunicator).  
</ul> 
<BR> 
 The other communicator constructors,  MPI_COMM_CREATE  
  and    
 MPI_COMM_SPLIT, currently apply only to intracommunicators.  
These operations in fact have well-defined semantics for  
intercommunicators [<a href="node250.htm#-Bib20">20</a>].  
<P> 
In the following discussions, the two groups in an intercommunicator are  
called the <em> left</em> and <em> right</em> groups.  A process in an  
intercommunicator is a member of either the left or the right group.  From the  
point of view of that process, the  
group that the process is a member of is called the <em> local</em> group; the  
other group (relative to that process) is the <em> remote</em> group.  
The left and right group labels give us a way to describe the two groups in  
an intercommunicator that is not relative to any particular process (as the  
local and remote groups are).  
<P> 
In addition, the specification of collective operations (Section 4.1 of  
 MPI-1)  
requires that all collective routines are called with matching  
arguments.  For the intercommunicator extensions, this is weakened to matching  
for all members of the same local group.  
<P> 
  
<TABLE><TR><TD COLSPAN=2>MPI_COMM_CREATE(comm_in, group, comm_out)</TD></TR>  
<TR><TD> IN comm_in</TD><TD>original communicator (handle)</TD></TR>  
<TR><TD> IN group</TD><TD>group of processes to be in new communicator (handle)</TD></TR>  
<TR><TD> OUT comm_out</TD><TD>new communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> MPI::Intercomm MPI::Intercomm::Create(const Group&amp; group) const <BR></tt>  
  
 <tt> MPI::Intracomm MPI::Intracomm::Create(const Group&amp; group) const <BR></tt>  
  
<P> 
The C and Fortran language bindings are identical to those in  MPI-1, so are omitted  
here.   
<P> 
 If  comm_in is an  
intercommunicator, then the output communicator is also an intercommunicator  
where the local group consists only of those processes contained in  
 group (see Figure <a href="node142.htm#Figure9">9 
</a>).  The  group   
argument should only contain those processes in the local group of the input  
intercommunicator that are to be a part of  comm_out.  If either  
 group does not specify at least one process in the local group of  
the intercommunicator, or if the calling process is not included in the  
 group,  MPI_COMM_NULL is returned.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
In the case where either the left or right group is empty, a null communicator  
is returned instead of an intercommunicator with  MPI_GROUP_EMPTY  
because the side with the empty group must return  MPI_COMM_NULL.  
 (<em> End of rationale.</em>) <BR> 
  
  <CENTER><P><IMG WIDTH=481 HEIGHT=459 SRC="collective-create.gif"><P>
</CENTER>  
  <BR> 
<b>Figure 9: </b><A NAME="Figure9"></a><P> 
[ ]Intercommunicator create using  MPI_COMM_CREATE  
extended to intercommunicators.  The input groups are those in the grey  
circle.  
    
<BR><b> Example</b>  
The following example illustrates how the first node in the left  
side of an intercommunicator could be joined with all members on the  
right side of an intercommunicator to form a new  
intercommunicator.  
  
<BR> 
<pre><tt>        MPI_Comm  inter_comm, new_inter_comm; 
        MPI_Group local_group, group; 
        int       rank = 0; /* rank on left side to include in  
                               new inter-comm */ 
 
        /* Construct the original intercommunicator: "inter_comm" */ 
        ... 
 
        /* Construct the group of processes to be in new  
           intercommunicator */ 
        if (/* I'm on the left side of the intercommunicator */) { 
          MPI_Comm_group ( inter_comm, &amp;local_group ); 
          MPI_Group_incl ( local_group, 1, &amp;rank, &amp;group ); 
          MPI_Group_free ( &amp;local_group ); 
        } 
        else  
          MPI_Comm_group ( inter_comm, &amp;group ); 
 
        MPI_Comm_create ( inter_comm, group, &amp;new_inter_comm ); 
        MPI_Group_free( &amp;group ); 
</tt></pre> 
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_COMM_SPLIT(comm_in, color, key, comm_out)</TD></TR>  
<TR><TD> IN comm_in</TD><TD>original communicator (handle)</TD></TR>  
<TR><TD> IN color</TD><TD>control of subset assignment (integer)</TD></TR>  
<TR><TD> IN key</TD><TD>control of rank assignment (integer)</TD></TR>  
<TR><TD> OUT comm_out</TD><TD>new communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> MPI::Intercomm MPI::Intercomm::Split(int color, int key) const <BR></tt>  
  
 <tt> MPI::Intracomm MPI::Intracomm::Split(int color, int key) const <BR></tt>  
  
<P> 
The C and Fortran language bindings are identical to those in  MPI-1, so are omitted  
here.   
<P> 
 The result of  MPI_COMM_SPLIT on an intercommunicator is that those  
processes on the left with the same  color as those processes on  
the right combine to create a new intercommunicator.  The  key  
argument describes the relative rank of processes on each side of the  
intercommunicator (see Figure <a href="node142.htm#Figure10">10 
</a>).  For those colors  
that are specified only on one side of the intercommunicator,  
 MPI_COMM_NULL is returned.   MPI_COMM_NULL   
is also returned to those processes that specify  MPI_UNDEFINED  
as the color.  
<P> 
<P> 
  <CENTER><P><IMG WIDTH=293 HEIGHT=431 SRC="collective-split2.gif"><P>
</CENTER>  
  <BR> 
<b>Figure 10: </b><A NAME="Figure10"></a><P> 
[ ]Intercommunicator construction achieved by splitting an  
    existing intercommunicator with  MPI_COMM_SPLIT  
extended to intercommunicators.  
    
<BR><b> Example</b>(Parallel client-server model).  
The following client code illustrates how clients on the left side of an  
intercommunicator could be assigned to a single server from a pool of  
servers on the right side of an intercommunicator.  
  
<BR> 
<pre><tt>        /* Client code */ 
        MPI_Comm  multiple_server_comm; 
        MPI_Comm  single_server_comm; 
        int       color, rank, num_servers; 
         
        /* Create intercommunicator with clients and servers:  
           multiple_server_comm */ 
        ... 
         
        /* Find out the number of servers available */ 
        MPI_Comm_remote_size ( multiple_server_comm, &amp;num_servers ); 
         
        /* Determine my color */ 
        MPI_Comm_rank ( multiple_server_comm, &amp;rank ); 
        color = rank % num_servers; 
         
        /* Split the intercommunicator */ 
        MPI_Comm_split ( multiple_server_comm, color, rank,  
                         &amp;single_server_comm ); 
</tt></pre> 
 The following is the corresponding server code:  
<BR> 
<pre><tt>        /* Server code */ 
        MPI_Comm  multiple_client_comm; 
        MPI_Comm  single_server_comm; 
        int       rank; 
 
        /* Create intercommunicator with clients and servers:  
           multiple_client_comm */ 
        ... 
         
        /* Split the intercommunicator for a single server per group 
           of clients */ 
        MPI_Comm_rank ( multiple_client_comm, &amp;rank ); 
        MPI_Comm_split ( multiple_client_comm, rank, 0,  
                         &amp;single_server_comm );   
</tt></pre> 
  
<P> 

<P>
<HR>
<A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node140.htm#Node140"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node143.htm#Node143"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node140.htm#Node140"> Extended Collective Operations</a>
<b>Next: </b><A HREF="node143.htm#Node143"> Extended Collective Operations</a>
<b>Previous: </b><A HREF="node141.htm#Node141"> Introduction</a>
<P>
<HR>
Return to <A HREF="node306.htm">MPI-2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/docs/mpi-11-html/node182.html">MPI 1.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 18, 1997<BR>
HTML Generated on September 10, 2001
</FONT>
</BODY>
</HTML>
