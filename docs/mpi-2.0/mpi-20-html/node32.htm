<HTML>
<!-- This file was generated by tohtml from misc-1.2.tex -->
<!-- with the command
tohtml -default -endpage ../mpi2-forum-tail.htm -basedef ../mpi2defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex mpi2-report.tex 
-->
<TITLE>Clarification of  MPI_FINALIZE</TITLE>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node32">3.2.2. Clarification of  MPI_FINALIZE</a></H2>
<A HREF="node31.htm#Node31"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node30.htm#Node30"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node33.htm#Node33"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node30.htm#Node30"> MPI-1.0 and MPI-1.1 Clarifications</a>
<b>Next: </b><A HREF="node33.htm#Node33"> Clarification of  status after  MPI_WAIT and  MPI_TEST</a>
<b>Previous: </b><A HREF="node31.htm#Node31"> Clarification of  MPI_INITIALIZED</a>
<P>
  
<P> 
This routine cleans up all MPI state. Each process must call  
 MPI_FINALIZE before it exits.   
  
  
  
Unless there has been a call to  MPI_ABORT, each process must ensure that all pending non-blocking  
  
communications are (locally) complete before calling  MPI_FINALIZE.  
Further, at the instant at which the last process calls  
 MPI_FINALIZE, all pending sends must be matched by a receive, and  
all pending receives must be matched by a send.  
<P> 
For example, the following program is correct:  
<BR> 
<pre><tt>        Process 0                Process 1 
        ---------                --------- 
        MPI_Init();              MPI_Init(); 
        MPI_Send(dest=1);        MPI_Recv(src=0); 
        MPI_Finalize();          MPI_Finalize(); 
</tt></pre> 
Without the matching receive, the program is erroneous:  
<BR> 
<pre><tt>        Process 0                Process 1 
        -----------              ----------- 
        MPI_Init();              MPI_Init(); 
        MPI_Send (dest=1); 
        MPI_Finalize();          MPI_Finalize(); 
</tt></pre> 
  
  
<P> 
A successful return from a blocking communication operation or from  
 MPI_WAIT or  MPI_TEST tells the user that the buffer can  
be reused and means that the communication is completed by the user, but does  
not guarantee that the local process has no more work to do.  
  
A successful return from  MPI_REQUEST_FREE with a request handle  
generated by an  MPI_ISEND nullifies the handle but provides no  
assurance of operation completion.  The  MPI_ISEND is complete only when it is  
known by some means that a matching receive has completed.  
  
 MPI_FINALIZE guarantees that all local actions required by  
communications the user has completed will, in fact, occur before it returns.  
<P> 
  
 MPI_FINALIZE guarantees nothing about pending communications that  
have not been completed (completion is assured only by  MPI_WAIT,  
 MPI_TEST, or  MPI_REQUEST_FREE combined with some other  
verification of completion).   
<P> 
<BR><b> Example</b>  
   This program is correct:  
<BR> 
<pre><tt>rank 0                          rank 1 
===================================================== 
...                             ... 
MPI_Isend();                    MPI_Recv(); 
MPI_Request_free();             MPI_Barrier(); 
MPI_Barrier();                  MPI_Finalize(); 
MPI_Finalize();                 exit(); 
exit();                         
</tt></pre> 
  
<P> 
<BR><b> Example</b>  
   This program is erroneous and its behavior is undefined:  
<BR> 
<pre><tt>rank 0                          rank 1 
===================================================== 
...                             ... 
MPI_Isend();                    MPI_Recv(); 
MPI_Request_free();             MPI_Finalize(); 
MPI_Finalize();                 exit(); 
exit();                         
</tt></pre> 
  
<P> 
If no  MPI_BUFFER_DETACH occurs between an  MPI_BSEND (or  
other buffered send) and  
 MPI_FINALIZE, the  MPI_FINALIZE implicitly supplies  
the  MPI_BUFFER_DETACH.  
<P> 
<BR><b> Example</b>  
   This program is correct, and after the  MPI_Finalize, it is  
    as if the buffer had been detached.  
<BR> 
<pre><tt>rank 0                          rank 1 
===================================================== 
...                             ... 
buffer = malloc(1000000);       MPI_Recv(); 
MPI_Buffer_attach();            MPI_Finalize(); 
MPI_Bsend();                    exit();               
MPI_Finalize(); 
free(buffer); 
exit();                         
</tt></pre> 
  
<P> 
<BR><b> Example</b>  
   In this example,  MPI_Iprobe() must return a  FALSE  
    flag.   MPI_Test_cancelled() must return a  TRUE flag,  
    independent of the relative order of execution of  MPI_Cancel()  
    in process 0 and  MPI_Finalize() in process 1.  
    <P> 
The  MPI_Iprobe() call is there to make sure the implementation  
    knows that the ``tag1'' message exists at the destination, without being  
    able to claim that the user knows about it.  
<P> 
<BR> 
<pre><tt>rank 0                          rank 1 
======================================================== 
MPI_Init();                     MPI_Init(); 
MPI_Isend(tag1); 
MPI_Barrier();                  MPI_Barrier(); 
                                MPI_Iprobe(tag2); 
MPI_Barrier();                  MPI_Barrier(); 
                                MPI_Finalize(); 
                                exit(); 
MPI_Cancel(); 
MPI_Wait(); 
MPI_Test_cancelled(); 
MPI_Finalize(); 
exit(); 
 
</tt></pre> 
  
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
An implementation may need to delay the return from  MPI_FINALIZE  
   until all potential future message cancellations have been  
   processed.  One possible solution is to place a barrier inside  
    MPI_FINALIZE  
 (<em> End of advice to implementors.</em>) <BR> 
  
<P> 
  
<P> 
Once  MPI_FINALIZE returns, no  MPI routine (not even  MPI_INIT) may  
be called, except for  MPI_GET_VERSION,  MPI_INITIALIZED,  
and the  MPI-2 function  MPI_FINALIZED.  Each process must complete  
any pending communication it initiated before it calls  
 MPI_FINALIZE.  If the call returns, each process may continue local  
computations, or exit, without participating in further  MPI communication  
with other processes.   MPI_FINALIZE is collective on  
 MPI_COMM_WORLD.  
<P> 
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
Even though a process has completed all the communication it initiated, such  
  communication may not yet be completed from the viewpoint of the underlying  
   MPI system.  E.g., a blocking send may have completed, even though the data  
  is still buffered at the sender.  The  MPI implementation must ensure that a  
  process has completed any involvement in  MPI communication before  
   MPI_FINALIZE returns.  Thus, if a process exits after the call to  
   MPI_FINALIZE, this will not cause an ongoing communication to  
  fail.  
 (<em> End of advice to implementors.</em>) <BR> 
  
<P> 
  
<P> 
  
Although it is not required that all processes return from  
 MPI_FINALIZE, it is required that at least process 0 in  
 MPI_COMM_WORLD return, so  
that users can know that the MPI portion of the computation is over.  In  
addition, in a POSIX environment, they may desire to supply an exit code for  
each process that returns from  MPI_FINALIZE.  
<P> 
<BR><b> Example</b>  
   The following illustrates the use of requiring that at least one  
    process return and that it be known that process 0 is one of the processes  
    that return.  One wants code like the following to work no matter how many  
    processes return.  
<P> 
<BR> 
<pre><tt>    ... 
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank); 
    ... 
    MPI_Finalize(); 
    if (myrank == 0) { 
        resultfile = fopen("outfile","w"); 
        dump_results(resultfile); 
        fclose(resultfile); 
    } 
    exit(0); 
</tt></pre> 
  
<P> 
  
<P> 
  
<P> 
  
<P> 

<P>
<HR>
<A HREF="node31.htm#Node31"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node30.htm#Node30"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node33.htm#Node33"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node30.htm#Node30"> MPI-1.0 and MPI-1.1 Clarifications</a>
<b>Next: </b><A HREF="node33.htm#Node33"> Clarification of  status after  MPI_WAIT and  MPI_TEST</a>
<b>Previous: </b><A HREF="node31.htm#Node31"> Clarification of  MPI_INITIALIZED</a>
<P>
<HR>
Return to <A HREF="node306.htm">MPI-2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/docs/mpi-11-html/node182.html">MPI 1.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 18, 1997<BR>
HTML Generated on September 10, 2001
</FONT>
</BODY>
</HTML>
