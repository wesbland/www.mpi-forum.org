<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml erif"> MPI-2.0</font>
-->
<TITLE>Introduction</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node229">214. Introduction</a></H1>
<A HREF="node228.htm#Node228"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi22-report.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node230.htm#Node230"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi22-report.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node230.htm#Node230"> Initialization</a>
<b>Previous: </b><A HREF="node228.htm#Node228"> One-Sided Communications</a>
<P>
Remote Memory Access (<font face="sans-serif"> RMA</font>) extends the communication mechanisms of <font face="sans-serif"> MPI</font> by  
allowing one process to specify all communication parameters, both for  
the sending side and for the receiving side.  
This mode of communication facilitates the coding of some applications  
with dynamically changing data access patterns  
where the data distribution is fixed or slowly changing.    
  
In such a case,  
each process can compute what data it needs to access or update at  
other  processes.  However, processes may not know which data in their  
own memory need to be accessed or updated by remote processes, and may  
not even know the identity of these processes.  
Thus, the transfer parameters are all available only on one side.  
Regular send/receive communication requires matching operations by  
sender and receiver.  
  
In order to issue the matching operations, an application needs to  
distribute the transfer parameters.   
This may  
require all processes to participate in a time consuming global  
computation,  
or to periodically poll for potential communication requests to  
receive and act upon.  
The use of <font face="sans-serif"> RMA</font> communication mechanisms avoids the need for  
global computations or explicit polling.  
A generic example of this nature is the execution of an assignment of  
the form  
<tt> A = B(map)</tt>, where <tt> map</tt> is a permutation vector, and <tt> A,  
B</tt> and <tt> map</tt> are distributed in the same manner.  
<P> 
Message-passing communication achieves two effects: <em>  
communication</em> of data from sender to receiver; and <em>  
synchronization</em> of sender  
with receiver.  
The <font face="sans-serif"> RMA</font> design separates these two functions.   Three communication  
calls are provided: <font face="sans-serif"> MPI_PUT</font> (remote write),  
<font face="sans-serif"> MPI_GET</font> (remote read) and <font face="sans-serif"> MPI_ACCUMULATE</font> (remote  
update).  A larger number of synchronization calls are provided that  
support different synchronization styles.  The design is similar to  
that of weakly coherent memory systems: correct ordering of memory  
accesses has to be imposed by the user, using synchronization calls;  
the implementation can delay communication operations until the  
synchronization calls occur,  
for efficiency.  
<P> 
The design of the <font face="sans-serif"> RMA</font> functions allows implementors to take advantage, in  
many cases, of fast communication mechanisms provided by various  
platforms, such as coherent or noncoherent shared memory, DMA  
engines, hardware-supported put/get operations, communication  
coprocessors, etc.  The most frequently used <font face="sans-serif"> RMA</font> communication mechanisms can be layered on top of message-passing.  However, support for  
asynchronous communication agents (handlers, threads, etc.) is needed,  
for certain <font face="sans-serif"> RMA</font> functions, in a distributed memory environment.  
<P> 
We shall denote by <b> origin</b> the process that performs the call,  
and by <b> target</b> the process in which the memory is accessed.  
Thus, in a put  
operation, source=origin and destination=target; in a get operation, source=target and destination=origin.  
<P> 

<P>
<HR>
<A HREF="node228.htm#Node228"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi22-report.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node230.htm#Node230"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi22-report.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node230.htm#Node230"> Initialization</a>
<b>Previous: </b><A HREF="node228.htm#Node228"> One-Sided Communications</a>
<P>
<HR>
Return to <A HREF="node434.htm">MPI-2.2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-2.2 of September 4, 2009<BR>
HTML Generated on September 10, 2009
</FONT>
</BODY>
</HTML>
