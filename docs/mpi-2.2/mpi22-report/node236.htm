<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml erif"> MPI-2.0</font>
-->
<TITLE>Examples</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node236">221. Examples</a></H2>
<A HREF="node235.htm#Node235"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node233.htm#Node233"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node237.htm#Node237"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node233.htm#Node233"> Communication Calls</a>
<b>Next: </b><A HREF="node237.htm#Node237"> Accumulate Functions</a>
<b>Previous: </b><A HREF="node235.htm#Node235"> Get</a>
<P>
  
<P> 
<BR><b> Example</b>  
  
We show how to implement the generic indirect assignment  
A = B(map), where <tt> A, B</tt> and <tt> map</tt> have the same  
distribution, and <tt> map</tt> is a permutation.  To simplify, we assume  
a block distribution with equal size   
blocks.  
<P> 
<BR> 
<pre><tt>SUBROUTINE MAPVALS(A, B, map, m, comm, p) 
USE MPI 
INTEGER m, map(m), comm, p 
REAL A(m), B(m) 
 
INTEGER otype(p), oindex(m),   &amp; ! used to construct origin datatypes  
     ttype(p), tindex(m),      &amp; ! used to construct target datatypes 
     count(p), total(p),       &amp; 
     win, ierr 
INTEGER (KIND=MPI_ADDRESS_KIND) lowerbound, sizeofreal 
 
! This part does the work that depends on the locations of B. 
! Can be reused while this does not change 
 
CALL MPI_TYPE_GET_EXTENT(MPI_REAL, lowerbound, sizeofreal, ierr) 
CALL MPI_WIN_CREATE(B, m*sizeofreal, sizeofreal, MPI_INFO_NULL,   &amp; 
                     comm, win, ierr) 
 
! This part does the work that depends on the value of map and 
! the locations of the arrays. 
! Can be reused while these do not change 
 
! Compute number of entries to be received from each process 
 
DO i=1,p 
  count(i) = 0 
END DO 
DO i=1,m 
  j = map(i)/m+1 
  count(j) = count(j)+1 
END DO 
 
total(1) = 0 
DO i=2,p 
  total(i) = total(i-1) + count(i-1) 
END DO 
 
DO i=1,p 
  count(i) = 0 
END DO 
 
! compute origin and target indices of entries. 
! entry i at current process is received from location 
! k at process (j-1), where map(i) = (j-1)*m + (k-1), 
! j = 1..p and k = 1..m 
 
DO i=1,m 
  j = map(i)/m+1 
  k = MOD(map(i),m)+1 
  count(j) = count(j)+1 
  oindex(total(j) + count(j)) = i 
  tindex(total(j) + count(j)) = k 
END DO 
 
! create origin and target datatypes for each get operation 
DO i=1,p 
  CALL MPI_TYPE_CREATE_INDEXED_BLOCK(count(i), 1, oindex(total(i)+1),   &amp; 
                                     MPI_REAL, otype(i), ierr) 
  CALL MPI_TYPE_COMMIT(otype(i), ierr) 
  CALL MPI_TYPE_CREATE_INDEXED_BLOCK(count(i), 1, tindex(total(i)+1),   &amp; 
                                     MPI_REAL, ttype(i), ierr) 
  CALL MPI_TYPE_COMMIT(ttype(i), ierr) 
END DO 
 
! this part does the assignment itself 
CALL MPI_WIN_FENCE(0, win, ierr) 
DO i=1,p 
  CALL MPI_GET(A, 1, otype(i), i-1, 0, 1, ttype(i), win, ierr) 
END DO 
CALL MPI_WIN_FENCE(0, win, ierr) 
 
CALL MPI_WIN_FREE(win, ierr) 
DO i=1,p 
  CALL MPI_TYPE_FREE(otype(i), ierr) 
  CALL MPI_TYPE_FREE(ttype(i), ierr) 
END DO 
RETURN 
END 
</tt></pre> 
  
<P> 
<BR><b> Example</b>  
  
  
A simpler version can be written that does not require that a  
datatype be built for the target buffer.  But, one then needs a  
separate get call for each entry,  
as illustrated below.  This code is much simpler, but usually much less   
efficient, for large arrays.  
<P> 
  
2.2  
<P> 
<font color="red">  
<BR> 
<pre><tt>SUBROUTINE MAPVALS(A, B, map, m, comm, p) 
USE MPI 
INTEGER m, map(m), comm, p 
REAL A(m), B(m) 
INTEGER win, ierr 
INTEGER (KIND=MPI_ADDRESS_KIND) lowerbound, sizeofreal 
 
CALL MPI_TYPE_GET_EXTENT(MPI_REAL, lowerbound, sizeofreal, ierr) 
CALL MPI_WIN_CREATE(B, m*sizeofreal, sizeofreal, MPI_INFO_NULL,  &amp; 
                    comm, win, ierr) 
 
CALL MPI_WIN_FENCE(0, win, ierr) 
DO i=1,m 
  j = map(i)/m 
  k = MOD(map(i),m) 
  CALL MPI_GET(A(i), 1, MPI_REAL, j, k, 1, MPI_REAL, win, ierr) 
END DO 
CALL MPI_WIN_FENCE(0, win, ierr) 
CALL MPI_WIN_FREE(win, ierr) 
RETURN 
END 
</tt></pre> 
<font color="black">  
  
<P> 

<P>
<HR>
<A HREF="node235.htm#Node235"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node233.htm#Node233"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node237.htm#Node237"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node233.htm#Node233"> Communication Calls</a>
<b>Next: </b><A HREF="node237.htm#Node237"> Accumulate Functions</a>
<b>Previous: </b><A HREF="node235.htm#Node235"> Get</a>
<P>
<HR>
Return to <A HREF="node434.htm">MPI-2.2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-2.2 of September 4, 2009<BR>
HTML Generated on September 10, 2009
</FONT>
</BODY>
</HTML>
