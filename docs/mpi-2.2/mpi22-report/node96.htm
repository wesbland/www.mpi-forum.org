<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml erif"> MPI-2.0</font>
-->
<TITLE>Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font></TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node96">95. Examples using  MPI_GATHER,  MPI_GATHERV</a></H2>
<A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node97.htm#Node97"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node95.htm#Node95"> Gather</a>
<b>Next: </b><A HREF="node97.htm#Node97"> Scatter</a>
<b>Previous: </b><A HREF="node95.htm#Node95"> Gather</a>
<P>
The examples in this section use intracommunicators.  
  
<BR><b> Example</b>   
  
  
Gather 100 <tt> int</tt>s from every process in group to root. See figure  
<a href="node96.htm#Figure4">4 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, *rbuf; 
    ... 
    MPI_Comm_size( comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    MPI_Gather( sendarray, 100, MPI_INT, rbuf, 100, MPI_INT, root, comm); 
</tt></pre> 
   
<P> 
<BR><b> Example</b>   
  
  
Previous example modified -- only the root allocates memory for the  
receive buffer.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, myrank, *rbuf; 
    ... 
    MPI_Comm_rank( comm, &amp;myrank); 
    if ( myrank == root) { 
       MPI_Comm_size( comm, &amp;gsize); 
       rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    } 
    MPI_Gather( sendarray, 100, MPI_INT, rbuf, 100, MPI_INT, root, comm); 
</tt></pre> 
   
<P> 
<P> 
  <CENTER>  
</CENTER>  <P><IMG WIDTH=497 HEIGHT=203 SRC="mycoll-fig2.gif"><P>
  
    
  <BR> 
<b>Figure 4: </b><A NAME="Figure4">The root process gathers 100 <tt> int</tt>s from each process
  in the group.
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
Do the same as the previous example, but use a derived datatype.  Note that  
the type cannot be the entire set of <tt> gsize*100 int</tt>s since type matching  
is defined pairwise between the root and each process in the gather.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, *rbuf; 
    MPI_Datatype rtype; 
    ... 
    MPI_Comm_size( comm, &amp;gsize); 
    MPI_Type_contiguous( 100, MPI_INT, &amp;rtype ); 
    MPI_Type_commit( &amp;rtype ); 
    rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    MPI_Gather( sendarray, 100, MPI_INT, rbuf, 1, rtype, root, comm); 
</tt></pre> 
   
<P> 
<BR><b> Example</b>   
  
  
Now have each process send 100 <tt> int</tt>s to root, but place each set (of 100)  
<tt> stride int</tt>s apart at receiving end. Use <font face="sans-serif"> MPI_GATHERV</font>  
and the <font face="sans-serif"> displs</font>  
argument to achieve this effect. Assume <IMG WIDTH=58 HEIGHT=9 SRC="img57.gif">
.  
See Figure <a href="node96.htm#Figure5">5 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, *rbuf, stride; 
    int *displs,i,*rcounts; 
 
    ... 
 
    MPI_Comm_size( comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100; 
    } 
    MPI_Gatherv( sendarray, 100, MPI_INT, rbuf, rcounts, displs, MPI_INT, 
                                                               root, comm); 
</tt></pre> 
Note that the program is erroneous if <I>stride &lt; 100</I>.  
   
<P> 
<P> 
  <CENTER>  
</CENTER>  <P><IMG WIDTH=497 HEIGHT=203 SRC="mycoll-fig3.gif"><P>
  
    
  <BR> 
<b>Figure 5: </b><A NAME="Figure5">The root process gathers 100 <tt> int</tt>s from each process
  in the group, each set is placed <tt> stride int</tt>s apart.
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
Same as Example <a href="node96.htm#Node96">Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font> 
</a> on the receiving side, but send the  
100 <tt> int</tt>s from the 0th column of a  
100<I>&#215;</I>150 <tt> int</tt> array, in C.  See Figure <a href="node96.htm#Figure6">6 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150]; 
    int root, *rbuf, stride; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts; 
 
    ... 
 
    MPI_Comm_size( comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100; 
    } 
    /* Create datatype for 1 column of array 
     */ 
    MPI_Type_vector( 100, 1, 150, MPI_INT, &amp;stype); 
    MPI_Type_commit( &amp;stype ); 
    MPI_Gatherv( sendarray, 1, stype, rbuf, rcounts, displs, MPI_INT, 
                                                             root, comm); 
</tt></pre> 
   
<P> 
<P> 
  <CENTER>  
</CENTER>  <P><IMG WIDTH=611 HEIGHT=257 SRC="mycoll-fig4.gif"><P>
  
    
  <BR> 
<b>Figure 6: </b><A NAME="Figure6">The root process gathers column <tt> 0</tt> of a 100$ x $150
  C array, and each set is placed <tt> stride int</tt>s apart.
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
Process <tt> i</tt> sends <tt> (100-i) int</tt>s from the <tt> i</tt>-th column of a  
100 <I>&#215;</I> 150 <tt> int</tt> array, in C.  It is received into a buffer with stride,  
as in the previous two examples. See Figure <a href="node96.htm#Figure7">7 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150],*sptr; 
    int root, *rbuf, stride, myrank; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts; 
 
    ... 
 
    MPI_Comm_size( comm, &amp;gsize); 
    MPI_Comm_rank( comm, &amp;myrank ); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100-i;     /* note change from previous example */ 
    } 
    /* Create datatype for the column we are sending 
     */ 
    MPI_Type_vector( 100-myrank, 1, 150, MPI_INT, &amp;stype); 
    MPI_Type_commit( &amp;stype ); 
    /* sptr is the address of start of "myrank" column 
     */ 
    sptr = &amp;sendarray[0][myrank]; 
    MPI_Gatherv( sptr, 1, stype, rbuf, rcounts, displs, MPI_INT, 
                                                        root, comm); 
</tt></pre> 
Note that a different amount of data is received from each process.  
   
<P> 
<P> 
  <CENTER>  
</CENTER>  <P><IMG WIDTH=611 HEIGHT=257 SRC="mycoll-fig5.gif"><P>
  
    
  <BR> 
<b>Figure 7: </b><A NAME="Figure7">The root process gathers <tt> 100-i int</tt>s from
  column <tt> i</tt> of a 100$ x $150
  C array, and each set is placed <tt> stride int</tt>s apart.
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
Same as Example <a href="node96.htm#Node96">Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font> 
</a>, but done in a different way at the sending end.  
We create a datatype that causes the correct striding at the  
sending end so   
that   
we read a column of a C array.  
A similar thing was done in Example <a href="node83.htm#Node83">Examples 
</a>,  
Section <a href="node83.htm#Node83">Examples 
</a>.  
<P> 
<P><IMG WIDTH=477 HEIGHT=375 SRC="img58.gif"><P>
   
<BR><b> Example</b>   
  
  
Same as Example <a href="node96.htm#Node96">Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font> 
</a> at sending side, but  
at receiving side we make the  
stride between received blocks vary from block to block.  
See Figure <a href="node96.htm#Figure8">8 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150],*sptr; 
    int root, *rbuf, *stride, myrank, bufsize; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts,offset; 
 
    ... 
 
    MPI_Comm_size( comm, &amp;gsize); 
    MPI_Comm_rank( comm, &amp;myrank ); 
 
    stride = (int *)malloc(gsize*sizeof(int)); 
    ... 
    /* stride[i] for i = 0 to gsize-1 is set somehow 
     */ 
 
    /* set up displs and rcounts vectors first 
     */ 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    offset = 0; 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = offset; 
        offset += stride[i]; 
        rcounts[i] = 100-i; 
    } 
    /* the required buffer size for rbuf is now easily obtained 
     */ 
    bufsize = displs[gsize-1]+rcounts[gsize-1]; 
    rbuf = (int *)malloc(bufsize*sizeof(int)); 
    /* Create datatype for the column we are sending 
     */ 
    MPI_Type_vector( 100-myrank, 1, 150, MPI_INT, &amp;stype); 
    MPI_Type_commit( &amp;stype ); 
    sptr = &amp;sendarray[0][myrank]; 
    MPI_Gatherv( sptr, 1, stype, rbuf, rcounts, displs, MPI_INT, 
                                                        root, comm); 
</tt></pre> 
   
<P> 
<P> 
  <CENTER>  
</CENTER>  <P><IMG WIDTH=611 HEIGHT=257 SRC="mycoll-fig6.gif"><P>
  
    
  <BR> 
<b>Figure 8: </b><A NAME="Figure8">The root process gathers <tt> 100-i int</tt>s from
  column <tt> i</tt> of a 100$ x $150
  C array, and each set is placed <tt> stride[i] int</tt>s apart (a varying
stride).
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
Process <tt> i</tt> sends <tt> num int</tt>s from the <tt> i</tt>-th column of a  
100 <I>&#215;</I> 150 <tt> int</tt> array, in C.  The complicating factor is that  
the various values of <tt> num</tt> are not known to <tt> root</tt>, so a  
separate gather must first be run to find these out.  The data is  
placed contiguously at the receiving end.  
<P> 
<P><IMG WIDTH=477 HEIGHT=511 SRC="img59.gif"><P>
   

<P>
<HR>
<A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node97.htm#Node97"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node95.htm#Node95"> Gather</a>
<b>Next: </b><A HREF="node97.htm#Node97"> Scatter</a>
<b>Previous: </b><A HREF="node95.htm#Node95"> Gather</a>
<P>
<HR>
Return to <A HREF="node434.htm">MPI-2.2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-2.2 of September 4, 2009<BR>
HTML Generated on September 10, 2009
</FONT>
</BODY>
</HTML>
