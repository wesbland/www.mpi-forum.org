<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-context/context.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Example #4</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node135">133. Example #4</a></H2>
<A HREF="node134.htm#Node134"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node131.htm#Node131"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node136.htm#Node136"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node131.htm#Node131"> Motivating Examples</a>
<b>Next: </b><A HREF="node136.htm#Node136"> Library Example #1</a>
<b>Previous: </b><A HREF="node134.htm#Node134"> (Approximate) Current Practice #3</a>
<P>
  
The following example is meant to illustrate ``safety'' between  
point-to-point and collective communication.   MPI guarantees that a single  
communicator can do safe point-to-point and collective communication.  
<BR> 
<pre><tt>   #define TAG_ARBITRARY 12345 
   #define SOME_COUNT       50 
 
   main(int argc, char **argv) 
   { 
     int me; 
     MPI_Request request[2]; 
     MPI_Status status[2]; 
     MPI_Group MPI_GROUP_WORLD, subgroup; 
     int ranks[] = {2, 4, 6, 8}; 
     MPI_Comm the_comm; 
     ... 
     MPI_Init(&amp;argc, &amp;argv); 
     MPI_Comm_group(MPI_COMM_WORLD, &amp;MPI_GROUP_WORLD); 
 
     MPI_Group_incl(MPI_GROUP_WORLD, 4, ranks, &amp;subgroup); /* local */ 
     MPI_Group_rank(subgroup, &amp;me);     /* local */ 
 
     MPI_Comm_create(MPI_COMM_WORLD, subgroup, &amp;the_comm); 
 
     if(me != MPI_UNDEFINED) 
     { 
         MPI_Irecv(buff1, count, MPI_DOUBLE, MPI_ANY_SOURCE, TAG_ARBITRARY, 
                           the_comm, request); 
         MPI_Isend(buff2, count, MPI_DOUBLE, (me+1)%4, TAG_ARBITRARY, 
                           the_comm, request+1); 
         for(i = 0; i &lt; SOME_COUNT, i++) 
           MPI_Reduce(..., the_comm); 
         MPI_Waitall(2, request, status); 
     
         MPI_Comm_free(&amp;the_comm); 
     } 
  
     MPI_Group_free(&amp;MPI_GROUP_WORLD); 
     MPI_Group_free(&amp;subgroup); 
     MPI_Finalize(); 
   } 
</tt></pre> 

<P>
<HR>
<A HREF="node134.htm#Node134"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node131.htm#Node131"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node136.htm#Node136"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node131.htm#Node131"> Motivating Examples</a>
<b>Next: </b><A HREF="node136.htm#Node136"> Library Example #1</a>
<b>Previous: </b><A HREF="node134.htm#Node134"> (Approximate) Current Practice #3</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
