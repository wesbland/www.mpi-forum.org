<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-ei/ei-2.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Clarifications</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node254">238. Clarifications</a></H2>
<A HREF="node253.htm#Node253"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node252.htm#Node252"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node255.htm#Node255"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node252.htm#Node252"> MPI and Threads</a>
<b>Next: </b><A HREF="node255.htm#Node255"> Initialization</a>
<b>Previous: </b><A HREF="node253.htm#Node253"> General</a>
<P>
<P> 
Initialization and Completion The call to  MPI_FINALIZE should occur on the same thread  
that   
initialized  MPI. We call this thread the <b> main  
thread</b>.  The call should occur only after all the process threads  
have completed their  MPI calls, and have no pending communications  
or I/O operations.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
This constraint simplifies implementation.  
 (<em> End of rationale.</em>) <BR> 
<P> 
Multiple threads completing the same request. A program where two threads block, waiting on the same  
request, is erroneous.  Similarly, the same request cannot appear in  
the array of requests of two concurrent   
 MPI_{WAIT<I>|</I>TEST}{ANY<I>|</I>SOME<I>|</I>ALL}  
calls.  
In  MPI, a request can only be completed once.  Any combination of  
wait or test which violates this rule is erroneous.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
This is consistent with the view that a multithreaded execution  
corresponds to an interleaving of the  MPI calls.  
In a single threaded implementation, once a wait is  
posted on a request  
the request handle will be nullified before it is possible to  
post a second wait on the same handle.  
With threads, an  MPI_WAIT{ANY<I>|</I>SOME<I>|</I>ALL}  
may be blocked without having nullified its request(s) so it  
becomes the user's responsibility to avoid using the same request  
in an  MPI_WAIT on another thread.  
This constraint also simplifies  
implementation, as only one thread will be blocked on any  
communication or I/O event.  
 (<em> End of rationale.</em>) <BR> 
<P> 
Probe A receive call that uses source and tag values returned by a preceding  
call to  MPI_PROBE or  MPI_IPROBE will receive the  
message matched by the probe call only if there was no other matching  
receive  
after the probe and before that receive.  In a multithreaded  
environment, it is up to the user to enforce this condition using  
suitable mutual exclusion logic.  
This can be enforced by  
making sure that each communicator is used by only one thread on each  
process.  
<P> 
<P> 
Collective calls Matching of collective calls on a  
  
communicator, window, or file handle is done according to the order in which the calls are issued  
  
at each process.  If concurrent threads issue such calls on the same  
communicator, window or file handle, it is up to  
the user to make sure the calls are correctly ordered, using  
interthread synchronization.  
 
<BR> 
<em> Advice to users.</em>  
<P> 
With three concurrent threads in each  MPI process of a communicator  comm,  
  it is allowed that thread A in each  MPI process calls a collective   
  operation on  comm, thread B calls a file operation on an existing  
  filehandle that was formerly opened on  comm, and thread C invokes one-sided  
  operations on an existing window handle that was also formerly created   
  on  comm.   
 (<em> End of advice to users.</em>) <BR> 
 
<BR> 
<em> Rationale.</em>  
<P> 
As already specified in  MPI_FILE_OPEN and   
   MPI_WIN_CREATE, a file handle and  
  a window handle inherit only the group of processes of the underlying  
  communicator, but not the communicator itself. Accesses to communicators,  
  window handles and file handles cannot affect one another.  
 (<em> End of rationale.</em>) <BR> 
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
Advice to implementors.  
  If the implementation of file or window operations internally   
  uses  MPI communication then a duplicated communicator may be cached  
  on the file or window object.    
 (<em> End of advice to implementors.</em>) <BR> 
  
<P> 
Exception handlers An exception handler does not necessarily execute in the context of the  
thread that made  
the exception-raising  MPI call;  the exception handler may be  
executed by a thread that is distinct from the thread that will  
return the error code.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
The  MPI implementation may be multithreaded, so that part of the  
communication protocol may execute on a thread that is distinct from  
the thread that made the  MPI call.  
The design allows the exception handler to be executed on the  
thread  
where the exception occurred.  
 (<em> End of rationale.</em>) <BR> 
<P> 
Interaction with signals and cancellations The outcome is undefined if a thread that executes an  MPI call is  
cancelled (by another thread), or if a thread catches a signal while  
executing an  MPI call.  
However, a thread of an  MPI process may terminate, and may catch  
signals or be cancelled by another thread when not executing  MPI calls.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
Few C library functions are signal safe, and many have cancellation  
points --- points where the thread executing them may be cancelled.  The  
above restriction simplifies implementation (no need for the  MPI  
library to be ``async-cancel-safe'' or ``async-signal-safe.''    
 (<em> End of rationale.</em>) <BR> 
 
<BR> 
<em> Advice to users.</em>  
<P> 
Users can catch signals in separate, non- MPI threads (e.g., by  
masking signals on  MPI calling threads, and unmasking them in one or  
more non- MPI threads).    
  
A good programming practice is to have a distinct thread blocked  
in a call to <tt> sigwait</tt> for each user expected signal that may occur.  
Users must not catch signals used by the  MPI implementation; as   
each  MPI implementation is required to document the signals used   
internally, users can avoid these signals.  
  
 (<em> End of advice to users.</em>) <BR> 
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
The  MPI library should not invoke  library calls that are  
not thread safe, if multiple threads execute.  
 (<em> End of advice to implementors.</em>) <BR> 
  

<P>
<HR>
<A HREF="node253.htm#Node253"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node252.htm#Node252"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node255.htm#Node255"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node252.htm#Node252"> MPI and Threads</a>
<b>Next: </b><A HREF="node255.htm#Node255"> Initialization</a>
<b>Previous: </b><A HREF="node253.htm#Node253"> General</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
