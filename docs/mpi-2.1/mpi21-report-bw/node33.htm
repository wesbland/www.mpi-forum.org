<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-terms/terms-2.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Error Handling</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node33">33. Error Handling</a></H1>
<A HREF="node32.htm#Node32"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node34.htm#Node34"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node34.htm#Node34"> Implementation Issues</a>
<b>Previous: </b><A HREF="node32.htm#Node32"> Processes</a>
<P>
 MPI provides the user with reliable message transmission.  
A message sent is always received  
correctly, and the user does not need to check for transmission errors,  
time-outs, or other error conditions.  In  
other words,  MPI does not provide mechanisms for  
dealing with failures in the communication system.  
If the  MPI implementation is built on an unreliable underlying  
mechanism, then it is the job of the implementor of the  MPI subsystem  
to insulate the user from this unreliability, or to reflect unrecoverable  
errors as failures.  
Whenever possible, such failures will be reflected as errors in the relevant  
communication call.  
Similarly,  MPI itself provides no mechanisms for  
handling processor failures.  
<P> 
Of course,  MPI programs may still be erroneous.  A <b> program error</b> can  
occur when an  MPI call is made with an incorrect argument (non-existing  
destination in a send operation, buffer too small in a receive  
operation, etc.).  
This type of error would occur in any implementation.  
In addition, a <b> resource error</b> may occur when a program exceeds the amount  
of available system resources (number of pending messages, system buffers,  
etc.).   The occurrence of this type of error depends on the amount of  
available resources in the system and the resource allocation mechanism used;  
this may differ from system to system.   A high-quality  
implementation will provide generous limits on the important  
resources so as to alleviate the portability problem this  
represents.  
<P> 
In C and Fortran, almost all  MPI calls return a code that indicates  
successful completion of the operation.  Whenever possible,  MPI  
calls return an error code if an error occurred during the call.  By  
default, an error detected during the execution of the  MPI library  
causes the parallel computation to abort,  
  
except for file operations.  
  
However,  MPI provides  
mechanisms for users to change this default and to handle recoverable  
errors.  The user may specify that no error is fatal, and handle error  
codes returned by  MPI calls by himself or herself.  Also, the user  
may provide his or her own error-handling routines, which will be  
invoked whenever an  MPI call returns abnormally.  The  MPI error  
handling facilities are described   
in Section <a href="node182.htm#Node182">Error Handling 
</a>.  
The return values of  
C++ functions are not error codes.    
  
If the default error handler has been set to  
 MPI::ERRORS_THROW_EXCEPTIONS, the C++ exception mechanism is  
used to signal an error by throwing an  
  
<tt> MPI::Exception</tt>  
  
object.  
See also Section <a href="node332.htm#Node332">Exceptions 
</a> on page <a href="node332.htm#Node332">Exceptions 
</a>.   
  
Several factors limit the ability of  MPI calls to return with meaningful error  
codes when an error occurs.  
 MPI may not be able to detect some errors;  other errors may be too  
expensive to detect in normal execution mode; finally some errors may be  
``catastrophic'' and may prevent  MPI from returning control to the caller in a  
consistent state.  
<P> 
Another subtle issue arises because of the nature of asynchronous  
communications:  
 MPI calls may initiate operations that continue  
asynchronously after the call returned.  Thus, the operation may return with a  
code indicating successful completion, yet later cause an error exception to be  
raised.  If there is a subsequent call that relates to the same  
operation (e.g.,  
a call that verifies that an asynchronous operation has completed) then the  
error argument associated with this call will be used to indicate the nature  
of the error.  In a few cases, the error may occur after all calls that  
relate to the operation have completed, so that no error value can be used  
to indicate the nature of the error (e.g., an error on the receiver in  
a send with the ready mode).  Such an error must be treated as fatal, since  
information cannot be returned for the user to recover from it.  
<P> 
This document does not specify the state of a computation after an erroneous  
 MPI call has occurred.  
The desired behavior is that a relevant error code be returned, and the effect  
of the error be localized to the greatest possible extent.  E.g., it is highly  
desirable that an erroneous receive call will not cause any part of the  
receiver's memory to be overwritten, beyond the area specified for receiving the  
message.  
<P> 
Implementations may  
go beyond this document in supporting in a meaningful manner  MPI calls  
that are defined here to be erroneous.   For example,  MPI specifies  
strict type matching rules between matching send and receive  
operations: it is erroneous to send a floating point variable and receive an  
integer.  Implementations may go beyond these type matching rules, and provide  
automatic type conversion in such situations.  It will be helpful to generate  
warnings for such non-conforming behavior.  
<P> 
 MPI   
defines a way for users to create new error codes as defined  
in Section <a href="node188.htm#Node188">Error Classes, Error Codes, and Error Handlers 
</a>.  
<P> 

<P>
<HR>
<A HREF="node32.htm#Node32"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node34.htm#Node34"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node34.htm#Node34"> Implementation Issues</a>
<b>Previous: </b><A HREF="node32.htm#Node32"> Processes</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
