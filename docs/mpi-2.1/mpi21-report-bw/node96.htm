<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Examples using  MPI_SCATTER,  MPI_SCATTERV</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node96">95. Examples using  MPI_SCATTER,  MPI_SCATTERV</a></H2>
<A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node97.htm#Node97"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node95.htm#Node95"> Scatter</a>
<b>Next: </b><A HREF="node97.htm#Node97"> Gather-to-all</a>
<b>Previous: </b><A HREF="node95.htm#Node95"> Scatter</a>
<P>
The examples in this section use intracommunicators.  
  
<BR><b> Example</b>   
  
  
<P> 
The reverse of Example <a href="node94.htm#Node94">Examples using  MPI_GATHER,  MPI_GATHERV 
</a>.  
Scatter sets of 100 <tt> int</tt>s from the root to each process in the group.  
See Figure <a href="node96.htm#Figure9">9 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,*sendbuf; 
    int root, rbuf[100]; 
    ... 
    MPI_Comm_size( comm, &amp;gsize); 
    sendbuf = (int *)malloc(gsize*100*sizeof(int)); 
    ... 
    MPI_Scatter( sendbuf, 100, MPI_INT, rbuf, 100, MPI_INT, root, comm); 
</tt></pre> 
   
<P> 
<P> 
  <CENTER></CENTER>  
  <P><IMG WIDTH=497 HEIGHT=208 SRC="mycoll-fig7.gif"><P>
  
    
  <BR> 
<b>Figure 9: </b><A NAME="Figure9">The root process scatters sets of 100 <tt> int</tt>s to each process
  in the group.
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
<P> 
The reverse of Example <a href="node94.htm#Node94">Examples using  MPI_GATHER,  MPI_GATHERV 
</a>.  
The root process scatters sets of 100 <tt> int</tt>s to the other processes,  
but the sets of 100 are <em> stride int</em>s apart in the sending buffer.  
Requires use of  MPI_SCATTERV.  
Assume <IMG WIDTH=168 HEIGHT=11 SRC="img44.gif">
.  See Figure <a href="node96.htm#Figure10">10 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,*sendbuf; 
    int root, rbuf[100], i, *displs, *scounts; 
 
    ... 
 
    MPI_Comm_size( comm, &amp;gsize); 
    sendbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    ... 
    displs = (int *)malloc(gsize*sizeof(int)); 
    scounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        scounts[i] = 100; 
    } 
    MPI_Scatterv( sendbuf, scounts, displs, MPI_INT, rbuf, 100, MPI_INT, 
                                                              root, comm); 
</tt></pre> 
   
<P> 
<P> 
  <CENTER></CENTER>  
  <P><IMG WIDTH=497 HEIGHT=212 SRC="mycoll-fig8.gif"><P>
  
    
  <BR> 
<b>Figure 10: </b><A NAME="Figure10">The root process scatters sets of 100 <tt> int</tt>s, moving by
  <tt> stride int</tt>s from send to send in the scatter.
  </a><P> 
  
    
<BR><b> Example</b>   
  
  
  
  
<P> 
The reverse of Example <a href="node94.htm#Node94">Examples using  MPI_GATHER,  MPI_GATHERV 
</a>.  
We have a varying stride between blocks at sending (root) side,  
at the receiving side we receive into the <tt> i</tt>-th column of a 100<I>&#215;</I>150  
C array.  
See Figure <a href="node96.htm#Figure11">11 
</a>.  
<P> 
<BR> 
<pre><tt>    MPI_Comm comm; 
    int gsize,recvarray[100][150],*rptr; 
    int root, *sendbuf, myrank, bufsize, *stride; 
    MPI_Datatype rtype; 
    int i, *displs, *scounts, offset; 
    ... 
    MPI_Comm_size( comm, &amp;gsize); 
    MPI_Comm_rank( comm, &amp;myrank ); 
 
    stride = (int *)malloc(gsize*sizeof(int)); 
    ... 
    /* stride[i] for i = 0 to gsize-1 is set somehow 
     * sendbuf comes from elsewhere 
     */ 
    ... 
    displs = (int *)malloc(gsize*sizeof(int)); 
    scounts = (int *)malloc(gsize*sizeof(int)); 
    offset = 0; 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = offset; 
        offset += stride[i]; 
        scounts[i] = 100 - i; 
    } 
    /* Create datatype for the column we are receiving 
     */ 
    MPI_Type_vector( 100-myrank, 1, 150, MPI_INT, &amp;rtype); 
    MPI_Type_commit( &amp;rtype ); 
    rptr = &amp;recvarray[0][myrank]; 
    MPI_Scatterv( sendbuf, scounts, displs, MPI_INT, rptr, 1, rtype, 
                                                            root, comm); 
 
</tt></pre> 
   
<P> 
<P> 
  <CENTER></CENTER>  
  <P><IMG WIDTH=611 HEIGHT=262 SRC="mycoll-fig9.gif"><P>
  
    
  <BR> 
<b>Figure 11: </b><A NAME="Figure11">The root scatters blocks of <tt> 100-i int</tt>s into
  column <tt> i</tt> of a 100$ x $150
  C array.  At the sending side, the blocks are <tt> stride[i] int</tt>s apart.
  </a><P> 
  
    
  

<P>
<HR>
<A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node95.htm#Node95"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node97.htm#Node97"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node95.htm#Node95"> Scatter</a>
<b>Next: </b><A HREF="node97.htm#Node97"> Gather-to-all</a>
<b>Previous: </b><A HREF="node95.htm#Node95"> Scatter</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
