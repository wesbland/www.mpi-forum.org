<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Communication Calls</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node228">212. Communication Calls</a></H1>
<A HREF="node227.htm#Node227"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node229.htm#Node229"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node229.htm#Node229"> Put</a>
<b>Previous: </b><A HREF="node227.htm#Node227"> Window Attributes</a>
<P>
  
<P> 
 MPI supports three  RMA communication calls:  MPI_PUT  
transfers data from the  
caller memory (origin) to the target memory;  
 MPI_GET transfers data from the target memory to the caller  
memory;  
and  MPI_ACCUMULATE updates locations in the target memory,  
e.g. by adding to these locations values sent from the caller memory.  
These operations are <em> nonblocking</em>: the call initiates  
the transfer, but the transfer may continue after the call returns.  
The transfer is completed, both at the origin and at the target, when  
a subsequent <em> synchronization</em> call is issued by the caller on  
the involved window object.  These synchronization calls are described in  
Section <a href="node233.htm#Node233">Synchronization Calls 
</a>,  
page <a href="node233.htm#Node233">Synchronization Calls 
</a>.  
<P> 
The local communication buffer of an  RMA call should not be updated,  
and the local communication buffer of a get call should not be accessed  
after the  RMA  
call, until the subsequent synchronization call completes.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
The rule above is more lenient than for message-passing, where we do  
not allow two concurrent sends, with overlapping send buffers.  Here,  
we allow two concurrent puts with overlapping send buffers.  
The reasons for this relaxation are  
<ol> 
 
1. Users do not like that restriction, which is not very natural (it  
prohibits concurrent  
reads).  
 
<BR> 
2. Weakening the rule does not prevent efficient implementation, as far  
as we know.  
<P> 
 
<BR> 
3. Weakening the rule is important for performance of  RMA: we want to associate one synchronization call with as many  RMA operations is  
possible.  If puts from overlapping buffers cannot be concurrent, then  
we need to needlessly add synchronization points in the  
code.  
</ol> 
 (<em> End of rationale.</em>) <BR> 
It is erroneous to have concurrent conflicting accesses to the same memory location in a window; if a location is updated by a put or accumulate operation, then this location cannot be accessed by a load or another  RMA operation until the updating operation has completed at the target.  
There is one exception to this rule; namely, the same location can be  
updated by several concurrent accumulate calls, the outcome being as  
if these updates occurred in some order.  In addition, a window cannot  
concurrently be updated by a put or accumulate operation and by a  
local store operation.  This, even if these two updates access  
different locations in the window.  The last restriction enables  
more efficient implementations of  RMA operations on many systems.  
These restrictions are described in more detail in  
Section <a href="node243.htm#Node243">Semantics and Correctness 
</a>, page <a href="node243.htm#Node243">Semantics and Correctness 
</a>.  
<P> 
The calls use general datatype arguments to specify communication  
buffers at the origin and at the target.  Thus, a transfer operation  
may also gather data at the source and scatter it at the destination.  
However, all arguments specifying both communication buffers are  
provided by the caller.  
<P> 
For all three calls, the target process may be identical with the  
origin process;  
i.e., a  
process may use an RMA operation to move data in its memory.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
The choice of supporting ``self-communication'' is the same as for  
message-passing.  
It simplifies some coding, and is very useful with accumulate  
operations, to allow atomic updates of local variables.  
 (<em> End of rationale.</em>) <BR> 
 MPI_PROC_NULL is a valid target rank in the  MPI RMA calls  
 MPI_ACCUMULATE,  MPI_GET, and  MPI_PUT.    
The effect is the same as for  MPI_PROC_NULL in  MPI point-to-point  
communication.  
After any RMA operation with rank  MPI_PROC_NULL, it is still necessary to  
finish the RMA epoch with the synchronization method that started the epoch.   
  
<menu> 
</menu> 

<P>
<HR>
<A HREF="node227.htm#Node227"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node229.htm#Node229"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node229.htm#Node229"> Put</a>
<b>Previous: </b><A HREF="node227.htm#Node227"> Window Attributes</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
