<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>All-to-All Scatter/Gather</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node99">98. All-to-All Scatter/Gather</a></H1>
<A HREF="node98.htm#Node98"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node100.htm#Node100"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node100.htm#Node100"> Global Reduction Operations</a>
<b>Previous: </b><A HREF="node98.htm#Node98"> Examples using  MPI_ALLGATHER,  MPI_ALLGATHERV</a>
<P>
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_ALLTOALL(sendbuf, sendcount, sendtype, recvbuf,  
recvcount, recvtype, comm)</TD></TR>  
<TR><TD> IN  sendbuf</TD><TD> starting address of send buffer (choice)</TD></TR>  
<TR><TD> IN  sendcount</TD><TD> number of elements sent to each process (non-negative  
integer)</TD></TR>  
<TR><TD> IN  sendtype</TD><TD> data type of send buffer elements (handle)</TD></TR>  
<TR><TD> OUT  recvbuf</TD><TD> address of receive buffer (choice)</TD></TR>  
<TR><TD> IN  recvcount</TD><TD> number of elements received from any process (non-negative  
integer)</TD></TR>  
<TR><TD> IN  recvtype</TD><TD> data type of receive buffer elements (handle)</TD></TR>  
<TR><TD> IN  comm</TD><TD> communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Alltoall(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm) <BR></tt>  
<P> 
 <tt> MPI_ALLTOALL(SENDBUF, SENDCOUNT, SENDTYPE, RECVBUF, RECVCOUNT, RECVTYPE, COMM, IERROR) <BR> &lt;type&gt; SENDBUF(*), RECVBUF(*) <BR>INTEGER SENDCOUNT, SENDTYPE, RECVCOUNT, RECVTYPE, COMM, IERROR <BR></tt>  
  
  
 <tt> void MPI::Comm::Alltoall(const void* sendbuf, int sendcount, const MPI::Datatype&amp; sendtype, void* recvbuf, int recvcount, const MPI::Datatype&amp; recvtype) const = 0 <BR></tt>  
  
  
<P> 
 MPI_ALLTOALL is an extension of  MPI_ALLGATHER to the case  
where each process sends distinct data to each of the receivers.  
The   
<tt> j</tt>-th   
block sent from process <tt> i</tt> is received by process <tt> j</tt>  
and is placed in the   
<tt> i</tt>-th   
block of  recvbuf.  
<P> 
The type signature associated with  sendcount, sendtype,  
at a process must be equal to the type signature associated with  
 recvcount, recvtype at any other process.  
This implies that the amount of data sent must be equal to the  
amount of data received, pairwise between every pair of processes.  
As usual, however, the type maps may be different.  
<P> 
If  comm is an intracommunicator,   
the outcome is as if each process executed a send to each  
process (itself included)  
with a call to,  
<p><I> 
MPI_Send(sendbuf+i&#183; sendcount&#183; 
extent(sendtype),sendcount,sendtype,i, ...), 
</I><p>  
and a receive from every other process  
with a call to,  
<P><IMG WIDTH=168 HEIGHT=11 SRC="img45.gif"><P>
  
<P> 
All arguments  
on all processes are significant.  The argument  comm  
must have identical values on all processes.  
  
No ``in place'' option is supported.  
<P> 
<P> 
<P> 
If  comm is an intercommunicator, then the outcome is as if  
each process in group A sends a message to each process in group B,  
and vice versa.  The <tt> j</tt>-th send buffer of process <tt> i</tt> in group A should  
be consistent with the <tt> i</tt>-th receive buffer of process <tt> j</tt> in group B,  
and vice versa.  
<P> 
<P> 
<P> 
 
<BR> 
<em> Advice to users.</em>  
<P> 
When all-to-all is executed on an intercommunication domain, then  
the number of data items sent from processes in group A to processes  
in group B need not equal the number of items sent in the reverse  
direction.  In particular, one can have unidirectional communication  
by specifying  sendcount = 0 in the reverse direction.  
<P> 
 (<em> End of advice to users.</em>) <BR> 
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_ALLTOALLV(sendbuf, sendcounts, sdispls, sendtype,  
recvbuf, recvcounts, rdispls, recvtype, comm)</TD></TR>  
<TR><TD> IN  sendbuf</TD><TD> starting address of send buffer (choice)</TD></TR>  
<TR><TD> IN  sendcounts</TD><TD>non-negative  
integer array equal to the group size  
specifying the number of elements to send to each processor</TD></TR>  
<TR><TD> IN  sdispls</TD><TD> integer array (of length group size).  Entry  
<tt> j</tt> specifies the displacement (relative to  sendbuf from  
which to take the outgoing data destined for process <tt> j</tt></TD></TR>  
<TR><TD> IN  sendtype</TD><TD> data type of send buffer elements (handle)</TD></TR>  
<TR><TD> OUT  recvbuf</TD><TD> address of receive buffer (choice)</TD></TR>  
<TR><TD> IN  recvcounts</TD><TD>non-negative  
integer array equal to the group size  
specifying the number of elements that can be received from  
each processor</TD></TR>  
<TR><TD> IN  rdispls</TD><TD> integer array (of length group size).  Entry  
<tt> i</tt> specifies the displacement (relative to  recvbuf at  
which to place the incoming data from process <tt> i</tt></TD></TR>  
<TR><TD> IN  recvtype</TD><TD> data type of receive buffer elements (handle)</TD></TR>  
<TR><TD> IN  comm</TD><TD> communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Alltoallv(void* sendbuf, int *sendcounts, int *sdispls, MPI_Datatype sendtype, void* recvbuf, int *recvcounts, int *rdispls, MPI_Datatype recvtype, MPI_Comm comm) <BR></tt>  
<P> 
 <tt> MPI_ALLTOALLV(SENDBUF, SENDCOUNTS, SDISPLS, SENDTYPE, RECVBUF, RECVCOUNTS, RDISPLS, RECVTYPE, COMM, IERROR) <BR> &lt;type&gt; SENDBUF(*), RECVBUF(*) <BR>INTEGER SENDCOUNTS(*), SDISPLS(*), SENDTYPE, RECVCOUNTS(*), RDISPLS(*), RECVTYPE, COMM, IERROR <BR></tt>  
  
  
 <tt> void MPI::Comm::Alltoallv(const void* sendbuf,  const int sendcounts[], const int sdispls[],  const MPI::Datatype&amp; sendtype, void* recvbuf,  const int recvcounts[], const int rdispls[],  const MPI::Datatype&amp; recvtype) const = 0 <BR></tt>  
  
  
<P> 
 MPI_ALLTOALLV adds flexibility to  MPI_ALLTOALL in that  
the location of data for the send is specified by  sdispls  
and the location of the placement of the data on the receive side  
is specified by  rdispls.  
<P> 
If  comm is an intracommunicator, then  
the   
<tt> j</tt>-th   
block sent from process <tt> i</tt> is received by process <tt> j</tt>  
and is placed in the   
<tt> i</tt>-th   
block of  recvbuf.  These blocks need not all have the same size.  
<P> 
The type signature associated with  
 sendcount[j], sendtype at process <tt> i</tt> must be equal  
to the type signature  
associated with  recvcount[i], recvtype at process <tt> j</tt>.  
This implies that the amount of data sent must be equal to the  
amount of data received, pairwise between every pair of processes.  
Distinct type maps between sender and receiver are still allowed.  
<P> 
The outcome is as if each process sent a message to every other process  
with,  
<p><I> 
MPI_Send(sendbuf+displs[i]&#183; extent(sendtype),sendcounts[i],sendtype,i,...), 
</I><p>  
and received a message from every other process with  
a call to  
<p><I> 
MPI_Recv(recvbuf+displs[i]&#183; extent(recvtype),recvcounts[i],recvtype,i,...). 
</I><p>  
<P> 
All arguments  
on all processes are significant.  The argument  comm  
must have identical values on all processes.  
  
No ``in place'' option is supported.  
<P> 
If  comm is an intercommunicator, then the outcome is as if  
each process in group A sends a message to each process in group B,  
and vice versa.  The <tt> j</tt>-th send buffer of process <tt> i</tt> in group A should  
be consistent with the <tt> i</tt>-th receive buffer of process <tt> j</tt> in group B,  
and vice versa.  
  
 
<BR> 
<em> Rationale.</em>  
<P> 
The definitions of  MPI_ALLTOALL and  MPI_ALLTOALLV give as much  
flexibility as one would achieve by specifying <tt> n</tt> independent,  
point-to-point communications, with two exceptions: all messages use the same  
datatype, and messages are scattered from (or gathered to) sequential  
storage.  
 (<em> End of rationale.</em>) <BR> 
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
Although the discussion of collective communication in terms of  
point-to-point operation implies that each message is transferred directly  
from sender to receiver, implementations may use a tree communication  
pattern. Messages can be forwarded by intermediate nodes where they  
are split (for scatter) or concatenated (for gather), if this  
is more efficient.  
 (<em> End of advice to implementors.</em>) <BR> 
  
<P> 
  
  
  
<P> 
  
<P> 
<P> 
<P> 
<P> 
<P> 
<P> 
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_ALLTOALLW(sendbuf, sendcounts, sdispls, sendtypes,  
recvbuf, recvcounts, rdispls, recvtypes, comm)</TD></TR>  
<TR><TD> IN sendbuf</TD><TD>starting address of send buffer (choice)</TD></TR>  
<TR><TD> IN sendcounts</TD><TD>integer array equal to the group size specifying the  
number of elements to send to each processor (array of   
non-negative  
integers)</TD></TR>  
<TR><TD> IN sdispls</TD><TD>integer array (of length group size). Entry <tt> j</tt> specifies  
the displacement in bytes (relative to  sendbuf) from which to take  
the outgoing data destined for process <tt> j</tt> (array of integers)</TD></TR>  
<TR><TD> IN sendtypes</TD><TD>array of datatypes (of length group size). Entry <tt> j</tt>  
specifies the type of data to send to process <tt> j</tt> (array of handles)</TD></TR>  
<TR><TD> OUT recvbuf</TD><TD>address of receive buffer (choice)</TD></TR>  
<TR><TD> IN recvcounts</TD><TD>integer array equal to the group size specifying the  
number of elements that can be received from each processor (array of   
non-negative  
integers)</TD></TR>  
<TR><TD> IN rdispls</TD><TD>integer array (of length group size). Entry <tt> i</tt> specifies  
the displacement in bytes (relative to  recvbuf) at which to place the  
incoming data from process <tt> i</tt> (array of integers)</TD></TR>  
<TR><TD> IN recvtypes</TD><TD>array of datatypes (of length group size). Entry <tt> i</tt>  
specifies the type of data received from process <tt> i</tt> (array of handles)</TD></TR>  
<TR><TD> IN comm</TD><TD>communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Alltoallw(void *sendbuf, int sendcounts[], int sdispls[], MPI_Datatype sendtypes[], void *recvbuf, int recvcounts[], int rdispls[], MPI_Datatype recvtypes[], MPI_Comm comm) <BR></tt>  
<P> 
 <tt> MPI_ALLTOALLW(SENDBUF, SENDCOUNTS, SDISPLS, SENDTYPES, RECVBUF, RECVCOUNTS, RDISPLS, RECVTYPES, COMM, IERROR) <BR> &lt;type&gt; SENDBUF(*), RECVBUF(*)<BR>INTEGER SENDCOUNTS(*), SDISPLS(*), SENDTYPES(*), RECVCOUNTS(*), RDISPLS(*), RECVTYPES(*), COMM, IERROR <BR></tt>  
<P> 
  
 <tt> void MPI::Comm::Alltoallw(const void* sendbuf, const int sendcounts[], const int sdispls[], const MPI::Datatype sendtypes[], void* recvbuf, const int recvcounts[], const int rdispls[], const MPI::Datatype recvtypes[]) const = 0 <BR></tt>  
  
<P> 
<P> 
 MPI_ALLTOALLW  
is the most general form of <tt> All-to-all</tt>.  
Like  MPI_TYPE_CREATE_STRUCT, the most general type constructor,  
 MPI_ALLTOALLW allows separate specification of count,  
displacement and datatype.  In addition, to allow maximum flexibility,  
the displacement of blocks within the send and receive buffers is  
specified in bytes.  
<P> 
If  comm is an intracommunicator, then  
the <tt> j</tt>-th block sent from process <tt> i</tt> is received by process  
<tt> j</tt> and is placed in the <tt> i</tt>-th block of  recvbuf.  
These blocks need not all have the same size.  
<P> 
The type signature associated with  
 sendcounts[j], sendtypes[j] at process <tt> i</tt> must be equal  
to the type signature  
associated with  recvcounts[i], recvtypes[i] at process <tt> j</tt>.  
This implies that the amount of data sent must be equal to the  
amount of data received, pairwise between every pair of processes.  
Distinct type maps between sender and receiver are still allowed.  
<P> 
The outcome is as if each process sent a message to every other process with  
<p><I> 
MPI_Send(sendbuf+sdispls[i],sendcounts[i],sendtypes[i] ,i,...), 
</I><p>  
and received a message from every other process with a call to  
<p><I> 
MPI_Recv(recvbuf+rdispls[i],recvcounts[i],recvtypes[i] ,i,...). 
</I><p>  
<P> 
All arguments on all processes are significant.  The argument  
 comm must describe the same communicator on all processes.  
<P> 
No ``in place'' option is supported.  
  
If  comm is an intercommunicator, then the outcome is as if  
each process in group A sends a message to each process in group B,  
and vice versa.  The <tt> j</tt>-th send buffer of process <tt> i</tt> in group A should  
be consistent with the <tt> i</tt>-th receive buffer of process <tt> j</tt> in group B,  
and vice versa.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
The  MPI_ALLTOALLW function generalizes several  MPI functions by  
carefully selecting the input arguments.  For example, by making all but one  
process have <tt>sendcounts[i] = 0</tt>, this achieves an <tt>MPI_SCATTERW</tt>  
function.   
 (<em> End of rationale.</em>) <BR> 
  
  

<P>
<HR>
<A HREF="node98.htm#Node98"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node100.htm#Node100"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node100.htm#Node100"> Global Reduction Operations</a>
<b>Previous: </b><A HREF="node98.htm#Node98"> Examples using  MPI_ALLGATHER,  MPI_ALLGATHERV</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
