<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-topol/topol.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Low-Level Topology Functions</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node171">163. Low-Level Topology Functions</a></H2>
<A HREF="node170.htm#Node170"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node164.htm#Node164"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node172.htm#Node172"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node164.htm#Node164"> Topology Constructors</a>
<b>Next: </b><A HREF="node172.htm#Node172"> An Application Example</a>
<b>Previous: </b><A HREF="node170.htm#Node170"> Partitioning of Cartesian structures</a>
<P>
  
The two additional functions introduced in this section can be used to  
implement all other topology functions. In general they will not be  
called by the user directly, unless he or she is creating additional  
virtual topology capability other than that provided by  MPI.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_CART_MAP(comm, ndims, dims, periods, newrank)</TD></TR>  
<TR><TD> IN  comm</TD><TD> input communicator (handle)</TD></TR>  
<TR><TD> IN  ndims</TD><TD> number of dimensions of Cartesian structure (integer)</TD></TR>  
<TR><TD> IN  dims</TD><TD> integer array of size <tt> ndims</tt> specifying the number of processes in each coordinate direction </TD></TR>  
<TR><TD> IN   periods</TD><TD> logical array of size <tt> ndims</tt> specifying the periodicity specification in each coordinate direction</TD></TR>  
<TR><TD> OUT  newrank</TD><TD> reordered rank of the calling process;  MPI_UNDEFINED if calling process does not belong to grid (integer)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Cart_map(MPI_Comm comm, int ndims, int *dims, int *periods, int *newrank) <BR></tt>  
<P> 
 <tt> MPI_CART_MAP(COMM, NDIMS, DIMS, PERIODS, NEWRANK, IERROR)<BR> INTEGER COMM, NDIMS, DIMS(*), NEWRANK, IERROR <BR>LOGICAL PERIODS(*) <BR></tt>  
 <tt> int MPI::Cartcomm::Map(int ndims, const int dims[], const bool periods[]) const <BR></tt>  
  
 MPI_CART_MAP  
computes an ``optimal'' placement for the calling process on the  
physical machine.  A possible implementation of this function is to always  
return the rank of the calling process, that is, not to perform any reordering.  
<P> 
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
The function  MPI_CART_CREATE(comm, ndims, dims,  
periods, reorder, comm_cart), with <tt> reorder = true</tt> can be implemented by  
calling  
 MPI_CART_MAP(comm, ndims, dims, periods, newrank), then calling  
<BR>  
 MPI_COMM_SPLIT(comm, color, key, comm_cart), with  
<tt> color = 0</tt> if <tt> newrank <IMG WIDTH=436 HEIGHT=549 SRC="img89.gif">
  
<BR>  
MPI_UNDEFINED</tt>, <tt> color = MPI_UNDEFINED</tt> otherwise,  
and <tt> key = newrank</tt>.  
<P> 
The function  MPI_CART_SUB(comm, remain_dims, comm_new) can be  
implemented by a call to  MPI_COMM_SPLIT(comm, color, key, comm_new),  
using a single number encoding of the lost dimensions as <tt> color</tt> and a  
single number encoding of the preserved dimensions as <tt> key</tt>.  
<P> 
All other Cartesian topology functions can be implemented locally, using  
the topology information that is cached with the communicator.  
 (<em> End of advice to implementors.</em>) <BR> 
The corresponding new function for general graph structures is as follows.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_GRAPH_MAP(comm, nnodes, index, edges, newrank)</TD></TR>  
<TR><TD> IN  comm</TD><TD> input communicator (handle)</TD></TR>  
<TR><TD> IN  nnodes</TD><TD> number of graph nodes (integer)</TD></TR>  
<TR><TD> IN  index</TD><TD>integer array specifying the graph structure, see <BR> MPI_GRAPH_CREATE</TD></TR>  
<TR><TD> IN  edges</TD><TD>integer array specifying the graph structure</TD></TR>  
<TR><TD> OUT  newrank</TD><TD> reordered rank of the calling process;  MPI_UNDEFINED if the calling process does not belong to graph (integer)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Graph_map(MPI_Comm comm, int nnodes, int *index, int *edges, int *newrank) <BR></tt>  
<P> 
 <tt> MPI_GRAPH_MAP(COMM, NNODES, INDEX, EDGES, NEWRANK, IERROR)<BR> INTEGER COMM, NNODES, INDEX(*), EDGES(*), NEWRANK, IERROR <BR></tt>  
 <tt> int MPI::Graphcomm::Map(int nnodes, const int index[], const int edges[]) const <BR></tt>  
  
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
The function  MPI_GRAPH_CREATE(comm, nnodes, index, edges,  
reorder, comm_graph),  
with <tt> reorder = true</tt> can be implemented by calling  
 MPI_GRAPH_MAP(comm, nnodes, index, edges, newrank),  
then calling  
<BR>  
 MPI_COMM_SPLIT(comm, color, key, comm_graph), with <tt> color = 0</tt>  
if <tt> newrank <IMG WIDTH=121 HEIGHT=12 SRC="img90.gif">
  
<BR>  
MPI_UNDEFINED</tt>, <tt> color = MPI_UNDEFINED</tt>  
otherwise, and <tt> key = newrank</tt>.  
<P> 
All other graph topology functions can be implemented locally, using the  
topology information that is cached with the communicator.  
 (<em> End of advice to implementors.</em>) <BR> 
  

<P>
<HR>
<A HREF="node170.htm#Node170"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node164.htm#Node164"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node172.htm#Node172"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node164.htm#Node164"> Topology Constructors</a>
<b>Next: </b><A HREF="node172.htm#Node172"> An Application Example</a>
<b>Previous: </b><A HREF="node170.htm#Node170"> Partitioning of Cartesian structures</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
