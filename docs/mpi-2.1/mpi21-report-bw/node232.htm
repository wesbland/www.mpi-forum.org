<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Accumulate Functions</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node232">216. Accumulate Functions</a></H2>
<A HREF="node231.htm#Node231"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node228.htm#Node228"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node233.htm#Node233"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node228.htm#Node228"> Communication Calls</a>
<b>Next: </b><A HREF="node233.htm#Node233"> Synchronization Calls</a>
<b>Previous: </b><A HREF="node231.htm#Node231"> Examples</a>
<P>
  
<P> 
It is often useful in a put operation to combine the data moved to the  
target process with the data that resides at that process, rather   
then replacing the data there.  This will allow, for example, the  
accumulation of   
a sum by having all involved processes add their contribution to the  
sum variable in the memory of one process.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_ACCUMULATE(origin_addr, origin_count, origin_datatype, target_rank, target_disp, target_count,  
target_datatype, op, win)</TD></TR>  
<TR><TD> IN origin_addr</TD><TD>initial address of buffer (choice)</TD></TR> <TR><TD> IN origin_count</TD><TD>number of entries in buffer (nonnegative  
integer)</TD></TR>  
<TR><TD> IN origin_datatype</TD><TD>datatype of each buffer entry (handle)</TD></TR> <TR><TD> IN target_rank</TD><TD>rank of target (nonnegative integer)</TD></TR> <TR><TD> IN target_disp</TD><TD>displacement from start of window to beginning  
of target buffer (nonnegative integer)</TD></TR>  
<TR><TD> IN target_count</TD><TD>number of entries in target buffer  
(nonnegative integer)</TD></TR>  
<TR><TD> IN target_datatype</TD><TD>datatype of each entry in target buffer  
(handle)</TD></TR>  
<TR><TD> IN op</TD><TD>reduce operation (handle)</TD></TR>  
<TR><TD> IN win</TD><TD>window object (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Accumulate(void *origin_addr, int origin_count, MPI_Datatype origin_datatype, int target_rank, MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype,  MPI_Op op, MPI_Win win) <BR></tt>  
<P> 
 <tt> MPI_ACCUMULATE(ORIGIN_ADDR, ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK, TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE,  OP, WIN, IERROR) <BR> &lt;type&gt; ORIGIN_ADDR(*) <BR>INTEGER(KIND=MPI_ADDRESS_KIND) TARGET_DISP <BR>INTEGER ORIGIN_COUNT, ORIGIN_DATATYPE,TARGET_RANK, TARGET_COUNT, TARGET_DATATYPE,  OP, WIN, IERROR <BR></tt>  
<P> 
 <tt> void MPI::Win::Accumulate(const void* origin_addr, int origin_count, const MPI::Datatype&amp; origin_datatype, int target_rank, MPI::Aint target_disp, int target_count, const MPI::Datatype&amp; target_datatype, const MPI::Op&amp; op) const <BR></tt>  
<P> 
Accumulate the contents of the origin buffer  
(as defined by  origin_addr,  origin_count and  
 origin_datatype)  
to the buffer specified by arguments  target_count and  
 target_datatype,  
at offset  target_disp, in  
the target window specified by  target_rank and  win,  
using the operation   
 op.  
This is like  MPI_PUT except that data is combined into  
the target area instead of overwriting it.  
<P> 
Any of the predefined operations for  MPI_REDUCE can be  
used. User-defined functions cannot be used.  
For example, if  op is  MPI_SUM,  
each element of the origin buffer is added to the corresponding element  
in the target, replacing the former value in the target.  
<P> 
Each datatype argument must be a predefined datatype or a derived  
datatype, where all basic components are of the same predefined  
datatype.  Both datatype arguments must be constructed from the same  
predefined datatype.  
The operation  op applies to elements of that predefined  
type.  target_datatype must not specify overlapping   
entries, and the target buffer must fit in the target window.  
<P> 
A new predefined operation,  MPI_REPLACE, is defined.    
It corresponds to the associative function <I>f(a,b) = b</I>; i.e., the current  
value in the target memory is replaced by the value supplied by the  
origin.  
 MPI_REPLACE, like the other predefined operations, is defined  
only for the predefined  MPI datatypes.   
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
The rationale for this is that, for consistency,  MPI_REPLACE  
should have the same limitations as the other operations.  Extending  
it to all datatypes doesn't provide any real benefit.  
 (<em> End of rationale.</em>) <BR> 
  
 
<BR> 
<em> Advice to users.</em>  
<P> 
 MPI_PUT is a special case of  MPI_ACCUMULATE,  
with the  operation  MPI_REPLACE.  
Note, however, that  MPI_PUT and  MPI_ACCUMULATE  
have different constraints on concurrent updates.  
 (<em> End of advice to users.</em>) <BR> 
<BR><b> Example</b>  
  
  
  
  
  
We want to compute <IMG WIDTH=31 HEIGHT=10 SRC="img99.gif">
.  The arrays  
<tt> A, B</tt> and <tt> map</tt> are distributed in the same manner.  We write  
the simple version.  
<P> 
<BR> 
<pre><tt>SUBROUTINE SUM(A, B, map, m, comm, p) 
USE MPI 
INTEGER m, map(m), comm, p, win, ierr 
REAL A(m), B(m) 
INTEGER (KIND=MPI_ADDRESS_KIND) lowerbound, sizeofreal 
 
CALL MPI_TYPE_GET_EXTENT(MPI_REAL, lowerbound, sizeofreal, ierr) 
CALL MPI_WIN_CREATE(B, m*sizeofreal, sizeofreal, MPI_INFO_NULL,  &amp; 
                    comm, win, ierr) 
 
CALL MPI_WIN_FENCE(0, win, ierr) 
DO i=1,m 
  j = map(i)/p 
  k = MOD(map(i),p) 
  CALL MPI_ACCUMULATE(A(i), 1, MPI_REAL, j, k, 1, MPI_REAL,   &amp; 
                      MPI_SUM, win, ierr) 
END DO 
CALL MPI_WIN_FENCE(0, win, ierr) 
 
CALL MPI_WIN_FREE(win, ierr) 
RETURN 
END 
</tt></pre> 
  
This code is identical to the code in  
Example <a href="node231.htm#Node231">Examples 
</a>, page <a href="node231.htm#Node231">Examples 
</a>,  
except that a call to get has been  
replaced by a call to accumulate.  (Note that, if <tt> map</tt> is  
one-to-one, then the code computes <I> B = A(map<SUP>-1</SUP>)</I>, which is the  
reverse assignment to the one computed in that previous example.)  
In a similar manner, we can replace  
in Example <a href="node231.htm#Node231">Examples 
</a>,  
page <a href="node231.htm#Node231">Examples 
</a>,  
the call to get by a call to accumulate,  
thus  
performing the computation with only one communication between any  
two processes.  
  
<P> 

<P>
<HR>
<A HREF="node231.htm#Node231"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node228.htm#Node228"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node233.htm#Node233"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node228.htm#Node228"> Communication Calls</a>
<b>Next: </b><A HREF="node233.htm#Node233"> Synchronization Calls</a>
<b>Previous: </b><A HREF="node231.htm#Node231"> Examples</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
