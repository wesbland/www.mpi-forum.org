<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Synchronization Calls</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node233">217. Synchronization Calls</a></H1>
<A HREF="node232.htm#Node232"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node234.htm#Node234"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node234.htm#Node234"> Fence</a>
<b>Previous: </b><A HREF="node232.htm#Node232"> Accumulate Functions</a>
<P>
  
<P> 
 RMA communications fall in two categories:  
<ul> 
 
<li><b> active target</b> communication, where data is moved from the memory of one  
process to the memory of another, and both are explicitly involved in the  
communication.  This communication pattern is similar to message  
passing, except that all the data transfer arguments are provided by  
one process, and the second process only participates in the synchronization.  
 
<li><b> passive target</b> communication, where data is moved from the memory of one  
process to the memory of another, and only the origin process is  
explicitly involved  
in  
the transfer.  Thus, two origin processes may communicate by accessing  
the same location in a target window.  The process that owns the  
target window may be distinct from the two communicating processes,   
in which case it does not participate explicitly in the communication.  
This communication  
paradigm is closest to a shared memory model, where shared data can be  
accessed by all processes, irrespective   
of location.  
</ul> 
<BR> 
 RMA communication calls with argument  win must occur at a process  
only within an <b> access epoch</b> for  win.  Such an epoch  
starts with an  RMA synchronization  
call on  win; it proceeds with zero or more  RMA  
communication calls ( MPI_PUT,  MPI_GET or  
 MPI_ACCUMULATE) on  win; it completes with another  
synchronization call on   
 win.  
This allows users to amortize one synchronization with multiple data  
transfers and provide implementors  
more flexibility in the implementation of  RMA operations.  
<P> 
Distinct access epochs for  win at the same process must be disjoint.  
On the other hand, epochs pertaining to different  win arguments  
may  
overlap.  Local operations or other  MPI calls may also occur during  
an epoch.  
<P> 
In active target communication, a target window can be accessed by  RMA  
operations only within an <b> exposure epoch</b>. Such an epoch is  
started and completed by  RMA synchronization calls executed by the  
target process.  Distinct exposure epochs at a process  
on the same window must be disjoint, but such an exposure epoch  
may overlap with exposure epochs on other windows or  
with access epochs for the same or other  win arguments.  
  
There is a one-to-one matching between access epochs at origin  
processes and exposure epochs on target processes:  
 RMA operations issued by an origin process for a target window will  
access that  
target window during the same exposure epoch if and only if they were  
issued during the same access   
epoch.  
  
<P> 
In passive target communication the target  
process does not execute  RMA synchronization calls, and there is no  
concept of an exposure   
epoch.  
<P> 
 MPI provides three synchronization mechanisms:  
<ol> 
 
1. The  
 MPI_WIN_FENCE collective synchronization call supports a  
simple synchronization pattern that is often used in parallel  
computations: namely a loosely-synchronous model, where global  
computation phases alternate with global communication phases.  
This mechanism is most useful for loosely synchronous algorithms where  
the graph of communicating processes changes very frequently, or where  
each process communicates with many   
others.  
<P> 
This call is used for active target communication.  An access epoch at an  
origin process or an exposure epoch at a target process are started  
and completed by calls to  MPI_WIN_FENCE.  A process can  
access windows at all processes in the group of  win during  
such an access  
epoch, and the local window can be accessed by all processes in the  
group of  win during such an exposure epoch.  
 
<BR> 
2. The four functions  MPI_WIN_START,   
 MPI_WIN_COMPLETE,  MPI_WIN_POST and  MPI_WIN_WAIT  
can be used to restrict synchronization to the minimum: only  
pairs of communicating processes synchronize, and they do so only when  
a synchronization is needed to order correctly  RMA accesses to a  
window with respect to local accesses to that same window.  
This mechanism may be   
more efficient when each process communicates with few (logical)  
neighbors, and the communication graph is fixed or changes  
infrequently.  
<P> 
These calls are used for   
active target communication.  An access epoch is started  
at the origin process  
by a call to  MPI_WIN_START and is terminated by a call to  
 MPI_WIN_COMPLETE.  The start call has a group argument  
that specifies the group of target processes for that  
epoch. An exposure epoch is started at the  
target process by a call  
to  MPI_WIN_POST and is completed by a call to  
 MPI_WIN_WAIT.  The post call has a group argument that  
specifies the set of origin processes for that   
epoch.  
 
<BR> 
3. Finally,  
shared and exclusive locks are provided by the two functions  
 MPI_WIN_LOCK and  MPI_WIN_UNLOCK.    
Lock synchronization  
is useful for  MPI applications that  
emulate a shared memory model via  MPI calls; e.g., in a ``billboard''  
model, where processes can, at random times, access or update  
different parts of the billboard.  
<P> 
These two calls provide passive target communication.  An access epoch is  
started by a call to  MPI_WIN_LOCK and terminated by a  
call to  MPI_WIN_UNLOCK.  Only one target window can be  
accessed during that epoch with  win.  
</ol> 
Figure <a href="node233.htm#Figure17">17 
</a> illustrates the general synchronization  
pattern for active target   
communication.  
<CENTER><P><IMG WIDTH=414 HEIGHT=664 SRC="sync15.gif"><P>
</CENTER>  
<BR> 
<b>Figure 17: </b><A NAME="Figure17">Active target communication.  Dashed arrows represent
synchronizations (ordering of events).</a><P> 
  
  
The synchronization between  <tt> post</tt> and  
<tt> start</tt> ensures that the put call of the origin process does  
not start  
until the target process exposes the window (with the <tt> post</tt> call);  
the target process will  
expose the window only after preceding local accesses to the window  
have completed.  
The synchronization between <tt> complete</tt> and <tt> wait</tt>  
ensures that the put call of the origin process completes  
before the window is unexposed (with the <tt> wait</tt> call).  
The target process will execute  
following local accesses to the target window only after the <tt>  
wait</tt> returned.  
<P> 
Figure <a href="node233.htm#Figure17">17 
</a> shows operations occurring in the natural  
temporal order implied by the synchronizations: the <tt> post</tt>  
occurs before the matching <tt> start</tt>, and <tt> complete</tt> occurs before  
the  
matching <tt> wait</tt>.  However, such <b> strong</b> synchronization is more  
than  
needed for correct ordering of window accesses.  The semantics of  
 MPI calls allow <b> weak</b>  
synchronization, as illustrated in Figure <a href="node233.htm#Figure18">18 
</a>.  
<CENTER><P><IMG WIDTH=391 HEIGHT=546 SRC="sync14.gif"><P>
</CENTER>  
<BR> 
<b>Figure 18: </b><A NAME="Figure18">Active target communication, with weak synchronization.  Dashed
arrows represent synchronizations (ordering of events)</a><P> 
  
  
The access to the target window  is delayed until the window is  
exposed, after the <tt> post</tt>. However the <tt> start</tt>  
may complete earlier; the <tt> put</tt> and   
<tt> complete</tt> may also terminate earlier, if put data is  
buffered by the implementation.  
The synchronization calls order correctly window accesses, but do not  
necessarily synchronize other operations.  This weaker synchronization  
semantic allows for more efficient   
implementations.  
<P> 
Figure <a href="node233.htm#Figure19">19 
</a> illustrates the general synchronization  
pattern for passive target   
communication.  
The first origin process communicates data to the second  
origin process, through the memory of the target process; the target  
process is not explicitly involved in the   
communication.  
<CENTER><P><IMG WIDTH=604 HEIGHT=715 SRC="sync23.gif"><P>
</CENTER>  
<BR> 
<b>Figure 19: </b><A NAME="Figure19">Passive target communication.  Dashed arrows represent
synchronizations (ordering of events).</a><P> 
  
  
The  
<tt> lock</tt> and <tt> unlock</tt> calls ensure that the two  RMA  
accesses do not occur concurrently. However, they do <em> not</em> ensure  
that the <tt> put</tt> by origin 1 will precede the <tt> get</tt> by   
origin 2.  
<P> 
<menu> 
</menu> 

<P>
<HR>
<A HREF="node232.htm#Node232"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node234.htm#Node234"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node234.htm#Node234"> Fence</a>
<b>Previous: </b><A HREF="node232.htm#Node232"> Accumulate Functions</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
