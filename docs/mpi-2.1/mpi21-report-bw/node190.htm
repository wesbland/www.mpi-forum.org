<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-inquiry/inquiry.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Startup</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node190">178. Startup</a></H1>
<A HREF="node189.htm#Node189"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node191.htm#Node191"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node191.htm#Node191"> Allowing User Functions at Process Termination</a>
<b>Previous: </b><A HREF="node189.htm#Node189"> Timers and Synchronization</a>
<P>
  
  
  
    
One goal of  MPI is to achieve <em> source code portability</em>.  By this we mean  
that a program written using  MPI and complying with the relevant language  
standards is portable as written, and must not require any source code changes  
when moved from one system to another.  This explicitly does <em> not</em> say  
anything about how an  MPI program is started or launched from the command  
line, nor what the user must do to set up the environment in which an  MPI  
program will run.  However, an implementation may require some setup to be  
performed before other  MPI routines may be called.  To provide for this,  MPI  
includes an initialization routine  MPI_INIT.  
<P> 
  
      
      
      
     MPI_INIT()<BR>  
<P> 
  
<P> 
 <tt> int MPI_Init(int *argc, char ***argv) <BR></tt>  
<P> 
 <tt> MPI_INIT(IERROR)<BR> INTEGER IERROR <BR></tt>  
 <tt> void MPI::Init(int&amp; argc, char**&amp; argv) <BR></tt>  
 <tt> void MPI::Init() <BR></tt>  
  
<P> 
This routine must be called before any other  MPI routine.  It must be called  
at most once; subsequent calls are erroneous (see  MPI_INITIALIZED).  
<P> 
All  MPI programs must contain a call to  MPI_INIT; this routine must be  
called before any other  MPI routine (apart from   
 MPI_GET_VERSION,  MPI_INITIALIZED, and  MPI_FINALIZED)  
is called.  
The version for   
ISO C   
accepts the  argc and  argv that are  
provided by the arguments to <tt>main</tt>:  
  
<BR> 
<pre><tt>int main(argc, argv) 
int argc; 
char **argv; 
{ 
    MPI_Init(&amp;argc, &amp;argv); 
 
    /* parse arguments */ 
    /* main program    */ 
 
    MPI_Finalize();     /* see below */ 
} 
</tt></pre> 
  
The Fortran version takes only  IERROR.  
<P> 
Conforming implementations of  MPI are required to allow  
applications to pass  NULL for both the  argc and  
 argv arguments of  main in C and C++.  In C++, there is an alternative  
binding for  MPI::Init that does not have these arguments at all.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
In some applications, libraries may be making the call to  MPI_Init,  
and may not have access to  argc and  argv from  main.  
It is anticipated that applications requiring special information about  
the environment or information supplied by <tt> mpiexec</tt> can get that  
information from environment variables.  
 (<em> End of rationale.</em>) <BR> 
  
  
  
      
      
      
     MPI_FINALIZE()<BR>  
<P> 
  
<P> 
 <tt> int MPI_Finalize(void) <BR></tt>  
<P> 
 <tt> MPI_FINALIZE(IERROR)<BR> INTEGER IERROR <BR></tt>  
 <tt> void MPI::Finalize() <BR></tt>  
  
<P> 
This routine cleans up all  MPI state.  
  
  
Each process must call  MPI_FINALIZE before it exits.  
Unless there has been a call to  MPI_ABORT, each process must ensure that all pending non-blocking  
communications are (locally) complete before calling  MPI_FINALIZE.  
Further, at the instant at which the last process calls  
 MPI_FINALIZE, all pending sends must be matched by a receive, and  
all pending receives must be matched by a send.  
<P> 
For example, the following program is correct:  
<BR> 
<pre><tt>        Process 0                Process 1 
        ---------                --------- 
        MPI_Init();              MPI_Init(); 
        MPI_Send(dest=1);        MPI_Recv(src=0); 
        MPI_Finalize();          MPI_Finalize(); 
</tt></pre> 
Without the matching receive, the program is erroneous:  
<BR> 
<pre><tt>        Process 0                Process 1 
        -----------              ----------- 
        MPI_Init();              MPI_Init(); 
        MPI_Send (dest=1); 
        MPI_Finalize();          MPI_Finalize(); 
</tt></pre> 
  
<P> 
A successful return from a blocking communication operation or from  
 MPI_WAIT or  MPI_TEST tells the user that the buffer can  
be reused and means that the communication is completed by the user, but does  
not guarantee that the local process has no more work to do.  
A successful return from  MPI_REQUEST_FREE with a request handle  
generated by an  MPI_ISEND nullifies the handle but provides no  
assurance of operation completion.  The  MPI_ISEND is complete only when it is  
known by some means that a matching receive has completed.  
 MPI_FINALIZE guarantees that all local actions required by  
communications the user has completed will, in fact, occur before it returns.  
<P> 
 MPI_FINALIZE guarantees nothing about pending communications that  
have not been completed (completion is assured only by  MPI_WAIT,  
 MPI_TEST, or  MPI_REQUEST_FREE combined with some other  
verification of completion).  
<P> 
<BR><b> Example</b>  
  
  
  
   This program is correct:  
<BR> 
<pre><tt>rank 0                          rank 1 
===================================================== 
...                             ... 
MPI_Isend();                    MPI_Recv(); 
MPI_Request_free();             MPI_Barrier(); 
MPI_Barrier();                  MPI_Finalize(); 
MPI_Finalize();                 exit(); 
exit(); 
</tt></pre> 
  
<P> 
<BR><b> Example</b>  
  
  
   This program is erroneous and its behavior is undefined:  
<BR> 
<pre><tt>rank 0                          rank 1 
===================================================== 
...                             ... 
MPI_Isend();                    MPI_Recv(); 
MPI_Request_free();             MPI_Finalize(); 
MPI_Finalize();                 exit(); 
exit(); 
</tt></pre> 
  
<P> 
If no  MPI_BUFFER_DETACH occurs between an  MPI_BSEND (or  
other buffered send) and  
 MPI_FINALIZE, the  MPI_FINALIZE implicitly supplies  
the  MPI_BUFFER_DETACH.  
<P> 
<BR><b> Example</b>  
  
  
   This program is correct, and after the  MPI_Finalize, it is  
    as if the buffer had been detached.  
<BR> 
<pre><tt>rank 0                          rank 1 
===================================================== 
...                             ... 
buffer = malloc(1000000);       MPI_Recv(); 
MPI_Buffer_attach();            MPI_Finalize(); 
MPI_Bsend();                    exit(); 
MPI_Finalize(); 
free(buffer); 
exit(); 
</tt></pre> 
  
<P> 
<BR><b> Example</b>  
  
  
  
  
  
   In this example,  MPI_Iprobe() must return a  FALSE  
    flag.   MPI_Test_cancelled() must return a  TRUE flag,  
    independent of the relative order of execution of  MPI_Cancel()  
    in process 0 and  MPI_Finalize() in process 1.  
<P> 
The  MPI_Iprobe() call is there to make sure the implementation  
    knows that the ``tag1'' message exists at the destination, without being  
    able to claim that the user knows about it.  
<P> 
<BR> 
<pre><tt>rank 0                          rank 1 
======================================================== 
MPI_Init();                     MPI_Init(); 
MPI_Isend(tag1); 
MPI_Barrier();                  MPI_Barrier(); 
                                MPI_Iprobe(tag2); 
MPI_Barrier();                  MPI_Barrier(); 
                                MPI_Finalize(); 
                                exit(); 
MPI_Cancel(); 
MPI_Wait(); 
MPI_Test_cancelled(); 
MPI_Finalize(); 
exit(); 
 
</tt></pre> 
  
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
An implementation may need to delay the return from  MPI_FINALIZE  
   until all potential future message cancellations have been  
   processed.  One possible solution is to place a barrier inside  
    MPI_FINALIZE  
 (<em> End of advice to implementors.</em>) <BR> 
Once  MPI_FINALIZE returns, no  MPI routine (not even  MPI_INIT) may  
be called, except for  MPI_GET_VERSION,  MPI_INITIALIZED,  
and  MPI_FINALIZED.    
Each process must complete  
any pending communication it initiated before it calls  
 MPI_FINALIZE.  If the call returns, each process may continue local  
computations, or exit, without participating in further  MPI communication  
with other processes.    
 MPI_FINALIZE is collective over all connected processes.  
If no processes were spawned, accepted or connected then this means  
over  MPI_COMM_WORLD; otherwise it is collective over the  
union of all processes that have been and continue to be connected,  
as explained in Section <a href="node221.htm#Node221">Releasing Connections 
</a> on page <a href="node221.htm#Node221">Releasing Connections 
</a>.  
  
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
Even though a process has completed all the communication it initiated, such  
  communication may not yet be completed from the viewpoint of the underlying  
   MPI system.  E.g., a blocking send may have completed, even though the data  
  is still buffered at the sender.  The  MPI implementation must ensure that a  
  process has completed any involvement in  MPI communication before  
   MPI_FINALIZE returns.  Thus, if a process exits after the call to  
   MPI_FINALIZE, this will not cause an ongoing communication to  
  fail.  
 (<em> End of advice to implementors.</em>) <BR> 
Although it is not required that all processes return from  
 MPI_FINALIZE, it is required that at least process 0 in  
 MPI_COMM_WORLD return, so  
that users can know that the  MPI portion of the computation is over.  In  
addition, in a POSIX environment, they may desire to supply an exit code for  
each process that returns from  MPI_FINALIZE.  
<P> 
<BR><b> Example</b>  
  
   The following illustrates the use of requiring that at least one  
    process return and that it be known that process 0 is one of the processes  
    that return.  One wants code like the following to work no matter how many  
    processes return.  
<P> 
<BR> 
<pre><tt>    ... 
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank); 
    ... 
    MPI_Finalize(); 
    if (myrank == 0) { 
        resultfile = fopen("outfile","w"); 
        dump_results(resultfile); 
        fclose(resultfile); 
    } 
    exit(0); 
</tt></pre> 
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_INITIALIZED( flag )</TD></TR>  
<TR><TD> OUT flag</TD><TD></TD></TR>Flag is true if  MPI_INIT has been called and false  
otherwise.  
</TABLE>  
<P> 
 <tt> int MPI_Initialized(int *flag) <BR></tt>  
<P> 
 <tt> MPI_INITIALIZED(FLAG, IERROR)<BR> LOGICAL FLAG <BR>INTEGER IERROR <BR></tt>  
 <tt> bool MPI::Is_initialized() <BR></tt>  
  
<P> 
This routine may be used to determine whether  MPI_INIT has been  
called.  
 MPI_INITIALIZED returns  true if the calling process has  
called  MPI_INIT.  Whether  MPI_FINALIZE has been  
called does not affect the behavior of  MPI_INITIALIZED.  
  
It is one of the few routines that may be called before  
 MPI_INIT is called.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_ABORT( comm, errorcode )</TD></TR>  
<TR><TD> IN comm</TD><TD>communicator of tasks to abort</TD></TR>  
<TR><TD> IN errorcode</TD><TD>error code to return to invoking environment</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Abort(MPI_Comm comm, int errorcode) <BR></tt>  
<P> 
 <tt> MPI_ABORT(COMM, ERRORCODE, IERROR)<BR> INTEGER COMM, ERRORCODE, IERROR <BR></tt>  
 <tt> void MPI::Comm::Abort(int errorcode) <BR></tt>  
  
<P> 
This routine makes a ``best attempt'' to abort all tasks in the group  
of  comm.  
This function does not require that the invoking environment take any action  
with the error code.  However, a Unix or POSIX environment should handle this  
as a <tt>return errorcode</tt> from the main program.  
  
  
  
It may not be possible for an  MPI implementation to abort only the  
processes represented by  comm if this is a subset of the processes.  
In this case, the  MPI implementation should attempt to abort all the connected  
processes but should not abort any unconnected processes.  
If no processes were spawned, accepted or connected then this has the effect  
of aborting all the processes associated with  MPI_COMM_WORLD.  
<P> 
 
<BR> 
<em> Rationale.</em>  
<P> 
The communicator argument is provided to allow for future extensions of  MPI to  
environments with, for example, dynamic process management.  In particular, it  
allows but does not require an  MPI implementation to abort a subset of  
 MPI_COMM_WORLD.   
 (<em> End of rationale.</em>) <BR> 
  
 
<BR> 
<em> Advice to users.</em>  
<P> 
Whether the errorcode is returned from the executable or from the  
 MPI process startup mechanism (e.g., <tt> mpiexec</tt>), is an aspect of quality  
of the  MPI library but not mandatory.  
 (<em> End of advice to users.</em>) <BR> 
 
<BR> 
<em> Advice  
        to implementors.</em>  
<P> 
Where possible, a high-quality implementation will try to return the  
errorcode from the  MPI process startup mechanism  
(e.g. <tt> mpiexec</tt> or singleton init).  
 (<em> End of advice to implementors.</em>) <BR> 
  
<menu> 
</menu> 

<P>
<HR>
<A HREF="node189.htm#Node189"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="mpi21-report-bw.htm#Node0"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node191.htm#Node191"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="mpi21-report-bw.htm#Node0">Contents</a>
<b>Next: </b><A HREF="node191.htm#Node191"> Allowing User Functions at Process Termination</a>
<b>Previous: </b><A HREF="node189.htm#Node189"> Timers and Synchronization</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
