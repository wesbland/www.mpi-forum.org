<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-context/context.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Communicator Accessors</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node128">126. Communicator Accessors</a></H2>
<A HREF="node127.htm#Node127"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node127.htm#Node127"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node129.htm#Node129"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node127.htm#Node127"> Communicator Management</a>
<b>Next: </b><A HREF="node129.htm#Node129"> Communicator Constructors</a>
<b>Previous: </b><A HREF="node127.htm#Node127"> Communicator Management</a>
<P>
  
<P> 
The following are all local operations.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_COMM_SIZE(comm, size)</TD></TR>  
<TR><TD> IN comm</TD><TD> communicator (handle)</TD></TR>  
<TR><TD> OUT size</TD><TD>  number of processes in the group of    
comm (integer)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Comm_size(MPI_Comm comm, int *size) <BR></tt>  
<P> 
 <tt> MPI_COMM_SIZE(COMM, SIZE, IERROR)<BR> INTEGER COMM, SIZE, IERROR <BR></tt>  
 <tt> int MPI::Comm::Get_size() const <BR></tt>  
  
 
<BR> 
<em> Rationale.</em>  
<P> 
This function is equivalent to accessing the communicator's group with  
 MPI_COMM_GROUP (see above), computing the size using  
 MPI_GROUP_SIZE,  
and then freeing the temporary group via  MPI_GROUP_FREE.  However,  
this function is so commonly used, that this shortcut was introduced.  
 (<em> End of rationale.</em>) <BR> 
 
<BR> 
<em> Advice to users.</em>  
<P> 
This function indicates the number of processes involved in a communicator.  
For  MPI_COMM_WORLD, it indicates the total number of processes  
available (for this version of  MPI, there is no standard way to change  
the number of processes once initialization has taken place).  
<P> 
This call is often used with the next call to determine the amount of  
concurrency available for a specific library or program.  The following  
call,  MPI_COMM_RANK indicates the rank of the process  
that calls it in the range from <I>0...</I> size<I>-1</I>, where  size  
is the return value of  MPI_COMM_SIZE. (<em> End of advice to users.</em>) <BR> 
<TABLE><TR><TD COLSPAN=2>MPI_COMM_RANK(comm, rank)</TD></TR>  
<TR><TD> IN comm</TD><TD> communicator (handle)</TD></TR>  
<TR><TD> OUT rank</TD><TD>  rank of the calling process in group of  
  comm (integer)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Comm_rank(MPI_Comm comm, int *rank) <BR></tt>  
<P> 
 <tt> MPI_COMM_RANK(COMM, RANK, IERROR)<BR> INTEGER COMM, RANK, IERROR <BR></tt>  
 <tt> int MPI::Comm::Get_rank() const <BR></tt>  
  
  
 
<BR> 
<em> Rationale.</em>  
<P> 
This function is equivalent to accessing the communicator's group with  
 MPI_COMM_GROUP (see above), computing the rank using  
 MPI_GROUP_RANK,  
and then freeing the temporary group via  MPI_GROUP_FREE.  However,  
this function is so commonly used, that this shortcut was introduced.  
 (<em> End of rationale.</em>) <BR> 
  
<P> 
 
<BR> 
<em> Advice to users.</em>  
<P> 
This function gives the rank of the process in the particular communicator's  
group.  It is useful, as noted above, in conjunction with  
 MPI_COMM_SIZE.  
<P> 
Many programs will be written with the master-slave model, where one process  
(such as the rank-zero process) will play a supervisory role, and the other  
processes will serve as compute nodes.  In this framework, the two preceding  
calls are useful for determining the roles of the various processes of a  
communicator.  
 (<em> End of advice to users.</em>) <BR> 
<TABLE><TR><TD COLSPAN=2>MPI_COMM_COMPARE(comm1, comm2, result)</TD></TR>  
<TR><TD> IN comm1</TD><TD> first communicator (handle)</TD></TR>  
<TR><TD> IN comm2</TD><TD> second communicator (handle)</TD></TR>  
<TR><TD> OUT result</TD><TD> result (integer)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Comm_compare(MPI_Comm comm1,MPI_Comm comm2, int *result) <BR></tt>  
<P> 
 <tt> MPI_COMM_COMPARE(COMM1, COMM2, RESULT, IERROR)<BR> INTEGER COMM1, COMM2, RESULT, IERROR <BR></tt>  
 <tt> static int MPI::Comm::Compare(const MPI::Comm&amp; comm1, const MPI::Comm&amp; comm2) <BR></tt>  
  
 MPI_IDENT results if and only if  
 comm1 and  comm2 are handles for the same object  
(identical groups and same contexts).  
 MPI_CONGRUENT results if the underlying groups are identical  
in constituents and rank order; these communicators differ only by context.  
 MPI_SIMILAR results if the group members of both  
communicators are the same but the rank order  
differs.  MPI_UNEQUAL results otherwise.  
  

<P>
<HR>
<A HREF="node127.htm#Node127"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node127.htm#Node127"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node129.htm#Node129"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node127.htm#Node127"> Communicator Management</a>
<b>Next: </b><A HREF="node129.htm#Node129"> Communicator Constructors</a>
<b>Previous: </b><A HREF="node127.htm#Node127"> Communicator Management</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
