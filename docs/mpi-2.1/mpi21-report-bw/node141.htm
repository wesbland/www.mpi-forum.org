<HTML>
<HEAD>
<!-- This file was generated by tohtml from chap-context/context.tex -->
<!-- with the command
tohtml -default -basedef ../mpi2defs-bw.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi2-forum-tail.htm -Wnoredef -o mpi21-report-bw.tex mpi-report.tex 
-->
<TITLE>Inter-Communication Examples</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node141">139. Inter-Communication Examples</a></H2>
<A HREF="node140.htm#Node140"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node138.htm#Node138"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node141.htm#Node142"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node138.htm#Node138"> Inter-Communication</a>
<b>Next: </b><A HREF="node141.htm#Node142"> Example 1:  Three-Group ``Pipeline"</a>
<b>Previous: </b><A HREF="node140.htm#Node140"> Inter-communicator Operations</a>
<P>
<menu> 
</menu> 

<P>
<HR>
<A HREF="node140.htm#Node140"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node138.htm#Node138"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node141.htm#Node142"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node138.htm#Node138"> Inter-Communication</a>
<b>Next: </b><A HREF="node141.htm#Node142"> Example 1:  Three-Group ``Pipeline"</a>
<b>Previous: </b><A HREF="node140.htm#Node140"> Inter-communicator Operations</a>
<P>
<HR><H3><A NAME="Node142">139.1. Example 1:  Three-Group ``Pipeline"</a></H3>
<A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node141.htm#Node143"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<b>Next: </b><A HREF="node141.htm#Node143"> Example 2:  Three-Group ``Ring"</a>
<b>Previous: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<P>
  
<P> 
<P> 
  <CENTER></CENTER>  
  <P><IMG WIDTH=378 HEIGHT=91 SRC="context-fig-1.gif"><P>
  
  <BR> 
<b>Figure 15: </b><A NAME="Figure15">Three-group pipeline.</a><P> 
  
  
 Groups 0 and 1 communicate.  Groups 1 and 2 communicate.  Therefore, group  
0 requires one inter-communicator, group 1 requires two  
inter-communicators, and group 2 requires 1 inter-communicator.  
<P> 
<BR> 
<pre><tt>   main(int argc, char **argv) 
   { 
     MPI_Comm   myComm;       /* intra-communicator of local sub-group */ 
     MPI_Comm   myFirstComm;  /* inter-communicator */ 
     MPI_Comm   mySecondComm; /* second inter-communicator (group 1 only) */ 
     int membershipKey; 
     int rank; 
 
     MPI_Init(&amp;argc, &amp;argv); 
     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); 
 
     /* User code must generate membershipKey in the range [0, 1, 2] */ 
     membershipKey = rank % 3; 
 
     /* Build intra-communicator for local sub-group */ 
     MPI_Comm_split(MPI_COMM_WORLD, membershipKey, rank, &amp;myComm); 
 
     /* Build inter-communicators.  Tags are hard-coded. */ 
     if (membershipKey == 0) 
     {                     /* Group 0 communicates with group 1. */ 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 1, 
                            1, &amp;myFirstComm); 
     } 
     else if (membershipKey == 1) 
     {              /* Group 1 communicates with groups 0 and 2. */ 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 0, 
                            1, &amp;myFirstComm); 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 2, 
                            12, &amp;mySecondComm); 
     } 
     else if (membershipKey == 2) 
     {                     /* Group 2 communicates with group 1. */ 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 1, 
                            12, &amp;myFirstComm); 
     } 
 
     /* Do work ... */ 
 
     switch(membershipKey)  /* free communicators appropriately */ 
     { 
     case 1: 
        MPI_Comm_free(&amp;mySecondComm); 
     case 0: 
     case 2: 
        MPI_Comm_free(&amp;myFirstComm); 
        break; 
     } 
 
     MPI_Finalize(); 
   } 
</tt></pre> 

<P>
<HR>
<A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node141.htm#Node143"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<b>Next: </b><A HREF="node141.htm#Node143"> Example 2:  Three-Group ``Ring"</a>
<b>Previous: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<P>
<HR><H3><A NAME="Node143">139.2. Example 2:  Three-Group ``Ring"</a></H3>
<A HREF="node141.htm#Node142"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node141.htm#Node144"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<b>Next: </b><A HREF="node141.htm#Node144"> Example 3:  Building Name Service for Intercommunication</a>
<b>Previous: </b><A HREF="node141.htm#Node142"> Example 1:  Three-Group ``Pipeline"</a>
<P>
  
<P> 
<P> 
  <CENTER></CENTER>  
  <P><IMG WIDTH=432 HEIGHT=118 SRC="context-fig-2.gif"><P>
  
  <BR> 
<b>Figure 16: </b><A NAME="Figure16">Three-group ring.</a><P> 
  
  
Groups 0 and 1 communicate.  Groups 1 and 2 communicate.  Groups 0 and  
2 communicate.  Therefore, each requires two inter-communicators.  
<P> 
<BR> 
<pre><tt>   main(int argc, char **argv) 
   { 
     MPI_Comm   myComm;      /* intra-communicator of local sub-group */ 
     MPI_Comm   myFirstComm; /* inter-communicators */ 
     MPI_Comm   mySecondComm; 
     MPI_Status status; 
     int membershipKey; 
     int rank; 
 
     MPI_Init(&amp;argc, &amp;argv); 
     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); 
     ... 
 
     /* User code must generate membershipKey in the range [0, 1, 2] */ 
     membershipKey = rank % 3; 
 
     /* Build intra-communicator for local sub-group */ 
     MPI_Comm_split(MPI_COMM_WORLD, membershipKey, rank, &amp;myComm); 
 
     /* Build inter-communicators.  Tags are hard-coded. */ 
     if (membershipKey == 0) 
     {             /* Group 0 communicates with groups 1 and 2. */ 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 1, 
                            1, &amp;myFirstComm); 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 2, 
                            2, &amp;mySecondComm); 
     } 
     else if (membershipKey == 1) 
     {         /* Group 1 communicates with groups 0 and 2. */ 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 0, 
                            1, &amp;myFirstComm); 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 2, 
                            12, &amp;mySecondComm); 
     } 
     else if (membershipKey == 2) 
     {        /* Group 2 communicates with groups 0 and 1. */ 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 0, 
                            2, &amp;myFirstComm); 
       MPI_Intercomm_create( myComm, 0, MPI_COMM_WORLD, 1, 
                            12, &amp;mySecondComm); 
     } 
 
     /* Do some work ... */ 
 
     /* Then free communicators before terminating... */ 
     MPI_Comm_free(&amp;myFirstComm); 
     MPI_Comm_free(&amp;mySecondComm); 
     MPI_Comm_free(&amp;myComm); 
     MPI_Finalize(); 
   } 
</tt></pre> 

<P>
<HR>
<A HREF="node141.htm#Node142"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node141.htm#Node144"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<b>Next: </b><A HREF="node141.htm#Node144"> Example 3:  Building Name Service for Intercommunication</a>
<b>Previous: </b><A HREF="node141.htm#Node142"> Example 1:  Three-Group ``Pipeline"</a>
<P>
<HR><H3><A NAME="Node144">139.3. Example 3:  Building Name Service for Intercommunication</a></H3>
<A HREF="node141.htm#Node143"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node145.htm#Node145"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<b>Next: </b><A HREF="node145.htm#Node145"> Caching</a>
<b>Previous: </b><A HREF="node141.htm#Node143"> Example 2:  Three-Group ``Ring"</a>
<P>
  
The following procedures exemplify the process by which a user could  
create name service for building intercommunicators via a rendezvous  
involving a server communicator, and a tag name selected by both  
groups.  
<P> 
After all  MPI processes execute  MPI_INIT, every process  
calls the example function,  Init_server(), defined below.  
Then, if the  new_world returned is NULL, the process getting  
NULL is required to implement a server function, in a reactive loop,  
 Do_server().  Everyone else just does their prescribed  
computation, using  new_world as the new effective ``global"  
communicator.  One designated process calls  Undo_Server() to  
get rid of the server when it is not needed any longer.  
<P> 
Features of this approach include:  
<P> 
<ul> 
 
<li>Support for multiple name servers  
 
<li>Ability to scope the name servers to specific processes  
 
<li>Ability to make such servers come and go as desired.  
</ul> 
<BR> 
<BR> 
<pre><tt>#define INIT_SERVER_TAG_1   666 
#define UNDO_SERVER_TAG_1   777 
 
static int server_key_val; 
 
/* for attribute management for server_comm,  copy callback: */ 
void handle_copy_fn(MPI_Comm *oldcomm, int *keyval, void *extra_state, 
void *attribute_val_in, void **attribute_val_out, int *flag) 
{ 
   /* copy the handle */ 
   *attribute_val_out = attribute_val_in; 
   *flag = 1; /* indicate that copy to happen */ 
} 
 
int Init_server(peer_comm, rank_of_server, server_comm, new_world) 
MPI_Comm peer_comm; 
int rank_of_server; 
MPI_Comm *server_comm; 
MPI_Comm *new_world;    /* new effective world, sans server */ 
{ 
    MPI_Comm temp_comm, lone_comm; 
    MPI_Group peer_group, temp_group; 
    int rank_in_peer_comm, size, color, key = 0; 
    int peer_leader, peer_leader_rank_in_temp_comm; 
 
    MPI_Comm_rank(peer_comm, &amp;rank_in_peer_comm); 
    MPI_Comm_size(peer_comm, &amp;size); 
 
    if ((size &lt; 2) || (0 &gt; rank_of_server) || (rank_of_server &gt;= size)) 
        return (MPI_ERR_OTHER); 
 
    /* create two communicators, by splitting peer_comm 
       into the server process, and everyone else */ 
 
    peer_leader = (rank_of_server + 1) % size;  /* arbitrary choice */ 
 
    if ((color = (rank_in_peer_comm == rank_of_server))) 
    { 
        MPI_Comm_split(peer_comm, color, key, &amp;lone_comm); 
 
        MPI_Intercomm_create(lone_comm, 0, peer_comm, peer_leader, 
                           INIT_SERVER_TAG_1, server_comm); 
 
        MPI_Comm_free(&amp;lone_comm); 
        *new_world = MPI_COMM_NULL; 
    } 
    else 
    { 
        MPI_Comm_Split(peer_comm, color, key, &amp;temp_comm); 
 
        MPI_Comm_group(peer_comm, &amp;peer_group); 
        MPI_Comm_group(temp_comm, &amp;temp_group); 
        MPI_Group_translate_ranks(peer_group, 1, &amp;peer_leader, 
     temp_group, &amp;peer_leader_rank_in_temp_comm); 
 
        MPI_Intercomm_create(temp_comm, peer_leader_rank_in_temp_comm, 
                           peer_comm, rank_of_server, 
                           INIT_SERVER_TAG_1, server_comm); 
 
        /* attach new_world communication attribute to server_comm: */ 
 
        /* CRITICAL SECTION FOR MULTITHREADING */ 
        if(server_keyval == MPI_KEYVAL_INVALID) 
        { 
            /* acquire the process-local name for the server keyval */ 
            MPI_keyval_create(handle_copy_fn, NULL, 
                                               &amp;server_keyval, NULL); 
        } 
 
        *new_world = temp_comm; 
 
        /* Cache handle of intra-communicator on inter-communicator: */ 
        MPI_Attr_put(server_comm, server_keyval, (void *)(*new_world)); 
    } 
 
    return (MPI_SUCCESS); 
} 
</tt></pre> 
The actual server process would commit to running the following code:  
<BR> 
<pre><tt>int Do_server(server_comm) 
MPI_Comm server_comm; 
{ 
    void init_queue(); 
    int en_queue(), de_queue(); /* keep triplets of integers 
                                   for later matching (fns not shown) */ 
 
    MPI_Comm comm; 
    MPI_Status status; 
    int client_tag, client_source; 
    int client_rank_in_new_world, pairs_rank_in_new_world; 
    int buffer[10], count = 1; 
 
    void *queue; 
    init_queue(&amp;queue); 
 
 
    for (;;) 
    { 
        MPI_Recv(buffer, count, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, 
                 server_comm, &amp;status); /* accept from any client */ 
 
        /* determine client: */ 
        client_tag = status.MPI_TAG; 
        client_source = status.MPI_SOURCE; 
        client_rank_in_new_world = buffer[0]; 
 
        if (client_tag == UNDO_SERVER_TAG_1)       /* client that 
                                                   terminates server */ 
        { 
            while (de_queue(queue, MPI_ANY_TAG, &amp;pairs_rank_in_new_world, 
                            &amp;pairs_rank_in_server)) 
                ; 
 
            MPI_Comm_free(&amp;server_comm); 
            break; 
        } 
 
        if (de_queue(queue, client_tag, &amp;pairs_rank_in_new_world, 
                        &amp;pairs_rank_in_server)) 
        { 
            /* matched pair with same tag, tell them 
               about each other! */ 
            buffer[0] = pairs_rank_in_new_world; 
            MPI_Send(buffer, 1, MPI_INT, client_src, client_tag, 
                                                     server_comm); 
 
            buffer[0] = client_rank_in_new_world; 
            MPI_Send(buffer, 1, MPI_INT, pairs_rank_in_server, client_tag, 
                     server_comm); 
        } 
        else 
            en_queue(queue, client_tag, client_source, 
                                        client_rank_in_new_world); 
 
    } 
} 
</tt></pre> 
A particular process would be responsible for ending the server  
when it is no longer needed.  Its call to  Undo_server would  
terminate server function.  
<BR> 
<pre><tt>int Undo_server(server_comm)     /* example client that ends server */ 
MPI_Comm *server_comm; 
{ 
    int buffer = 0; 
    MPI_Send(&amp;buffer, 1, MPI_INT, 0, UNDO_SERVER_TAG_1, *server_comm); 
    MPI_Comm_free(server_comm); 
} 
</tt></pre> 
The following is a blocking name-service for inter-communication, with same  
semantic restrictions as  MPI_Intercomm_create, but simplified syntax.  
It uses the functionality just defined to create the name service.  
<BR> 
<pre><tt>int Intercomm_name_create(local_comm, server_comm, tag, comm) 
MPI_Comm local_comm, server_comm; 
int tag; 
MPI_Comm *comm; 
{ 
    int error; 
    int found;   /* attribute acquisition mgmt for new_world */ 
                 /* comm in server_comm */ 
    void *val; 
 
    MPI_Comm new_world; 
 
    int buffer[10], rank; 
    int local_leader = 0; 
 
    MPI_Attr_get(server_comm, server_keyval, &amp;val, &amp;found); 
    new_world = (MPI_Comm)val; /* retrieve cached handle */ 
 
    MPI_Comm_rank(server_comm, &amp;rank);  /* rank in local group */ 
 
    if (rank == local_leader) 
    { 
        buffer[0] = rank; 
        MPI_Send(&amp;buffer, 1, MPI_INT, 0, tag, server_comm); 
        MPI_Recv(&amp;buffer, 1, MPI_INT, 0, tag, server_comm); 
    } 
 
    error = MPI_Intercomm_create(local_comm, local_leader, new_world, 
                                 buffer[0], tag, comm); 
 
    return(error); 
} 
</tt></pre> 

<P>
<HR>
<A HREF="node141.htm#Node143"><IMG WIDTH=16 HEIGHT=16 SRC="previous.gif"></A><A HREF="node141.htm#Node141"><IMG WIDTH=16 HEIGHT=16 SRC="up.gif"></A><A HREF="node145.htm#Node145"><IMG WIDTH=16 HEIGHT=16 SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node141.htm#Node141"> Inter-Communication Examples</a>
<b>Next: </b><A HREF="node145.htm#Node145"> Caching</a>
<b>Previous: </b><A HREF="node141.htm#Node143"> Example 2:  Three-Group ``Ring"</a>
<P>
<HR>
Return to <A HREF="node428.htm">MPI-2.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-2.0 of July 1, 2008<BR>
HTML Generated on July 6, 2008
</FONT>
</BODY>
</HTML>
