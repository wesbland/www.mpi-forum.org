<HTML>
<!-- This file was generated by tohtml from coll.tex -->
<TITLE>Gather-to-all</TITLE>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node73">4.7. Gather-to-all</a></H1>
<A HREF="node72.html#Node72"><IMG SRC="previous.gif"></A><A HREF="node63.html#Node63"><IMG SRC="up.gif"></A><A HREF="node74.html#Node74"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node63.html#Node63"> Collective Communication</a>
<b>Next: </b><A HREF="node74.html#Node74"> Examples using  MPI_ALLGATHER,  MPI_ALLGATHERV</a>
<b>Previous: </b><A HREF="node72.html#Node72"> Examples using  MPI_SCATTER,  MPI_SCATTERV</a>
<P>
  
<P> 
    
      
      
      
      
     MPI_ALLGATHER( sendbuf, sendcount, sendtype, recvbuf,  
recvcount, recvtype, comm)  
     
<BR> 
[  IN    sendbuf]  starting address of send buffer (choice)  
 
<BR> 
[  IN    sendcount]  number of elements in send buffer (integer)  
 
<BR> 
[  IN    sendtype]  data type of send buffer elements (handle)  
 
<BR> 
[  OUT    recvbuf]  address of receive buffer (choice)  
 
<BR> 
[  IN    recvcount]  number of elements received from any  
process (integer)  
 
<BR> 
[  IN    recvtype]  data type of receive buffer elements (handle)  
 
<BR> 
[  IN    comm]   communicator (handle)  
<BR> 
  
<P> 
 <tt> int MPI_Allgather(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm) <BR></tt>  
<P> 
 <tt> MPI_ALLGATHER(SENDBUF, SENDCOUNT, SENDTYPE, RECVBUF, RECVCOUNT, RECVTYPE, COMM, IERROR) <BR> &lt;type&gt; SENDBUF(*), RECVBUF(*) <BR>INTEGER SENDCOUNT, SENDTYPE, RECVCOUNT, RECVTYPE, COMM, IERROR <BR></tt>  
<P> 
 MPI_ALLGATHER can be thought of as  MPI_GATHER, but  
where all processes receive the result, instead of just the root.  
The <tt> j</tt>th block of data sent from each process is received  
by every process and placed in the <tt> j</tt>th block of the  
buffer  recvbuf.  
<P> 
The type signature associated with  sendcount, sendtype,  
at a process must be equal to the type signature associated with  
 recvcount, recvtype at any other process.  
<P> 
The outcome of a call to  MPI_ALLGATHER(...) is as if  
all processes executed <tt> n</tt> calls to  
<BR> 
<pre><tt>MPI_GATHER(sendbuf,sendcount,sendtype,recvbuf,recvcount, 
                                                 recvtype,root,comm), 
</tt></pre> 
for <tt> root = 0 , ..., n-1</tt>.  The rules for correct usage of  
 MPI_ALLGATHER are easily found from the corresponding rules  
for  MPI_GATHER.  
<P> 
    
      
      
      
      
     MPI_ALLGATHERV( sendbuf, sendcount, sendtype, recvbuf,  
recvcounts, displs, recvtype, comm)  
     
<BR> 
[  IN    sendbuf]  starting address of send buffer (choice)  
 
<BR> 
[  IN    sendcount]  number of elements in send buffer (integer)  
 
<BR> 
[  IN    sendtype]  data type of send buffer elements (handle)  
 
<BR> 
[  OUT    recvbuf]  address of receive buffer (choice)  
 
<BR> 
[  IN    recvcounts]  integer array (of length group size)  
containing the number of elements that are received from each process  
 
<BR> 
[  IN    displs]  integer array (of length group size).  Entry  
<tt> i</tt> specifies the displacement (relative to  recvbuf) at  
which to place the incoming data from process <tt> i</tt>  
 
<BR> 
[  IN    recvtype]  data type of receive buffer elements (handle)  
 
<BR> 
[  IN    comm]   communicator (handle)  
<BR> 
  
<P> 
 <tt> int MPI_Allgatherv(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int *recvcounts, int *displs, MPI_Datatype recvtype, MPI_Comm comm) <BR></tt>  
<P> 
 <tt> MPI_ALLGATHERV(SENDBUF, SENDCOUNT, SENDTYPE, RECVBUF, RECVCOUNTS, DISPLS, RECVTYPE, COMM, IERROR) <BR> &lt;type&gt; SENDBUF(*), RECVBUF(*) <BR>INTEGER SENDCOUNT, SENDTYPE, RECVCOUNTS(*), DISPLS(*), RECVTYPE, COMM, IERROR <BR></tt>  
<P> 
 MPI_ALLGATHERV can be thought of as  MPI_GATHERV, but  
where all processes receive the result, instead of just the root.  
The <tt> j</tt>th block of data sent from each process is received  
by every process and placed in the <tt> j</tt>th block of the  
buffer  recvbuf.  These blocks need not all be the same size.  
<P> 
The type signature associated with  sendcount, sendtype,  
at process <tt> j</tt> must be equal to the type signature associated with  
 recvcounts[j], recvtype at any other process.  
<P> 
The outcome is as if all processes executed calls to  
<BR> 
<pre><tt>MPI_GATHERV(sendbuf,sendcount,sendtype,recvbuf,recvcounts,displs, 
                                                   recvtype,root,comm), 
</tt></pre> 
for <tt> root = 0 , ..., n-1</tt>.  The rules for correct usage of  
 MPI_ALLGATHERV are easily found from the corresponding rules  
for  MPI_GATHERV.  
<P> 
<menu> 
</menu> 

<P>
<HR>
<A HREF="node72.html#Node72"><IMG SRC="previous.gif"></A><A HREF="node63.html#Node63"><IMG SRC="up.gif"></A><A HREF="node74.html#Node74"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node63.html#Node63"> Collective Communication</a>
<b>Next: </b><A HREF="node74.html#Node74"> Examples using  MPI_ALLGATHER,  MPI_ALLGATHERV</a>
<b>Previous: </b><A HREF="node72.html#Node72"> Examples using  MPI_SCATTER,  MPI_SCATTERV</a>
<P>
<HR>
Return to <A HREF="node182.html">MPI 1.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/docs/mpi-20-html/node306.html">MPI-2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-1.1 of June 12, 1995<BR>
HTML Generated on August 6, 1997
</FONT>
</BODY>
</HTML>
