<HTML>
<!-- This file was generated by tohtml from coll.tex -->
<TITLE>Examples using  MPI_ALLGATHER,  MPI_ALLGATHERV</TITLE>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node74">4.7.1. Examples using  MPI_ALLGATHER,  MPI_ALLGATHERV</a></H2>
<A HREF="node73.html#Node73"><IMG SRC="previous.gif"></A><A HREF="node73.html#Node73"><IMG SRC="up.gif"></A><A HREF="node75.html#Node75"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node73.html#Node73"> Gather-to-all</a>
<b>Next: </b><A HREF="node75.html#Node75"> All-to-All Scatter/Gather</a>
<b>Previous: </b><A HREF="node73.html#Node73"> Gather-to-all</a>
<P>
  
<P> 
<BR><b> Example</b>   
  
<P> 
The all-gather version of Example <a href="node70.html#Node70">Examples using  MPI_GATHER,  MPI_GATHERV
</a>.  
Using  MPI_ALLGATHER, we will gather 100 ints from every process in the  
group to every process.  
<P> 
<BR> 
<pre><tt>MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int *rbuf; 
    ... 
    MPI_Comm_size( comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    MPI_Allgather( sendarray, 100, MPI_INT, rbuf, 100, MPI_INT, comm); 
</tt></pre> 
After the call, every process has the group-wide concatenation of the  
sets of data.  
   
<P> 

<P>
<HR>
<A HREF="node73.html#Node73"><IMG SRC="previous.gif"></A><A HREF="node73.html#Node73"><IMG SRC="up.gif"></A><A HREF="node75.html#Node75"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node73.html#Node73"> Gather-to-all</a>
<b>Next: </b><A HREF="node75.html#Node75"> All-to-All Scatter/Gather</a>
<b>Previous: </b><A HREF="node73.html#Node73"> Gather-to-all</a>
<P>
<HR>
Return to <A HREF="node182.html">MPI 1.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/docs/mpi-20-html/node306.html">MPI-2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-1.1 of June 12, 1995<BR>
HTML Generated on August 6, 1997
</FONT>
</BODY>
</HTML>
