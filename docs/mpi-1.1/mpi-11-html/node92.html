<HTML>
<!-- This file was generated by tohtml from context.tex -->
<TITLE>Groups</TITLE>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node92">5.2.1. Groups</a></H2>
<A HREF="node91.html#Node91"><IMG SRC="previous.gif"></A><A HREF="node91.html#Node91"><IMG SRC="up.gif"></A><A HREF="node93.html#Node93"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node91.html#Node91"> Basic Concepts</a>
<b>Next: </b><A HREF="node93.html#Node93"> Contexts</a>
<b>Previous: </b><A HREF="node91.html#Node91"> Basic Concepts</a>
<P>
A <b> group</b> is an ordered set of process identifiers (henceforth  
processes); processes are implementation-dependent objects.  Each  
process in a group is associated with an integer <b> rank</b>.  Ranks are  
contiguous and start from zero.  
Groups are represented by opaque <b> group objects</b>, and hence cannot  
be directly transferred from one process to another.   A group is used  
within a communicator to describe the participants in a communication  
``universe'' and to rank such participants (thus giving them unique names  
within that ``universe'' of communication).  
<P> 
There is a special pre-defined group:  MPI_GROUP_EMPTY, which is  
a group with no members.  
The predefined constant  
 MPI_GROUP_NULL is the value used for invalid group handles.  
<P> 
 
<BR> 
[]<em> Advice to users.</em>  
<P> 
 MPI_GROUP_EMPTY, which is a valid handle to an empty group,  
should not be confused with  MPI_GROUP_NULL, which in turn is  
an invalid handle.  The former may be used as an argument to group  
operations; the latter, which is returned when a group is freed, in not  
a valid argument.  
 (<em> End of advice to users.</em>) <BR> 
 
<BR> 
[]<em> Advice  
 to implementors.</em>  
<P> 
A group may be represented by a virtual-to-real process-address-translation  
table.  Each communicator object (see below) would have a pointer to such a  
table.  
<P> 
Simple implementations of  MPI will enumerate groups, such as in a  
table.  However, more advanced data structures make sense in order  
to improve scalability and memory usage with large numbers of processes.  
Such implementations are possible with  MPI.  
 (<em> End of advice to implementors.</em>) <BR> 

<P>
<HR>
<A HREF="node91.html#Node91"><IMG SRC="previous.gif"></A><A HREF="node91.html#Node91"><IMG SRC="up.gif"></A><A HREF="node93.html#Node93"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node91.html#Node91"> Basic Concepts</a>
<b>Next: </b><A HREF="node93.html#Node93"> Contexts</a>
<b>Previous: </b><A HREF="node91.html#Node91"> Basic Concepts</a>
<P>
<HR>
Return to <A HREF="node182.html">MPI 1.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/docs/mpi-20-html/node306.html">MPI-2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-1.1 of June 12, 1995<BR>
HTML Generated on August 6, 1997
</FONT>
</BODY>
</HTML>
