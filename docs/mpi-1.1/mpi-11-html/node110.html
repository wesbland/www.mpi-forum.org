<HTML>
<!-- This file was generated by tohtml from context.tex -->
<TITLE>Library Example #2</TITLE>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node110">5.5.6. Library Example #2</a></H2>
<A HREF="node109.html#Node109"><IMG SRC="previous.gif"></A><A HREF="node104.html#Node104"><IMG SRC="up.gif"></A><A HREF="node111.html#Node111"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node104.html#Node104"> Motivating Examples</a>
<b>Next: </b><A HREF="node111.html#Node111"> Inter-Communication</a>
<b>Previous: </b><A HREF="node109.html#Node109"> Library Example #1</a>
<P>
  
The main program:  
<BR> 
<pre><tt>main(int argc, char **argv) 
   { 
     int ma, mb; 
     MPI_Group MPI_GROUP_WORLD, group_a, group_b; 
     MPI_Comm comm_a, comm_b; 
<P> 
static int list_a[] = {0, 1}; 
#if  defined(EXAMPLE_2B) | defined(EXAMPLE_2C) 
     static int list_b[] = {0, 2 ,3}; 
#else/* EXAMPLE_2A */ 
     static int list_b[] = {0, 2}; 
#endif 
     int size_list_a = sizeof(list_a)/sizeof(int); 
     int size_list_b = sizeof(list_b)/sizeof(int); 
<P> 
... 
     MPI_Init(&amp;argc, &amp;argv); 
     MPI_Comm_group(MPI_COMM_WORLD, &amp;MPI_GROUP_WORLD); 
<P> 
MPI_Group_incl(MPI_GROUP_WORLD, size_list_a, list_a, &amp;group_a); 
     MPI_Group_incl(MPI_GROUP_WORLD, size_list_b, list_b, &amp;group_b); 
<P> 
MPI_Comm_create(MPI_COMM_WORLD, group_a, &amp;comm_a); 
     MPI_Comm_create(MPI_COMM_WORLD, group_b, &amp;comm_b); 
<P> 
if(comm_a != MPI_COMM_NULL) 
        MPI_Comm_rank(comm_a, &amp;ma); 
     if(comm_a != MPI_COMM_NULL) 
        MPI_Comm_rank(comm_b, &amp;mb); 
<P> 
if(comm_a != MPI_COMM_NULL) 
        lib_call(comm_a); 
<P> 
if(comm_b != MPI_COMM_NULL) 
     { 
       lib_call(comm_b); 
       lib_call(comm_b); 
     } 
<P> 
if(comm_a != MPI_COMM_NULL) 
       MPI_Comm_free(&amp;comm_a); 
     if(comm_b != MPI_COMM_NULL) 
       MPI_Comm_free(&amp;comm_b); 
     MPI_Group_free(&amp;group_a); 
     MPI_Group_free(&amp;group_b); 
     MPI_Group_free(&amp;MPI_GROUP_WORLD); 
     MPI_Finalize(); 
   } 
</tt></pre> 
 The library:  
<BR> 
<pre><tt>void lib_call(MPI_Comm comm) 
   { 
     int me, done = 0; 
     MPI_Comm_rank(comm, &amp;me); 
     if(me == 0) 
        while(!done) 
        { 
           MPI_Recv(..., MPI_ANY_SOURCE, MPI_ANY_TAG, comm); 
           ... 
        } 
     else 
     { 
       /* work */ 
       MPI_Send(..., 0, ARBITRARY_TAG, comm); 
       .... 
     } 
#ifdef EXAMPLE_2C 
     /* include (resp, exclude) for safety (resp, no safety): */ 
     MPI_Barrier(comm); 
#endif 
   } 
</tt></pre> 
The above example is really three examples, depending on whether or  
not one includes rank 3 in  list_b, and whether or not a  
synchronize is included in  lib_call.  This example illustrates  
that, despite contexts, subsequent calls to  lib_call with the  
same context need not be safe from one another (colloquially,  
``back-masking'').  Safety is realized if the   MPI_Barrier is  
added.  What this demonstrates is that libraries have to be written  
carefully, even with contexts.  When rank 3 is excluded, then  
the synchronize is not needed to get safety from back masking.  
<P> 
Algorithms like ``reduce'' and ``allreduce'' have strong enough source  
selectivity properties so that they are inherently okay (no backmasking),  
provided that  MPI provides basic guarantees.  So are multiple calls to a  
typical tree-broadcast algorithm with the same root or different roots (see  
[<a href="node166.html#-Bib28">28</a>]).  Here we rely on two guarantees of  MPI: pairwise ordering of  
messages between processes in the same context, and source selectivity ---  
deleting either feature removes the guarantee that backmasking cannot  
be required.  
<P> 
Algorithms that try to do non-deterministic broadcasts or other calls that  
include wildcard operations will not generally have the good properties of the  
deterministic implementations of ``reduce,'' ``allreduce,'' and ``broadcast.''  
Such algorithms would have to utilize the monotonically increasing tags  
(within a communicator scope) to keep things straight.  
<P> 
All of the foregoing is a supposition of ``collective calls'' implemented with  
point-to-point operations.   MPI implementations may or may not implement  
collective calls using point-to-point operations.  These algorithms are used  
to illustrate the issues of correctness and safety, independent of how  MPI  
implements its collective calls.  See also section <a href="node121.html#Node121">Formalizing the Loosely Synchronous Model
</a>.  
<P> 
<P> 

<P>
<HR>
<A HREF="node109.html#Node109"><IMG SRC="previous.gif"></A><A HREF="node104.html#Node104"><IMG SRC="up.gif"></A><A HREF="node111.html#Node111"><IMG SRC="next.gif"></A><BR>
<b>Up: </b><A HREF="node104.html#Node104"> Motivating Examples</a>
<b>Next: </b><A HREF="node111.html#Node111"> Inter-Communication</a>
<b>Previous: </b><A HREF="node109.html#Node109"> Library Example #1</a>
<P>
<HR>
Return to <A HREF="node182.html">MPI 1.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/docs/mpi-20-html/node306.html">MPI-2 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>MPI-1.1 of June 12, 1995<BR>
HTML Generated on August 6, 1997
</FONT>
</BODY>
</HTML>
