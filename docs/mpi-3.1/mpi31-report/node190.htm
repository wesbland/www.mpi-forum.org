<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-topol/topol.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Overview of the Functions</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node190">178. Overview of the Functions</span></h1>
<a href="node189.htm#Node189"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="mpi31-report.htm#Node0"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node191.htm#Node191"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="mpi31-report.htm#Node0">Contents</a>
<b>Next: </b><a href="node191.htm#Node191"> Topology Constructors</a>
<b>Previous: </b><a href="node189.htm#Node189"> Embedding in <font face="sans-serif"> MPI</font></a>
<p>
  
<P> 
MPI supports three topology types:  
<b> Cartesian</b>,  
<b> graph</b>, and  
<b> distributed graph</b>.    
The function <font face="sans-serif"> MPI_CART_CREATE</font>  
is used to create Cartesian topologies, the function  
<font face="sans-serif"> MPI_GRAPH_CREATE</font> is used to create graph topologies, and the  
functions <font face="sans-serif"> MPI_DIST_GRAPH_CREATE_ADJACENT</font> and  
<font face="sans-serif"> MPI_DIST_GRAPH_CREATE</font> are used to create distributed graph  
topologies.  
These topology creation functions are collective.  As with  
other collective calls, the program must be written to work correctly,  
whether the call synchronizes or not.  
<P> 
The topology creation functions take as input an existing communicator  
<font face="sans-serif"> comm_old</font>,  
which defines the set of processes on which the topology is to be  
mapped.   
For <font face="sans-serif"> MPI_GRAPH_CREATE</font> and <font face="sans-serif"> MPI_CART_CREATE</font>,   
all input arguments must have identical  
values on all processes of the group of <font face="sans-serif"> comm_old</font>.  
When calling <font face="sans-serif"> MPI_GRAPH_CREATE</font>, each process specifies all  
nodes and edges in the graph. In contrast, the functions  
<font face="sans-serif"> MPI_DIST_GRAPH_CREATE_ADJACENT</font> or  
<font face="sans-serif"> MPI_DIST_GRAPH_CREATE</font> are used to  
specify the graph in a distributed fashion, whereby each process only  
specifies a subset of the edges in the graph such that the entire graph  
structure is defined collectively across the set of processes.  
Therefore the processes provide different values for the  
arguments specifying the graph. However, all processes must give the  
same value for <font face="sans-serif"> reorder</font> and the <font face="sans-serif"> info</font> argument. In all cases, a  
new communicator <font face="sans-serif"> comm_topol</font> is created that  
carries the topological structure as cached information (see  
Chapter <a href="node141.htm#Node141">Groups, Contexts, Communicators, and Caching 
</a>). In analogy to function  
<font face="sans-serif"> MPI_COMM_CREATE</font>, no cached information propagates from  
<font face="sans-serif"> comm_old</font> to <font face="sans-serif"> comm_topol</font>.  
<P> 
<font face="sans-serif"> MPI_CART_CREATE</font> can be used to describe Cartesian structures of  
arbitrary dimension. For each coordinate direction one specifies whether the  
process structure is periodic or not.  
Note that an <i>n</i>-dimensional hypercube is  
an <i>n</i>-dimensional torus with 2 processes per coordinate direction. Thus,  
special support for hypercube structures is not necessary.  The local  
auxiliary function <font face="sans-serif"> MPI_DIMS_CREATE</font> can be used to compute a balanced  
distribution of processes among a given number of dimensions.  
<P> 
<P> 
MPI defines functions to query a communicator for topology information.  
The function <font face="sans-serif"> MPI_TOPO_TEST</font> is used to query for the type of topology  
associated with a communicator. Depending on the topology type,  
different information can be extracted. For a graph topology, the  
functions <font face="sans-serif"> MPI_GRAPHDIMS_GET</font> and <font face="sans-serif"> MPI_GRAPH_GET</font> return the values that  
were specified in the call to <font face="sans-serif"> MPI_GRAPH_CREATE</font>. Additionally, the  
functions <font face="sans-serif"> MPI_GRAPH_NEIGHBORS_COUNT</font> and  
<font face="sans-serif"> MPI_GRAPH_NEIGHBORS</font> can be used  
to obtain the neighbors of an arbitrary node in the graph. For a  
distributed graph topology, the functions  
<font face="sans-serif"> MPI_DIST_GRAPH_NEIGHBORS_COUNT</font>  
and <font face="sans-serif"> MPI_DIST_GRAPH_NEIGHBORS</font> can be used to obtain the neighbors of the  
calling process. For a Cartesian topology, the functions  
<font face="sans-serif"> MPI_CARTDIM_GET</font> and <font face="sans-serif"> MPI_CART_GET</font> return the values that were specified in the call to  
<font face="sans-serif"> MPI_CART_CREATE</font>. Additionally, the functions  
<font face="sans-serif"> MPI_CART_RANK</font> and <font face="sans-serif"> MPI_CART_COORDS</font> translate Cartesian coordinates into a group rank, and  
vice-versa. The function <font face="sans-serif"> MPI_CART_SHIFT</font> provides the information needed  
to communicate with neighbors along a Cartesian dimension. All of these  
query functions are local.  
<P> 
For Cartesian topologies, the function  
<font face="sans-serif"> MPI_CART_SUB</font> can be used to extract a Cartesian subspace  
(analogous to <font face="sans-serif"> MPI_COMM_SPLIT</font>). This function is collective  
over the input communicator's group.  
<P> 
The two additional functions, <font face="sans-serif"> MPI_GRAPH_MAP</font> and  
<font face="sans-serif"> MPI_CART_MAP</font>, are, in general, not called by the user directly. However,  
together with the communicator manipulation functions presented in  
Chapter <a href="node141.htm#Node141">Groups, Contexts, Communicators, and Caching 
</a>, they are sufficient to implement all other  
topology functions.  Section <a href="node199.htm#Node199">Low-Level Topology Functions 
</a> outlines such  
an implementation.  
 <P> 
The neighborhood collective communication routines  
<font face="sans-serif"> MPI_NEIGHBOR_ALLGATHER</font>, <font face="sans-serif"> MPI_NEIGHBOR_ALLGATHERV</font>,   
<font face="sans-serif"> MPI_NEIGHBOR_ALLTOALL</font>,<font face="sans-serif"> MPI_NEIGHBOR_ALLTOALLV</font>,  
and <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALLW</font>  
communicate with the nearest neighbors on the topology associated with  
the communicator.  
The nonblocking variants are  
<font face="sans-serif"> MPI_INEIGHBOR_ALLGATHER</font>, <font face="sans-serif"> MPI_INEIGHBOR_ALLGATHERV</font>,   
<font face="sans-serif"> MPI_INEIGHBOR_ALLTOALL</font>, <font face="sans-serif"> MPI_INEIGHBOR_ALLTOALLV</font>,  
and <font face="sans-serif"> MPI_INEIGHBOR_ALLTOALLW</font>.  
<P> 

<P>
<hr>
<a href="node189.htm#Node189"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="mpi31-report.htm#Node0"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node191.htm#Node191"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="mpi31-report.htm#Node0">Contents</a>
<b>Next: </b><a href="node191.htm#Node191"> Topology Constructors</a>
<b>Previous: </b><a href="node189.htm#Node189"> Embedding in <font face="sans-serif"> MPI</font></a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
