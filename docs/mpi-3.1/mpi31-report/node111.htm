<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Reduce</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node111">106. Reduce</span></h2>
<a href="node110.htm#Node110"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node110.htm#Node110"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node112.htm#Node112"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node110.htm#Node110"> Global Reduction Operations</a>
<b>Next: </b><a href="node112.htm#Node112"> Predefined Reduction Operations</a>
<b>Previous: </b><a href="node110.htm#Node110"> Global Reduction Operations</a>
<p>
  
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_REDUCE(sendbuf, recvbuf, count, datatype, op,  
root, comm)</TD></TR>  
<TR><TD> IN  sendbuf</TD><TD> address of send buffer (choice)</TD></TR>  
<TR><TD> OUT  recvbuf</TD><TD> address of receive buffer (choice,  
significant only at root)</TD></TR>  
<TR><TD> IN  count</TD><TD> number of elements in send buffer (non-negative  
integer)</TD></TR>  
<TR><TD> IN  datatype</TD><TD> data type of elements of send buffer (handle)</TD></TR>  
<TR><TD> IN  op</TD><TD> reduce operation (handle)</TD></TR>  
<TR><TD> IN  root</TD><TD> rank of root process (integer)</TD></TR>  
<TR><TD> IN  comm</TD><TD>  communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Reduce(const void* sendbuf, void* recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm) <br></tt>  
<P> 
 <tt> MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm, ierror) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: sendbuf <br>TYPE(*), DIMENSION(..) :: recvbuf <br>INTEGER, INTENT(IN) :: count, root <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Op), INTENT(IN) :: op <br>TYPE(MPI_Comm), INTENT(IN) :: comm <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_REDUCE(SENDBUF, RECVBUF, COUNT, DATATYPE, OP, ROOT, COMM, IERROR) <br> &lt;type&gt; SENDBUF(*), RECVBUF(*) <br>INTEGER COUNT, DATATYPE, OP, ROOT, COMM, IERROR <br></tt>  
<P> 
  
<P> 
If <font face="sans-serif"> comm</font> is an intracommunicator,  
<font face="sans-serif"> MPI_REDUCE</font> combines the elements provided  
in the input buffer of each process in the  
group, using the operation <font face="sans-serif"> op</font>, and returns the combined value in  
the output buffer of the process with rank <font face="sans-serif"> root</font>.  
The input buffer is defined by the arguments <font face="sans-serif"> sendbuf</font>,  
<font face="sans-serif"> count</font> and <font face="sans-serif"> datatype</font>; the output buffer is defined by  
the arguments <font face="sans-serif"> recvbuf</font>, <font face="sans-serif"> count</font> and <font face="sans-serif"> datatype</font>;  
both have the same number of elements, with the same type.  
The routine is called by all group members using the same arguments  
for <font face="sans-serif"> count, datatype, op, root</font> and <font face="sans-serif"> comm</font>.  
Thus, all processes provide input buffers of the  
same length, with elements of the same type as the output buffer at the root.  
Each process can provide one element, or a sequence of elements,  
in which case the  
combine operation is executed element-wise on each entry of the sequence.  
For example, if the operation is <font face="sans-serif">  MPI_MAX</font> and the send buffer  
contains two elements that are floating point numbers (<font face="sans-serif"> count</font> = 2 and  
<font face="sans-serif"> datatype</font> = <font face="sans-serif"> MPI_FLOAT</font>), then <img width=167 height=11 src="img112.gif" alt="Image file">
 and <img width=167 height=11 src="img113.gif" alt="Image file">
.  
<P> 
Section <a href="node112.htm#Node112">Predefined Reduction Operations 
</a>, lists the set of predefined operations  
provided by <font face="sans-serif"> MPI</font>. That section also enumerates  
the datatypes   
to which each operation can be applied.  
<P> 
In addition, users may define their own operations that can be  
overloaded to operate on several datatypes, either basic or derived.  
This is further explained in Section <a href="node115.htm#Node115">User-Defined Reduction Operations 
</a>.  
<P> 
The operation <font face="sans-serif"> op</font> is always assumed to be  
associative.  All predefined operations are also assumed to be  
commutative.  Users may define operations that are assumed to be  
associative, but not commutative.  The ``canonical'' evaluation order  
of a reduction is determined by the ranks of the processes in the  
group.  However, the implementation can take  
advantage of associativity, or associativity and commutativity  
in order to change the order of evaluation.  
This may change the result of the reduction for operations that are not  
strictly associative and commutative, such as floating point addition.  
<P> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
It is strongly recommended that <font face="sans-serif"> MPI_REDUCE</font> be implemented so  
that the same result be obtained  
whenever the function is applied on the same arguments,  
appearing in the same order.  Note that this may  
prevent optimizations that take  
advantage of the physical location of ranks.  
 (<em> End of advice to implementors.</em>) <br> 
 
<br> 
<em> Advice to users.</em>  
<P> 
Some applications may not be able to ignore the non-associative nature of  
floating-point operations or may use user-defined operations  
(see Section <a href="node115.htm#Node115">User-Defined Reduction Operations 
</a>) that require a special reduction  
order and cannot be treated as associative.  
Such applications should enforce the order of evaluation explicitly.  
For example, in the case of operations that require a strict left-to-right  
(or right-to-left) evaluation order, this could be done by gathering all  
operands at a single process (e.g., with <font face="sans-serif"> MPI_GATHER</font>), applying the  
reduction operation in the desired order (e.g., with <font face="sans-serif"> MPI_REDUCE_LOCAL</font>),  
and if needed, broadcast or scatter the result to the other processes  
(e.g., with <font face="sans-serif"> MPI_BCAST</font>).  
 (<em> End of advice to users.</em>) <br> 
The <font face="sans-serif"> datatype</font> argument of <font face="sans-serif"> MPI_REDUCE</font> must be  
compatible with   
<font face="sans-serif"> op</font>.    
Predefined operators work only with  
the <font face="sans-serif"> MPI</font> types listed in Section <a href="node112.htm#Node112">Predefined Reduction Operations 
</a> and   
Section <a href="node114.htm#Node114">MINLOC and MAXLOC 
</a>.  Furthermore, the  
<font face="sans-serif"> datatype</font> and <font face="sans-serif"> op</font> given for predefined operators  
must be the same on all processes.  
<P> 
Note that it is possible for users to supply different user-defined operations  
to <font face="sans-serif"> MPI_REDUCE</font> in each process.  <font face="sans-serif"> MPI</font> does not define which  
operations are used on which operands in this case.  
User-defined operators may operate on general, derived datatypes.  
In this case, each argument that  
the reduce operation is applied to is one element described by such a datatype,  
which may contain several basic values.  
This is further explained in Section <a href="node115.htm#Node115">User-Defined Reduction Operations 
</a>.  
 
<br> 
<em> Advice to users.</em>  
<P> 
Users should make no assumptions about how <font face="sans-serif"> MPI_REDUCE</font> is  
  implemented.  It is safest to ensure that the same function is passed to  
  <font face="sans-serif"> MPI_REDUCE</font> by each process.  
 (<em> End of advice to users.</em>) <br> 
Overlapping datatypes are permitted in ``send'' buffers.   
Overlapping datatypes in ``receive'' buffers are erroneous  
and may give unpredictable results.  
<P> 
The ``in place'' option  for intracommunicators is specified by passing the  
value   
<font face="sans-serif">  MPI_IN_PLACE</font> to the argument <font face="sans-serif"> sendbuf</font> at the root.  
In such a case, the input data is taken at the root from the receive buffer,  
where it will be replaced by the output data.  
<P> 
If <font face="sans-serif"> comm</font> is an intercommunicator, then the call involves all   
processes in the intercommunicator, but with one group (group A) defining the  
root process.  All processes in the other group (group B) pass the same value  
in argument   
<font face="sans-serif"> root</font>, which is the rank of the root in group A.  The root  
passes the value <font face="sans-serif">  MPI_ROOT</font> in <font face="sans-serif"> root</font>.  
All other processes in group A pass the value <font face="sans-serif">  MPI_PROC_NULL</font> in  
<font face="sans-serif"> root</font>.   
Only send buffer arguments are significant in group B and only receive  
buffer arguments are significant at the root.  
<P> 

<P>
<hr>
<a href="node110.htm#Node110"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node110.htm#Node110"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node112.htm#Node112"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node110.htm#Node110"> Global Reduction Operations</a>
<b>Next: </b><a href="node112.htm#Node112"> Predefined Reduction Operations</a>
<b>Previous: </b><a href="node110.htm#Node110"> Global Reduction Operations</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
