<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font></title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node104">99. Examples using  MPI_GATHER,  MPI_GATHERV</span></h2>
<a href="node103.htm#Node103"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node103.htm#Node103"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node105.htm#Node105"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node103.htm#Node103"> Gather</a>
<b>Next: </b><a href="node105.htm#Node105"> Scatter</a>
<b>Previous: </b><a href="node103.htm#Node103"> Gather</a>
<p>
The examples in this section use intracommunicators.  
<P> 
<br><b> Example</b>  
  
  
Gather 100 <tt>int</tt>s from every process in group to root. See   
Figure <a href="node104.htm#Figure4">4 
</a>.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, *rbuf; 
    ... 
    MPI_Comm_size(comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    MPI_Gather(sendarray, 100, MPI_INT, rbuf, 100, MPI_INT, root, comm); 
</tt></pre> 
  
<P> 
<br><b> Example</b>  
  
  
Previous example modified --- only the root allocates memory for the  
receive buffer.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, myrank, *rbuf; 
    ... 
    MPI_Comm_rank(comm, &amp;myrank); 
    if (myrank == root) { 
       MPI_Comm_size(comm, &amp;gsize); 
       rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    } 
    MPI_Gather(sendarray, 100, MPI_INT, rbuf, 100, MPI_INT, root, comm); 
</tt></pre> 
  
<P> 
  <div style=\"text-align:center\"><P><img width=497 height=203 src="mycoll-fig2.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 4: </b><span id="Figure4">The root process gathers 100 <tt>int</tt>s from 
    each process in the group.</span><P> 
  
    
<br><b> Example</b>  
  
  
Do the same as the previous example, but use a derived datatype.  Note that  
the type cannot be the entire set of <tt>gsize*100 int</tt>s since type matching  
is defined pairwise between the root and each process in the gather.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, *rbuf; 
    MPI_Datatype rtype; 
    ... 
    MPI_Comm_size(comm, &amp;gsize); 
    MPI_Type_contiguous(100, MPI_INT, &amp;rtype); 
    MPI_Type_commit(&amp;rtype); 
    rbuf = (int *)malloc(gsize*100*sizeof(int)); 
    MPI_Gather(sendarray, 100, MPI_INT, rbuf, 1, rtype, root, comm); 
</tt></pre> 
  
<P> 
<br><b> Example</b>  
  
  
Now have each process send 100 <tt>int</tt>s to root, but place each set (of 100)  
<tt>stride int</tt>s apart at receiving end. Use <font face="sans-serif"> MPI_GATHERV</font>  
and the <font face="sans-serif"> displs</font>  
argument to achieve this effect. Assume <img width=58 height=9 src="img98.gif" alt="Image file">
.  
See Figure <a href="node104.htm#Figure5">5 
</a>.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100]; 
    int root, *rbuf, stride; 
    int *displs,i,*rcounts; 
 
    ... 
 
    MPI_Comm_size(comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100; 
    } 
    MPI_Gatherv(sendarray, 100, MPI_INT, rbuf, rcounts, displs, MPI_INT, 
                                                               root, comm); 
</tt></pre> 
Note that the program is erroneous if <i>stride &lt; 100</i>.  
  
<P> 
  <div style=\"text-align:center\"><P><img width=497 height=203 src="mycoll-fig3.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 5: </b><span id="Figure5">The root process gathers 100 
    <tt>int</tt>s from each process
  in the group, each set is placed <tt>stride int</tt>s apart.</span><P> 
  
    
<br><b> Example</b>  
  
  
Same as Example <a href="node104.htm#Node104">Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font> 
</a> on the receiving side, but send the  
100 <tt>int</tt>s from the 0th column of a  
100<i>&#215;</i>150 <tt>int</tt> array, in C.  See Figure <a href="node104.htm#Figure6">6 
</a>.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150]; 
    int root, *rbuf, stride; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts; 
 
    ... 
 
    MPI_Comm_size(comm, &amp;gsize); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100; 
    } 
    /* Create datatype for 1 column of array 
     */ 
    MPI_Type_vector(100, 1, 150, MPI_INT, &amp;stype); 
    MPI_Type_commit(&amp;stype); 
    MPI_Gatherv(sendarray, 1, stype, rbuf, rcounts, displs, MPI_INT, 
                                                             root, comm); 
</tt></pre> 
  
<P> 
  <div style=\"text-align:center\"><P><img width=610 height=257 src="mycoll-fig4.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 6: </b><span id="Figure6">The root process gathers column 
    <tt>0</tt> of a 100$ x $150 
  C array, and each set is placed <tt>stride int</tt>s apart.</span><P> 
  
    
<br><b> Example</b>  
  
  
Process <tt>i</tt> sends <tt>(100-i) int</tt>s from the <tt>i</tt>-th column of a  
100 <i>&#215;</i> 150 <tt>int</tt> array, in C.  It is received into a buffer with stride,  
as in the previous two examples. See Figure <a href="node104.htm#Figure7">7 
</a>.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150],*sptr; 
    int root, *rbuf, stride, myrank; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts; 
 
    ... 
 
    MPI_Comm_size(comm, &amp;gsize); 
    MPI_Comm_rank(comm, &amp;myrank); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100-i;     /* note change from previous example */ 
    } 
    /* Create datatype for the column we are sending 
     */ 
    MPI_Type_vector(100-myrank, 1, 150, MPI_INT, &amp;stype); 
    MPI_Type_commit(&amp;stype); 
    /* sptr is the address of start of "myrank" column 
     */ 
    sptr = &amp;sendarray[0][myrank]; 
    MPI_Gatherv(sptr, 1, stype, rbuf, rcounts, displs, MPI_INT, 
                                                        root, comm); 
</tt></pre> 
Note that a different amount of data is received from each process.  
  
<P> 
  <div style=\"text-align:center\"><P><img width=610 height=257 src="mycoll-fig5.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 7: </b><span id="Figure7">The 
    root process gathers <tt>100-i int</tt>s from
  column <tt>i</tt> of a 100$ x $150
  C array, and each set is placed <tt>stride int</tt>s apart.</span><P> 
  
    
<br><b> Example</b>  
  
  
Same as Example <a href="node104.htm#Node104">Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font> 
</a>, but done in a different way at the sending end.  
We create a datatype that causes the correct striding at the  
sending end so   
that   
we read a column of a C array.  
A similar thing was done in Example <a href="node91.htm#Node91">Examples 
</a>,  
Section <a href="node91.htm#Node91">Examples 
</a>.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize, sendarray[100][150], *sptr;                                      
    int root, *rbuf, stride, myrank;                                            
    MPI_Datatype stype;                                                         
    int *displs, i, *rcounts;                
     
    ... 
 
    MPI_Comm_size(comm, &amp;gsize); 
    MPI_Comm_rank(comm, &amp;myrank); 
    rbuf = (int *)malloc(gsize*stride*sizeof(int)); 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = i*stride; 
        rcounts[i] = 100-i; 
    } 
    /* Create datatype for one int, with extent of entire row 
     */ 
    MPI_Type_create_resized( MPI_INT, 0, 150*sizeof(int), &amp;stype); 
    MPI_Type_commit(&amp;stype); 
    sptr = &amp;sendarray[0][myrank]; 
    MPI_Gatherv(sptr, 100-myrank, stype, rbuf, rcounts, displs, MPI_INT, 
                                                               root, comm); 
</tt></pre> 
  
<P> 
<br><b> Example</b>  
  
  
Same as Example <a href="node104.htm#Node104">Examples using <font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_GATHERV</font> 
</a> at sending side, but  
at receiving side we make the  
stride between received blocks vary from block to block.  
See Figure <a href="node104.htm#Figure8">8 
</a>.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150],*sptr; 
    int root, *rbuf, *stride, myrank, bufsize; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts,offset; 
 
    ... 
 
    MPI_Comm_size(comm, &amp;gsize); 
    MPI_Comm_rank(comm, &amp;myrank); 
 
    stride = (int *)malloc(gsize*sizeof(int)); 
    ... 
    /* stride[i] for i = 0 to gsize-1 is set somehow 
     */ 
 
    /* set up displs and rcounts vectors first 
     */ 
    displs = (int *)malloc(gsize*sizeof(int)); 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    offset = 0; 
    for (i=0; i&lt;gsize; ++i) { 
        displs[i] = offset; 
        offset += stride[i]; 
        rcounts[i] = 100-i; 
    } 
    /* the required buffer size for rbuf is now easily obtained 
     */ 
    bufsize = displs[gsize-1]+rcounts[gsize-1]; 
    rbuf = (int *)malloc(bufsize*sizeof(int)); 
    /* Create datatype for the column we are sending 
     */ 
    MPI_Type_vector(100-myrank, 1, 150, MPI_INT, &amp;stype); 
    MPI_Type_commit(&amp;stype); 
    sptr = &amp;sendarray[0][myrank]; 
    MPI_Gatherv(sptr, 1, stype, rbuf, rcounts, displs, MPI_INT, 
                                                        root, comm); 
</tt></pre> 
  
<P> 
  <div style=\"text-align:center\"><P><img width=610 height=257 src="mycoll-fig6.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 8: </b><span id="Figure8">The root process gathers <tt>100-i int</tt>s from
  column <tt>i</tt> of a 100$ x $150
  C array, and each set is placed <tt>stride[i] int</tt>s apart (a varying
  stride).</span><P> 
  
    
<br><b> Example</b>  
  
  
Process <tt>i</tt> sends <tt>num int</tt>s from the <tt>i</tt>-th column of a  
100 <i>&#215;</i> 150 <tt>int</tt> array, in C.  The complicating factor is that  
the various values of <tt>num</tt> are not known to <tt>root</tt>, so a  
separate gather must first be run to find these out.  The data is  
placed contiguously at the receiving end.  
<P> 
<br> 
<pre><tt>    MPI_Comm comm; 
    int gsize,sendarray[100][150],*sptr; 
    int root, *rbuf, myrank; 
    MPI_Datatype stype; 
    int *displs,i,*rcounts,num; 
 
    ... 
 
    MPI_Comm_size(comm, &amp;gsize); 
    MPI_Comm_rank(comm, &amp;myrank); 
 
    /* First, gather nums to root 
     */ 
    rcounts = (int *)malloc(gsize*sizeof(int)); 
    MPI_Gather(&amp;num, 1, MPI_INT, rcounts, 1, MPI_INT, root, comm); 
    /* root now has correct rcounts, using these we set displs[] so 
     * that data is placed contiguously (or concatenated) at receive end 
     */ 
    displs = (int *)malloc(gsize*sizeof(int)); 
    displs[0] = 0; 
    for (i=1; i&lt;gsize; ++i) { 
        displs[i] = displs[i-1]+rcounts[i-1]; 
    } 
    /* And, create receive buffer 
     */ 
    rbuf = (int *)malloc(gsize*(displs[gsize-1]+rcounts[gsize-1]) 
                                                             *sizeof(int)); 
    /* Create datatype for one int, with extent of entire row 
     */ 
    MPI_Type_create_resized( MPI_INT, 0, 150*sizeof(int), &amp;stype); 
    MPI_Type_commit(&amp;stype); 
    sptr = &amp;sendarray[0][myrank]; 
    MPI_Gatherv(sptr, num, stype, rbuf, rcounts, displs, MPI_INT, 
                                                               root, comm); 
</tt></pre> 
  
<P> 

<P>
<hr>
<a href="node103.htm#Node103"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node103.htm#Node103"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node105.htm#Node105"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node103.htm#Node103"> Gather</a>
<b>Next: </b><a href="node105.htm#Node105"> Scatter</a>
<b>Previous: </b><a href="node103.htm#Node103"> Gather</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
