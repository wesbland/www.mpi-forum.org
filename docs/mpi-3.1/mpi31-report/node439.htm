<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-binding/binding-2.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Temporary Data Movement and Temporary Memory Modification</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node439">372. Temporary Data Movement and Temporary Memory Modification</span></h2>
<a href="node427.htm#Node438"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node407.htm#Node407"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node440.htm#Node440"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node407.htm#Node407"> Fortran Support</a>
<b>Next: </b><a href="node440.htm#Node440"> Permanent Data Movement</a>
<b>Previous: </b><a href="node427.htm#Node438"> The Fortran TARGET Attribute</a>
<p>
  
<P> 
The compiler is allowed to temporarily modify data in memory.  
Normally, this problem may occur only when overlapping communication and computation,  
as in Example <a href="node427.htm#Equation0">0 
</a>, Case (b) on page <a href="node427.htm#Equation0">0 
</a>.  
Example <a href="node427.htm#Equation0">0 
</a>  
also shows a possibility   
that could be problematic.  
<P> 
<br><b> Example</b>  
Overlapping Communication and Computation.  
  
  
<br> 
<pre><tt>USE mpi_f08 
REAL :: buf(100,100) 
CALL MPI_Irecv(buf(1,1:100),...req,...) 
DO j=1,100 
  DO i=2,100 
    buf(i,j)=.... 
  END DO 
END DO 
CALL MPI_Wait(req,...) 
</tt></pre> 
  
<br><b> Example</b>  
The compiler may substitute the nested loops through loop fusion.  
  
  
<br> 
<pre><tt>REAL :: buf(100,100),  buf_1dim(10000) 
EQUIVALENCE (buf(1,1), buf_1dim(1)) 
CALL MPI_Irecv(buf(1,1:100),...req,...) 
tmp(1:100) = buf(1,1:100) 
DO j=1,10000 
  buf_1dim(h)=... 
END DO 
buf(1,1:100) = tmp(1:100) 
CALL MPI_Wait(req,...) 
</tt></pre> 
  
<br><b> Example</b>  
Another optimization is based on the usage of a separate memory storage area, e.g., in a GPU.  
  
  
<br> 
<pre><tt>REAL :: buf(100,100), local_buf(100,100)  
CALL MPI_Irecv(buf(1,1:100),...req,...) 
local_buf = buf  
DO j=1,100 
  DO i=2,100 
    local_buf(i,j)=.... 
  END DO 
END DO 
buf = local_buf ! may overwrite asynchronously received 
                ! data in buf(1,1:100) 
CALL MPI_Wait(req,...) 
</tt></pre> 
  
In the compiler-generated, possible optimization in Example <a href="node427.htm#Equation0">0 
</a>,  
<font face="sans-serif"> buf(100,100)</font> from Example <a href="node427.htm#Equation0">0 
</a>  
is equivalenced with the  1-dimensional array <font face="sans-serif"> buf_1dim(10000)</font>.  
The nonblocking receive may asynchronously receive the data in the boundary <font face="sans-serif"> buf(1,1:100)</font>  
while the fused loop is temporarily using this part of the buffer.  
When the <font face="sans-serif"> tmp</font> data is written back to <font face="sans-serif"> buf</font>,   
the previous data of <font face="sans-serif"> buf(1,1:100)</font> is restored  
and the received data is lost.  
The principle behind this optimization is that   
the receive buffer data <font face="sans-serif"> buf(1,1:100)</font> was temporarily moved to <font face="sans-serif"> tmp</font>.   
<P> 
Example <a href="node427.htm#Equation0">0 
</a> shows  
a second possible optimization.  
The whole array is temporarily moved to <font face="sans-serif"> local_buf</font>.   
<P> 
When storing <font face="sans-serif"> local_buf</font> back to the original location buf,  
then this implies overwriting the section of <font face="sans-serif"> buf</font> that serves  
as a receive buffer in the nonblocking <font face="sans-serif"> MPI</font> call, i.e., this storing  
back of <font face="sans-serif"> local_buf</font> is therefore likely to interfere with  
asynchronously received data in <font face="sans-serif"> buf(1,1:100)</font>.  
<P> 
Note that this problem may also occur:  
<ul> 
 
<li>With the local buffer at the origin process,  
between an RMA communication call and the ensuing synchronization call;  
see Chapter <a href="node258.htm#Node258">One-Sided Communications 
</a>.  
 
<li>With the window buffer at the target process  
between two ensuing RMA synchronization calls.  
 
<li>With the local buffer in <font face="sans-serif"> MPI</font> parallel file I/O split collective operations  
between the <font face="sans-serif"> ..._BEGIN</font> and <font face="sans-serif"> ..._END</font> calls;   
see Section <a href="node330.htm#Node330">Split Collective Data Access Routines 
</a>.  
</ul> 
<br> 
As already mentioned in subsection <em> The Fortran ASYNCHRONOUS attribute</em>   
on page <a href="node427.htm#Node433">The Fortran ASYNCHRONOUS Attribute 
</a> of  
Section <a href="node427.htm#Node427">Problems with Code Movement and Register Optimization 
</a>,  
the <tt> ASYNCHRONOUS</tt> attribute can prevent compiler optimization with temporary data movement,  
but only if the receive buffer and the local references are   
separated into different variables,  
as shown in Example <a href="node427.htm#Equation0">0 
</a>  
and in Example <a href="node427.htm#Equation0">0 
</a>.   
 <P> 
Note also that the methods  
<ul> 
 
<li>calling <font face="sans-serif"> MPI_F_SYNC_REG</font> (or such a user-defined routine),  
 
<li>using module variables and <tt> COMMON</tt> blocks, and  
 
<li>the <tt> TARGET</tt> attribute  
</ul> 
<br> 
cannot be used to prevent such temporary data movement.  
These methods influence compiler optimization when  
library routines are called. They cannot prevent the optimizations  
of the code fragments shown in   
Example <a href="node427.htm#Equation0">0 
</a>   
and <a href="node427.htm#Equation0">0 
</a>.  
<P> 
Note also that compiler optimization with temporary data movement   
should <b> not</b> be prevented by declaring <font face="sans-serif"> buf</font> as <tt> VOLATILE</tt>  
because  
the <tt> VOLATILE</tt> implies that all accesses to any storage unit (word)   
of <font face="sans-serif"> buf</font> must be directly done in the main memory exactly   
in the sequence defined by the application program.   
The <tt> VOLATILE</tt> attribute prevents all register and cache optimizations.  
Therefore, <tt> VOLATILE</tt> may cause a huge performance degradation.  
<P> 
Instead of solving the problem, it is better to <b> prevent</b> the problem:  
when overlapping communication and computation,  
the nonblocking communication (or nonblocking or split collective I/O)   
and the computation should be executed <b> on different variables</b>,  
and the communication should be <em> protected</em> with the  
<tt> ASYNCHRONOUS</tt> attribute.  
In this case, the temporary memory modifications are done  
only on the variables used in the computation and cannot have any  
side effect on the data used in the nonblocking <font face="sans-serif"> MPI</font> operations.  
 
<br> 
<em> Rationale.</em>  
 <P> 
This is a strong restriction for application programs.  
To weaken this restriction, a new or modified asynchronous feature   
in the Fortran language would be necessary:  
an asynchronous attribute that can be used on parts of an array  
and together with asynchronous operations outside the scope of Fortran.  
If such a feature becomes available in a future edition of the Fortran standard,  
then this restriction also may be weakened in a later version   
of the <font face="sans-serif"> MPI</font> standard.  
 (<em> End of rationale.</em>) <br> 
In Example <a href="node427.htm#Equation0">0 
</a>  
(which is a solution for the problem shown in   
Example <a href="node427.htm#Equation0">0 
</a>  
and in Example <a href="node427.htm#Equation0">0 
</a>  
(which is a solution for the problem shown in   
Example <a href="node427.htm#Equation0">0 
</a>),  
the array is split into inner and halo  
part and both disjoint parts are passed to a subroutine <tt> separated_sections</tt>.  
This routine overlaps the receiving of the halo data and the calculations  
on the inner part of the array.  
In a second step, the whole array is used to do  
the calculation on the elements where inner+halo is needed.  
Note that the halo and the inner area are strided arrays.  
Those can be used in non-blocking communication  
only with a TS 29113 based <font face="sans-serif"> MPI</font> library.  
<P> 

<P>
<hr>
<a href="node427.htm#Node438"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node407.htm#Node407"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node440.htm#Node440"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node407.htm#Node407"> Fortran Support</a>
<b>Next: </b><a href="node440.htm#Node440"> Permanent Data Movement</a>
<b>Previous: </b><a href="node427.htm#Node438"> The Fortran TARGET Attribute</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
