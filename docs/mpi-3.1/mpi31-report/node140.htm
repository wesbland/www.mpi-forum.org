<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Correctness</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node140">133. Correctness</span></h1>
<a href="node139.htm#Node139"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="mpi31-report.htm#Node0"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node141.htm#Node141"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="mpi31-report.htm#Node0">Contents</a>
<b>Next: </b><a href="node141.htm#Node141"> Groups, Contexts, Communicators, and Caching</a>
<b>Previous: </b><a href="node139.htm#Node139"> Nonblocking Exclusive Scan</a>
<p>
  
  
<P> 
A correct, portable program must invoke collective communications so  
that deadlock will  
not occur, whether collective communications are synchronizing or not.  
The following examples illustrate dangerous use of collective routines  
on intracommunicators.  
<P> 
<br><b> Example</b>  
  
  
  
<P> 
The following is erroneous.  
<P> 
<br> 
<pre><tt>switch(rank) { 
    case 0: 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Bcast(buf2, count, type, 1, comm); 
        break; 
    case 1: 
        MPI_Bcast(buf2, count, type, 1, comm); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        break; 
} 
</tt></pre> 
We assume that the group of <tt>comm</tt> is {0,1}.  
Two processes execute two broadcast operations in reverse order.  If  
the operation is synchronizing then a deadlock will occur.  
<P> 
Collective  
operations must be executed in the same order at all members of the  
communication group.  
  
<P> 
<br><b> Example</b>  
  
  
  
<P> 
The following is erroneous.  
<P> 
<br> 
<pre><tt>switch(rank) { 
    case 0: 
        MPI_Bcast(buf1, count, type, 0, comm0); 
        MPI_Bcast(buf2, count, type, 2, comm2); 
        break; 
    case 1: 
        MPI_Bcast(buf1, count, type, 1, comm1); 
        MPI_Bcast(buf2, count, type, 0, comm0); 
        break; 
    case 2: 
        MPI_Bcast(buf1, count, type, 2, comm2); 
        MPI_Bcast(buf2, count, type, 1, comm1); 
        break; 
} 
</tt></pre> 
Assume that the group of  
<tt>comm0</tt> is {0,1}, of <tt>comm1</tt> is {1, 2} and of <tt>comm2</tt>  
is {2,0}.  If the broadcast is a synchronizing operation, then there  
is a cyclic dependency: the broadcast in <tt>comm2</tt> completes only  
after the broadcast in <tt>comm0</tt>; the broadcast in <tt>comm0</tt>  
completes only after the broadcast in <tt>comm1</tt>; and the broadcast  
in <tt>comm1</tt> completes only after the broadcast in <tt>comm2</tt>.  
Thus, the code will deadlock.  
<P> 
Collective operations must be executed in an order so that  
no cyclic dependencies occur. Nonblocking collective operations can  
alleviate this issue.  
  
<P> 
<br><b> Example</b>  
  
  
  
<P> 
The following is erroneous.  
<P> 
<br> 
<pre><tt>switch(rank) { 
    case 0: 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        break; 
    case 1: 
        MPI_Recv(buf2, count, type, 0, tag, comm, status); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        break; 
} 
</tt></pre> 
Process zero executes a broadcast, followed by a blocking send operation.  
Process one first executes a blocking receive that matches the send,  
followed by broadcast call that matches the broadcast of process zero.  
This program may deadlock.  The broadcast call on process zero  
<em> may</em> block until process one executes the matching  
broadcast call, so that the  
send is not executed.  Process one will definitely block on the  
receive and so, in this case, never executes the  
broadcast.  
<P> 
The relative order of execution of collective operations and point-to-point  
operations should be such, so that even if the collective  
operations and the point-to-point operations are synchronizing, no  
deadlock will occur.  
  
<P> 
<br><b> Example</b>  
  
  
  
<P> 
An unsafe, non-deterministic program.  
<P> 
<br> 
<pre><tt>switch(rank) { 
    case 0: 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        break; 
    case 1: 
        MPI_Recv(buf2, count, type, MPI_ANY_SOURCE, tag, comm, status); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Recv(buf2, count, type, MPI_ANY_SOURCE, tag, comm, status); 
        break; 
    case 2: 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        break; 
} 
</tt></pre> 
All three processes participate in a broadcast.  Process 0 sends a message to  
process 1 after the broadcast, and process 2 sends a message  
to process 1 before  
the broadcast.  Process 1 receives before and after the broadcast, with a  
wildcard source argument.  
<P> 
Two possible executions of this program, with different matchings  
of sends and receives, are  
illustrated in Figure <a href="node140.htm#Figure12">12 
</a>.  
Note that the second execution has the peculiar effect that a send executed  
after the broadcast is received at another node before the broadcast.  
This example illustrates the fact that one should not rely on  
collective communication functions to have particular synchronization  
effects.  
A program that works correctly only when the first execution occurs  
(only when broadcast is synchronizing) is erroneous.  
<P> 
  
<P> 
  <div style=\"text-align:center\"><P><img width=383 height=394 src="coll-matchings.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 12: </b><span id="Figure12">A race condition causes non-deterministic matching of sends
    and receives.  One cannot rely on synchronization from a broadcast
    to make the program deterministic.</span><P> 
  
    
Finally, in multithreaded implementations, one can have more than one,  
concurrently executing, collective communication call at a process.  In these  
situations, it is the user's responsibility to ensure that  
the same communicator is not used concurrently by two different  
collective communication calls at the same process.  
<P> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
Assume that broadcast is implemented using point-to-point <font face="sans-serif"> MPI</font> communication.  
Suppose the following two rules are followed.  
<ol> 
 
1. All receives specify their source explicitly (no wildcards).  
 
<br> 
2. Each process sends all messages that pertain to one collective call before  
sending any message that pertain to a subsequent collective call.  
</ol> 
Then, messages belonging to successive broadcasts cannot be confused,  
as the order of point-to-point messages is preserved.  
<P> 
It is the implementor's responsibility to  
ensure that point-to-point messages are not confused with collective  
messages.  One way to accomplish this is, whenever a communicator is  
created, to also create a ``hidden communicator'' for collective communication.  
One could achieve a similar  
effect more cheaply, for example, by using a hidden  
tag or context bit to indicate  
whether the communicator is used for point-to-point or collective  
communication.  
 (<em> End of advice to implementors.</em>) <br> 
<br><b> Example</b>  
  
  
  
  
  
<P> 
Blocking and nonblocking collective operations can be interleaved, i.e.,  
a blocking collective operation can be posted even if there is a  
nonblocking collective operation outstanding.  
<P> 
<br> 
<pre><tt>MPI_Request req; 
 
MPI_Ibarrier(comm, &amp;req); 
MPI_Bcast(buf1, count, type, 0, comm); 
MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
</tt></pre> 
Each process starts a nonblocking barrier operation, participates in a  
blocking broadcast and then waits until every other process started the  
barrier operation. This effectively turns the broadcast into a  
synchronizing broadcast with possible communication/communication  
overlap (<font face="sans-serif"> MPI_Bcast</font> is allowed, but not required to  
synchronize).   
  
<P> 
<br><b> Example</b>  
  
  
  
  
  
<P> 
The starting order of collective operations on a particular communicator  
defines their matching. The following example shows an erroneous  
matching of different collective operations on the same communicator.  
<P> 
<br> 
<pre><tt>MPI_Request req; 
switch(rank) { 
    case 0: 
        /* erroneous matching */ 
        MPI_Ibarrier(comm, &amp;req); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
        break; 
    case 1: 
        /* erroneous matching */ 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Ibarrier(comm, &amp;req); 
        MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
        break; 
} 
</tt></pre> 
This ordering would match <font face="sans-serif"> MPI_Ibarrier</font> on rank 0 with  
<font face="sans-serif"> MPI_Bcast</font> on rank 1 which is erroneous and the program behavior is  
undefined. However, if such an order is required, the user must create  
different duplicate communicators and perform the operations on them.  
If started with two processes, the following program would be correct:  
<P> 
<br> 
<pre><tt>MPI_Request req; 
MPI_Comm dupcomm; 
MPI_Comm_dup(comm, &amp;dupcomm); 
switch(rank) { 
    case 0: 
        MPI_Ibarrier(comm, &amp;req); 
        MPI_Bcast(buf1, count, type, 0, dupcomm); 
        MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
        break; 
    case 1: 
        MPI_Bcast(buf1, count, type, 0, dupcomm); 
        MPI_Ibarrier(comm, &amp;req); 
        MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
        break; 
} 
</tt></pre> 
 
<br> 
<em> Advice to users.</em>  
<P> 
The use of different communicators offers some flexibility regarding the  
matching of nonblocking collective operations. In this sense,  
communicators could be used as an equivalent to tags. However,  
communicator construction might induce overheads so that this should be  
used carefully.  
 (<em> End of advice to users.</em>) <br> 
  
<P> 
<br><b> Example</b>  
  
  
  
  
  
  
<P> 
Nonblocking collective operations can rely on the same progression rules  
as nonblocking point-to-point messages. Thus, if started with two  
processes, the following program is a valid <font face="sans-serif"> MPI</font> program and is  
guaranteed to terminate:  
<P> 
<br> 
<pre><tt>MPI_Request req; 
 
switch(rank) { 
    case 0: 
      MPI_Ibarrier(comm, &amp;req); 
      MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
      MPI_Send(buf, count, dtype, 1, tag, comm); 
      break; 
    case 1: 
      MPI_Ibarrier(comm, &amp;req); 
      MPI_Recv(buf, count, dtype, 0, tag, comm, MPI_STATUS_IGNORE); 
      MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
      break; 
} 
</tt></pre> 
The <font face="sans-serif"> MPI</font> library must progress the barrier in the <font face="sans-serif"> MPI_Recv</font>  
call. Thus, the <font face="sans-serif"> MPI_Wait</font> call in rank 0 will eventually  
complete, which enables the matching <font face="sans-serif"> MPI_Send</font> so all calls  
eventually return.                     
<P> 
  
<P> 
<br><b> Example</b>  
  
  
  
  
  
<P> 
Blocking and nonblocking collective operations do not match. The  
following example is erroneous.  
<P> 
<br> 
<pre><tt>MPI_Request req; 
 
switch(rank) { 
    case 0: 
      /* erroneous false matching of Alltoall and Ialltoall */ 
      MPI_Ialltoall(sbuf, scnt, stype, rbuf, rcnt, rtype, comm, &amp;req); 
      MPI_Wait(&amp;req, MPI_STATUS_IGNORE); 
      break; 
    case 1: 
      /* erroneous false matching of Alltoall and Ialltoall */ 
      MPI_Alltoall(sbuf, scnt, stype, rbuf, rcnt, rtype, comm); 
      break; 
} 
</tt></pre> 
  
<P> 
<br><b> Example</b>  
  
  
  
  
  
  
  
<P> 
Collective and point-to-point requests can be mixed in functions that  
enable multiple completions. If started with two processes, the  
following program is valid.  
<P> 
<br> 
<pre><tt>MPI_Request reqs[2]; 
 
switch(rank) { 
    case 0: 
      MPI_Ibarrier(comm, &amp;reqs[0]); 
      MPI_Send(buf, count, dtype, 1, tag, comm); 
      MPI_Wait(&amp;reqs[0], MPI_STATUS_IGNORE); 
      break; 
    case 1: 
      MPI_Irecv(buf, count, dtype, 0, tag, comm, &amp;reqs[0]); 
      MPI_Ibarrier(comm, &amp;reqs[1]); 
      MPI_Waitall(2, reqs, MPI_STATUSES_IGNORE); 
      break; 
} 
</tt></pre> 
The <font face="sans-serif"> MPI_Waitall</font> call returns only after the barrier and the receive completed.  
<P> 
  
<P> 
<br><b> Example</b>  
  
  
  
  
<P> 
Multiple nonblocking collective operations can be outstanding on a  
single communicator and match in order.   
<P> 
<br> 
<pre><tt>MPI_Request reqs[3]; 
 
compute(buf1); 
MPI_Ibcast(buf1, count, type, 0, comm, &amp;reqs[0]); 
compute(buf2); 
MPI_Ibcast(buf2, count, type, 0, comm, &amp;reqs[1]); 
compute(buf3); 
MPI_Ibcast(buf3, count, type, 0, comm, &amp;reqs[2]); 
MPI_Waitall(3, reqs, MPI_STATUSES_IGNORE); 
</tt></pre> 
 
<br> 
<em> Advice to users.</em>  
<P> 
Pipelining and double-buffering techniques can efficiently be used to  
overlap computation and communication. However, having too many  
outstanding requests might have a negative impact on performance.  
 (<em> End of advice to users.</em>) <br> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
The use of pipelining may generate many outstanding requests. A  
high-quality hardware-supported implementation with limited resources  
should be able to fall back to a software implementation if its  
resources are exhausted. In this way, the implementation could limit the  
number of outstanding requests only by the available memory.  
 (<em> End of advice to implementors.</em>) <br> 
  
<P> 
<br><b> Example</b>  
  
  
  
  
<P> 
Nonblocking collective operations can also be used to enable  
simultaneous collective operations on multiple overlapping  
communicators (see Figure <a href="node140.htm#Figure13">13 
</a>). The following example is started with three processes and  
three communicators. The first communicator <tt>comm1</tt> includes ranks 0 and  
1, <tt>comm2</tt> includes ranks 1 and 2, and <tt>comm3</tt> spans ranks 0 and 2. It is not  
possible to perform a blocking collective operation on all communicators  
because there exists no deadlock-free order to invoke them. However,  
nonblocking collective operations can easily be used to achieve this  
task.  
<P> 
<br> 
<pre><tt>MPI_Request reqs[2]; 
 
switch(rank) { 
    case 0: 
      MPI_Iallreduce(sbuf1, rbuf1, count, dtype, MPI_SUM, comm1, &amp;reqs[0]); 
      MPI_Iallreduce(sbuf3, rbuf3, count, dtype, MPI_SUM, comm3, &amp;reqs[1]); 
      break; 
    case 1: 
      MPI_Iallreduce(sbuf1, rbuf1, count, dtype, MPI_SUM, comm1, &amp;reqs[0]); 
      MPI_Iallreduce(sbuf2, rbuf2, count, dtype, MPI_SUM, comm2, &amp;reqs[1]); 
      break; 
    case 2: 
      MPI_Iallreduce(sbuf2, rbuf2, count, dtype, MPI_SUM, comm2, &amp;reqs[0]); 
      MPI_Iallreduce(sbuf3, rbuf3, count, dtype, MPI_SUM, comm3, &amp;reqs[1]); 
      break; 
} 
MPI_Waitall(2, reqs, MPI_STATUSES_IGNORE); 
</tt></pre> 
 
<br> 
<em> Advice to users.</em>  
<P> 
This method can be useful if overlapping neighboring regions (halo  
or ghost zones) are used in collective operations. The sequence of the  
two calls in each process is irrelevant because the two nonblocking  
operations are performed on different communicators.  
 (<em> End of advice to users.</em>) <br> 
  <div style=\"text-align:center\"><P><img width=174 height=126 src="overlap_comms.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 13: </b><span id="Figure13">Example with overlapping
  communicators.</span><P> 
  
    
  
<P> 
<br><b> Example</b>  
  
  
  
<P> 
The progress of multiple outstanding nonblocking collective operations  
is completely independent.  
<P> 
<br> 
<pre><tt>MPI_Request reqs[2]; 
 
compute(buf1); 
MPI_Ibcast(buf1, count, type, 0, comm, &amp;reqs[0]); 
compute(buf2); 
MPI_Ibcast(buf2, count, type, 0, comm, &amp;reqs[1]); 
MPI_Wait(&amp;reqs[1], MPI_STATUS_IGNORE); 
/* nothing is known about the status of the first bcast here */ 
MPI_Wait(&amp;reqs[0], MPI_STATUS_IGNORE); 
</tt></pre> 
Finishing the second <font face="sans-serif"> MPI_IBCAST</font> is completely independent of  
the first one. This means that it is not guaranteed that the first  
broadcast operation is finished or even started after the second one is  
completed via <tt>reqs[1]</tt>.  
<P> 
  
<P> 
  

<P>
<hr>
<a href="node139.htm#Node139"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="mpi31-report.htm#Node0"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node141.htm#Node141"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="mpi31-report.htm#Node0">Contents</a>
<b>Next: </b><a href="node141.htm#Node141"> Groups, Contexts, Communicators, and Caching</a>
<b>Previous: </b><a href="node139.htm#Node139"> Nonblocking Exclusive Scan</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
