<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-io/io-2.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Data Access with Shared File Pointers</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node326">296. Data Access with Shared File Pointers</span></h2>
<a href="node325.htm#Node325"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node318.htm#Node318"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node326.htm#Node327"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node318.htm#Node318"> Data Access</a>
<b>Next: </b><a href="node326.htm#Node327"> Noncollective Operations</a>
<b>Previous: </b><a href="node325.htm#Node325"> Data Access with Individual File Pointers</a>
<p>
  
  
  
<P> 
<font face="sans-serif"> MPI</font> maintains exactly one shared file pointer  
per collective <font face="sans-serif"> MPI_FILE_OPEN</font>  
(shared among processes in the communicator group).  
The current value of this pointer implicitly specifies  
the offset in the data access routines described in this section.  
These routines only use and update the shared file pointer  
maintained by <font face="sans-serif"> MPI</font>.  
The individual file pointers are not used nor updated.  
<P> 
The shared file pointer routines  
have the same semantics as the data access with explicit offset routines  
described in Section <a href="node324.htm#Node324">Data Access with Explicit Offsets 
</a>,  
with the following modifications:  
<ul> 
 
<li>the <font face="sans-serif"> offset</font> is defined to be the current value  
        of the <font face="sans-serif"> MPI</font>-maintained shared file pointer,  
 
<li>the effect of multiple calls to shared file pointer routines  
        is defined to behave as if the calls were serialized, and  
 
<li>the use of shared file pointer routines is erroneous unless  
        all processes use the same file view.  
</ul> 
<br> 
For the noncollective shared file pointer routines,  
the  
serialization ordering is not deterministic.  
The user needs to use other synchronization means  
to enforce a specific order.  
<P> 
After a shared file pointer operation is initiated,  
the shared file pointer is updated to point to the next  
etype after the last one   
that will be accessed.  
The file pointer is updated relative to the current view of the file.  
<P> 
<ul> 
</ul> 

<P>
<hr>
<a href="node325.htm#Node325"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node318.htm#Node318"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node326.htm#Node327"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node318.htm#Node318"> Data Access</a>
<b>Next: </b><a href="node326.htm#Node327"> Noncollective Operations</a>
<b>Previous: </b><a href="node325.htm#Node325"> Data Access with Individual File Pointers</a>
<p>
<hr><h3><span id="Node327">296.1. Noncollective Operations</span></h3>
<a href="node326.htm#Node326"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node326.htm#Node326"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node326.htm#Node328"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<b>Next: </b><a href="node326.htm#Node328"> Collective Operations</a>
<b>Previous: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<p>
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_READ_SHARED(fh, buf, count, datatype, status)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> OUT buf</TD><TD>initial address of buffer (choice)</TD></TR>  
<TR><TD> IN count</TD><TD>number of elements in buffer (integer)</TD></TR>  
<TR><TD> IN datatype</TD><TD>datatype of each buffer element (handle)</TD></TR>  
<TR><TD> OUT status</TD><TD>status object (Status)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_File_read_shared(MPI_File fh, void *buf, int count, MPI_Datatype datatype, MPI_Status *status) <br></tt>  
 <tt> MPI_File_read_shared(fh, buf, count, datatype, status, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>TYPE(*), DIMENSION(..) :: buf <br>INTEGER, INTENT(IN) :: count <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Status) :: status <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_READ_SHARED(FH, BUF, COUNT, DATATYPE, STATUS, IERROR) <br> &lt;type&gt; BUF(*) <br>INTEGER FH, COUNT, DATATYPE, STATUS(MPI_STATUS_SIZE), IERROR  <br></tt>  
  
  
<P> 
<font face="sans-serif"> MPI_FILE_READ_SHARED</font> reads a file  
using the shared file pointer.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_WRITE_SHARED(fh, buf, count, datatype, status)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> IN buf</TD><TD>initial address of buffer (choice)</TD></TR>  
<TR><TD> IN count</TD><TD>number of elements in buffer (integer)</TD></TR>  
<TR><TD> IN datatype</TD><TD>datatype of each buffer element (handle)</TD></TR>  
<TR><TD> OUT status</TD><TD>status object (Status)</TD></TR>  
</TABLE>  
 <P> 
 <tt> int MPI_File_write_shared(MPI_File fh, const void *buf, int count, MPI_Datatype datatype, MPI_Status *status) <br></tt>  
 <tt> MPI_File_write_shared(fh, buf, count, datatype, status, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>TYPE(*), DIMENSION(..), INTENT(IN) :: buf <br>INTEGER, INTENT(IN) :: count <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Status) :: status <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_WRITE_SHARED(FH, BUF, COUNT, DATATYPE, STATUS, IERROR) <br> &lt;type&gt; BUF(*) <br>INTEGER FH, COUNT, DATATYPE, STATUS(MPI_STATUS_SIZE), IERROR <br></tt>  
  
  
<P> 
<font face="sans-serif"> MPI_FILE_WRITE_SHARED</font> writes a file  
using the shared file pointer.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_IREAD_SHARED(fh, buf, count, datatype, request)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> OUT buf</TD><TD>initial address of buffer (choice)</TD></TR>  
<TR><TD> IN count</TD><TD>number of elements in buffer (integer)</TD></TR>  
<TR><TD> IN datatype</TD><TD>datatype of each buffer element (handle)</TD></TR>  
<TR><TD> OUT request</TD><TD>request object (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_File_iread_shared(MPI_File fh, void *buf, int count, MPI_Datatype datatype, MPI_Request *request) <br></tt>  
 <tt> MPI_File_iread_shared(fh, buf, count, datatype, request, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>TYPE(*), DIMENSION(..), ASYNCHRONOUS :: buf <br>INTEGER, INTENT(IN) :: count <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Request), INTENT(OUT) :: request <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_IREAD_SHARED(FH, BUF, COUNT, DATATYPE, REQUEST, IERROR) <br> &lt;type&gt; BUF(*) <br>INTEGER FH, COUNT, DATATYPE, REQUEST, IERROR <br></tt>  
  
<P> 
<font face="sans-serif"> MPI_FILE_IREAD_SHARED</font> is a nonblocking version  
of the <font face="sans-serif"> MPI_FILE_READ_SHARED</font> interface.  
 <P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_IWRITE_SHARED(fh, buf, count, datatype, request)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> IN buf</TD><TD>initial address of buffer (choice)</TD></TR>  
<TR><TD> IN count</TD><TD>number of elements in buffer (integer)</TD></TR>  
<TR><TD> IN datatype</TD><TD>datatype of each buffer element (handle)</TD></TR>  
<TR><TD> OUT request</TD><TD>request object (handle)</TD></TR>  
</TABLE>  
 <P> 
 <tt> int MPI_File_iwrite_shared(MPI_File fh, const void *buf, int count, MPI_Datatype datatype, MPI_Request *request) <br></tt>  
 <tt> MPI_File_iwrite_shared(fh, buf, count, datatype, request, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: buf <br>INTEGER, INTENT(IN) :: count <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Request), INTENT(OUT) :: request <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_IWRITE_SHARED(FH, BUF, COUNT, DATATYPE, REQUEST, IERROR) <br> &lt;type&gt; BUF(*) <br>INTEGER FH, COUNT, DATATYPE, REQUEST, IERROR <br></tt>  
  
<P> 
<font face="sans-serif"> MPI_FILE_IWRITE_SHARED</font> is a nonblocking version  
of the <font face="sans-serif"> MPI_FILE_WRITE_SHARED</font> interface.  
<P> 

<P>
<hr>
<a href="node326.htm#Node326"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node326.htm#Node326"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node326.htm#Node328"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<b>Next: </b><a href="node326.htm#Node328"> Collective Operations</a>
<b>Previous: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<p>
<hr><h3><span id="Node328">296.2. Collective Operations</span></h3>
<a href="node326.htm#Node327"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node326.htm#Node326"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node326.htm#Node329"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<b>Next: </b><a href="node326.htm#Node329"> Seek</a>
<b>Previous: </b><a href="node326.htm#Node327"> Noncollective Operations</a>
<p>
  
  
  
<P> 
The semantics of a collective access using a shared file pointer is  
that the accesses to the file will be  
in the order determined by the ranks of the processes  
within the group.  
For each process, the location in the file at which data is accessed is the   
position at which the shared file pointer would be after all processes whose   
ranks within the group less than that of this process had accessed their data.  
In addition, in order to prevent subsequent  
shared offset accesses by the same processes from interfering  
with this collective   
access, the call might return only after all the processes   
within the group have initiated their   
accesses.  
When the call returns, the shared file pointer points  
to the next etype accessible,  
according to the file view used by all processes,  
after the last etype requested.  
<P> 
 
<br> 
<em> Advice to users.</em>  
<P> 
There may be some programs in which all processes in the  
group  
need to access the  
file using the shared file pointer, but the program may not <em> require</em>  
that data be accessed in order of process rank.  
In such programs, using the shared ordered routines  
(e.g., <font face="sans-serif"> MPI_FILE_WRITE_ORDERED</font>  
rather than <font face="sans-serif"> MPI_FILE_WRITE_SHARED</font>)  
may enable an implementation to optimize access, improving performance.  
 (<em> End of advice to users.</em>) <br> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
Accesses to the data requested by all processes do not have to be serialized.   
Once all processes have issued their requests, locations within the file for  
all accesses can be computed, and accesses can proceed independently from each  
other, possibly in parallel.  
 (<em> End of advice to implementors.</em>) <br> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_READ_ORDERED(fh, buf, count, datatype, status)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> OUT buf</TD><TD>initial address of buffer (choice)</TD></TR>  
<TR><TD> IN count</TD><TD>number of elements in buffer (integer)</TD></TR>  
<TR><TD> IN datatype</TD><TD>datatype of each buffer element (handle)</TD></TR>  
<TR><TD> OUT status</TD><TD>status object (Status)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_File_read_ordered(MPI_File fh, void *buf, int count, MPI_Datatype datatype, MPI_Status *status) <br></tt>  
 <tt> MPI_File_read_ordered(fh, buf, count, datatype, status, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>TYPE(*), DIMENSION(..) :: buf <br>INTEGER, INTENT(IN) :: count <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Status) :: status <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_READ_ORDERED(FH, BUF, COUNT, DATATYPE, STATUS, IERROR) <br> &lt;type&gt; BUF(*) <br>INTEGER FH, COUNT, DATATYPE, STATUS(MPI_STATUS_SIZE), IERROR <br></tt>  
  
  
<P> 
<font face="sans-serif"> MPI_FILE_READ_ORDERED</font> is a collective version of the  
<font face="sans-serif"> MPI_FILE_READ_SHARED</font> interface.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_WRITE_ORDERED(fh, buf, count, datatype, status)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> IN buf</TD><TD>initial address of buffer (choice)</TD></TR>  
<TR><TD> IN count</TD><TD>number of elements in buffer (integer)</TD></TR>  
<TR><TD> IN datatype</TD><TD>datatype of each buffer element (handle)</TD></TR>  
<TR><TD> OUT status</TD><TD>status object (Status)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_File_write_ordered(MPI_File fh, const void *buf, int count, MPI_Datatype datatype, MPI_Status *status) <br></tt>  
 <tt> MPI_File_write_ordered(fh, buf, count, datatype, status, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>TYPE(*), DIMENSION(..), INTENT(IN) :: buf <br>INTEGER, INTENT(IN) :: count <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Status) :: status <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_WRITE_ORDERED(FH, BUF, COUNT, DATATYPE, STATUS, IERROR) <br> &lt;type&gt; BUF(*) <br>INTEGER FH, COUNT, DATATYPE, STATUS(MPI_STATUS_SIZE), IERROR <br></tt>  
  
  
<P> 
<font face="sans-serif"> MPI_FILE_WRITE_ORDERED</font> is a collective version of the  
<font face="sans-serif"> MPI_FILE_WRITE_SHARED</font> interface.  
<P> 

<P>
<hr>
<a href="node326.htm#Node327"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node326.htm#Node326"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node326.htm#Node329"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<b>Next: </b><a href="node326.htm#Node329"> Seek</a>
<b>Previous: </b><a href="node326.htm#Node327"> Noncollective Operations</a>
<p>
<hr><h3><span id="Node329">296.3. Seek</span></h3>
<a href="node326.htm#Node328"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node326.htm#Node326"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node330.htm#Node330"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<b>Next: </b><a href="node330.htm#Node330"> Split Collective Data Access Routines</a>
<b>Previous: </b><a href="node326.htm#Node328"> Collective Operations</a>
<p>
  
  
<P> 
If <font face="sans-serif">  MPI_MODE_SEQUENTIAL</font> mode was specified when the file was opened,  
it is erroneous to call the following two routines  
(<font face="sans-serif"> MPI_FILE_SEEK_SHARED</font> and <font face="sans-serif"> MPI_FILE_GET_POSITION_SHARED</font>).  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_SEEK_SHARED(fh, offset, whence)</TD></TR>  
<TR><TD> INOUT fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> IN offset</TD><TD>file offset (integer)</TD></TR>  
<TR><TD> IN whence</TD><TD>update mode (state)</TD></TR>  
</TABLE>  
 <P> 
 <tt> int MPI_File_seek_shared(MPI_File fh, MPI_Offset offset, int whence) <br></tt>  
 <tt> MPI_File_seek_shared(fh, offset, whence, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>INTEGER(KIND=MPI_OFFSET_KIND), INTENT(IN) :: offset <br>INTEGER, INTENT(IN) :: whence <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_SEEK_SHARED(FH, OFFSET, WHENCE, IERROR)<br> INTEGER FH, WHENCE, IERROR <br>INTEGER(KIND=MPI_OFFSET_KIND) OFFSET <br></tt>  
  
 <P> 
<font face="sans-serif"> MPI_FILE_SEEK_SHARED</font> updates the shared file pointer according to   
<font face="sans-serif"> whence</font>,  
which has  
the following possible values:  
<ul> 
 
<li><font face="sans-serif">  MPI_SEEK_SET</font>:  
        the pointer is set to <font face="sans-serif"> offset</font>  
 
<li><font face="sans-serif">  MPI_SEEK_CUR</font>:  
        the pointer is set to the current pointer position plus <font face="sans-serif"> offset</font>  
 
<li><font face="sans-serif">  MPI_SEEK_END</font>:  
        the pointer is set to the end of   
file  
plus <font face="sans-serif"> offset</font>  
</ul> 
<br> 
<font face="sans-serif"> MPI_FILE_SEEK_SHARED</font> is collective;  
all the processes in the communicator group associated with the file  
handle <font face="sans-serif"> fh</font> must call <font face="sans-serif"> MPI_FILE_SEEK_SHARED</font> with the same  
values for  
<font face="sans-serif"> offset</font> and <font face="sans-serif"> whence</font>.  
 <P> 
The <font face="sans-serif"> offset</font> can be negative, which allows seeking backwards.  
It is erroneous to seek to a negative position in the view.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_FILE_GET_POSITION_SHARED(fh, offset)</TD></TR>  
<TR><TD> IN fh</TD><TD>file handle (handle)</TD></TR>  
<TR><TD> OUT offset</TD><TD>offset of shared pointer (integer)</TD></TR>  
</TABLE>  
 <P> 
 <tt> int MPI_File_get_position_shared(MPI_File fh, MPI_Offset *offset) <br></tt>  
 <tt> MPI_File_get_position_shared(fh, offset, ierror) <br> TYPE(MPI_File), INTENT(IN) :: fh <br>INTEGER(KIND=MPI_OFFSET_KIND), INTENT(OUT) :: offset <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_FILE_GET_POSITION_SHARED(FH, OFFSET, IERROR)<br> INTEGER FH, IERROR <br>INTEGER(KIND=MPI_OFFSET_KIND) OFFSET <br></tt>  
  
 <P> 
<font face="sans-serif"> MPI_FILE_GET_POSITION_SHARED</font> returns, in <font face="sans-serif"> offset</font>,  
the current position of the shared file pointer in etype units  
relative to the current  
view.  
<P> 
 
<br> 
<em> Advice to users.</em>  
<P> 
The <font face="sans-serif"> offset</font> can be used in a future call  
to <font face="sans-serif"> MPI_FILE_SEEK_SHARED</font>  
using <font face="sans-serif">  whence = MPI_SEEK_SET</font> to return to the current position.  
To set the displacement to the current file pointer position,  
first convert <font face="sans-serif"> offset</font> into an absolute byte position using  
<font face="sans-serif"> MPI_FILE_GET_BYTE_OFFSET</font>,  
then call <font face="sans-serif"> MPI_FILE_SET_VIEW</font> with the resulting  
displacement.  
 (<em> End of advice to users.</em>) <br> 

<P>
<hr>
<a href="node326.htm#Node328"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node326.htm#Node326"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node330.htm#Node330"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node326.htm#Node326"> Data Access with Shared File Pointers</a>
<b>Next: </b><a href="node330.htm#Node330"> Split Collective Data Access Routines</a>
<b>Previous: </b><a href="node326.htm#Node328"> Collective Operations</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
