<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title><font face="sans-serif"> MPI_REDUCE_SCATTER</font></title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node121">115.  MPI_REDUCE_SCATTER</span></h2>
<a href="node120.htm#Node120"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node119.htm#Node119"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node122.htm#Node122"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node119.htm#Node119"> Reduce-Scatter</a>
<b>Next: </b><a href="node122.htm#Node122"> Scan</a>
<b>Previous: </b><a href="node120.htm#Node120"> <font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK</font></a>
<p>
  
<font face="sans-serif"> MPI_REDUCE_SCATTER</font> extends the functionality of <font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK</font>  
such that the scattered blocks can vary in size.  
Block sizes are determined by the <font face="sans-serif"> recvcounts</font> array,  
such that the <font face="sans-serif"> i</font>-th block contains <font face="sans-serif"> recvcounts[i]</font> elements.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_REDUCE_SCATTER( sendbuf, recvbuf, recvcounts,  
datatype, op, comm)</TD></TR>  
<TR><TD> IN sendbuf</TD><TD> starting address of send buffer (choice)</TD></TR>  
<TR><TD> OUT recvbuf</TD><TD> starting address of receive buffer (choice)</TD></TR>  
<TR><TD> IN recvcounts</TD><TD>non-negative  
integer array (of length group size) specifying the  
number of elements of the result distributed to each process.  
</TD></TR>  
<TR><TD> IN datatype</TD><TD> data type of elements of send and receive buffers (handle)</TD></TR>  
<TR><TD> IN op</TD><TD> operation (handle)</TD></TR>  
<TR><TD> IN comm</TD><TD> communicator (handle)</TD></TR>  
</TABLE>  
<P> 
 <tt> int MPI_Reduce_scatter(const void* sendbuf, void* recvbuf, const int recvcounts[], MPI_Datatype datatype, MPI_Op op, MPI_Comm comm) <br></tt>  
<P> 
 <tt> MPI_Reduce_scatter(sendbuf, recvbuf, recvcounts, datatype, op, comm, ierror) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: sendbuf <br>TYPE(*), DIMENSION(..) :: recvbuf <br>INTEGER, INTENT(IN) :: recvcounts(*) <br>TYPE(MPI_Datatype), INTENT(IN) :: datatype <br>TYPE(MPI_Op), INTENT(IN) :: op <br>TYPE(MPI_Comm), INTENT(IN) :: comm <br>INTEGER, OPTIONAL, INTENT(OUT) :: ierror <br></tt>  
 <tt> MPI_REDUCE_SCATTER(SENDBUF, RECVBUF, RECVCOUNTS, DATATYPE, OP, COMM, IERROR) <br> &lt;type&gt; SENDBUF(*), RECVBUF(*) <br>INTEGER RECVCOUNTS(*), DATATYPE, OP, COMM, IERROR <br></tt>  
<P> 
  
<P> 
If <font face="sans-serif"> comm</font> is an intracommunicator,  
<font face="sans-serif"> MPI_REDUCE_SCATTER</font> first  
performs a global, element-wise reduction on vectors of   
<img width=125 height=13 src="img128.gif" alt="Image file">
 elements in the send  
buffers defined by <font face="sans-serif"> sendbuf</font>, <font face="sans-serif"> count</font> and  
<font face="sans-serif"> datatype</font>, using the operation <font face="sans-serif"> op</font>, where <font face="sans-serif"> n</font> is the number of  
processes in the group of <font face="sans-serif"> comm</font>. The routine is called by all group  
members using the same arguments for <font face="sans-serif"> recvcounts</font>,  
<font face="sans-serif"> datatype</font>, <font face="sans-serif"> op</font> and <font face="sans-serif"> comm</font>.  
The resulting vector is treated as n consecutive blocks where the number  
of elements of the <font face="sans-serif"> i</font>-th block is <font face="sans-serif"> recvcounts[i]</font>. The blocks are scattered  
to the processes of the group. The <font face="sans-serif"> i</font>-th block   
is sent to process <font face="sans-serif"> i</font> and stored in the  
receive buffer defined by <font face="sans-serif"> recvbuf, recvcounts[i]</font> and  
<font face="sans-serif"> datatype</font>.  
<P> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
The <font face="sans-serif"> MPI_REDUCE_SCATTER</font>  
routine is functionally equivalent to:  
an  
<font face="sans-serif"> MPI_REDUCE</font>  
collective  
operation  
with <font face="sans-serif"> count</font> equal to  
the sum of <font face="sans-serif"> recvcounts[i]</font> followed by  
<font face="sans-serif"> MPI_SCATTERV</font> with <font face="sans-serif"> sendcounts</font> equal to <font face="sans-serif"> recvcounts</font>.  
However, a direct implementation may run faster.  
 (<em> End of advice to implementors.</em>) <br> 
The ``in place'' option  for intracommunicators is specified by passing  
<font face="sans-serif">  MPI_IN_PLACE</font> in   
the <font face="sans-serif"> sendbuf</font> argument.  
In this case, the input data is taken from the receive  
buffer. It is not required to specify the ``in  
place'' option on all processes, since the processes for which  
<font face="sans-serif"> recvcounts[i]</font><font face="sans-serif">  ==0</font> may not have allocated a receive buffer.  
<P> 
If <font face="sans-serif"> comm</font> is an intercommunicator, then the result of the reduction  
of the data provided by processes in one  
group (group A) is scattered among processes in  
the other group (group B), and vice  
versa.  Within each group, all processes provide the same  
<font face="sans-serif"> recvcounts</font> argument, and provide input vectors of <img width=125 height=13 src="img129.gif" alt="Image file">
  
elements stored in the send buffers, where <font face="sans-serif"> n</font> is the size of the group.  
The resulting vector from the other group is scattered in blocks of  
<font face="sans-serif"> recvcounts[i]</font> elements among the processes in the group. The number of  
elements <font face="sans-serif"> count</font> must be the same for the two groups.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
The last restriction is needed so that the length of the send  
buffer can be determined by the sum of the local <font face="sans-serif"> recvcounts</font> entries.  
Otherwise, a communication is needed to figure out how many elements  
are reduced.  
 (<em> End of rationale.</em>) <br> 

<P>
<hr>
<a href="node120.htm#Node120"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node119.htm#Node119"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node122.htm#Node122"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node119.htm#Node119"> Reduce-Scatter</a>
<b>Next: </b><a href="node122.htm#Node122"> Scan</a>
<b>Previous: </b><a href="node120.htm#Node120"> <font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK</font></a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
