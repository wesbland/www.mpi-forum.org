<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Examples for Communication Calls</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node271">250. Examples for Communication Calls</span></h2>
<a href="node270.htm#Node270"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node268.htm#Node268"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node272.htm#Node272"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node268.htm#Node268"> Communication Calls</a>
<b>Next: </b><a href="node272.htm#Node272"> Accumulate Functions</a>
<b>Previous: </b><a href="node270.htm#Node270"> Get</a>
<p>
  
<P> 
These examples show the use of the <font face="sans-serif"> MPI_GET</font> function.  
  As all <font face="sans-serif"> MPI</font> <font face="sans-serif"> RMA</font> communication functions are nonblocking, they  
  must be completed.  In the following, this is accomplished with the  
  routine <font face="sans-serif"> MPI_WIN_FENCE</font>, introduced in  
  Section <a href="node279.htm#Node279">Synchronization Calls 
</a>.  
<P> 
<br><b> Example</b>  
  
We show how to implement the generic indirect assignment  
<tt>A = B(map)</tt>, where <tt>A</tt>,  
<tt>B</tt>, and   
<tt>map</tt> have the same  
distribution, and <tt>map</tt> is a permutation.  To simplify, we assume  
a block distribution with equal size   
blocks.  
<P> 
<br> 
<pre><tt>SUBROUTINE MAPVALS(A, B, map, m, comm, p) 
USE MPI 
INTEGER m, map(m), comm, p 
REAL A(m), B(m) 
 
INTEGER otype(p), oindex(m),   &amp; ! used to construct origin datatypes  
     ttype(p), tindex(m),      &amp; ! used to construct target datatypes 
     count(p), total(p),       &amp; 
     disp_int, win, ierr 
INTEGER (KIND=MPI_ADDRESS_KIND) lowerbound, size, realextent, disp_aint 
 
! This part does the work that depends on the locations of B. 
! Can be reused while this does not change 
 
CALL MPI_TYPE_GET_EXTENT(MPI_REAL, lowerbound, realextent, ierr) 
disp_int = realextent 
size = m * realextent 
CALL MPI_WIN_CREATE(B, size, disp_int, MPI_INFO_NULL,   &amp; 
                     comm, win, ierr) 
 
! This part does the work that depends on the value of map and 
! the locations of the arrays. 
! Can be reused while these do not change 
 
! Compute number of entries to be received from each process 
 
DO i=1,p 
  count(i) = 0 
END DO 
DO i=1,m 
  j = map(i)/m+1 
  count(j) = count(j)+1 
END DO 
 
total(1) = 0 
DO i=2,p 
  total(i) = total(i-1) + count(i-1) 
END DO 
 
DO i=1,p 
  count(i) = 0 
END DO 
 
! compute origin and target indices of entries. 
! entry i at current process is received from location 
! k at process (j-1), where map(i) = (j-1)*m + (k-1), 
! j = 1..p and k = 1..m 
 
DO i=1,m 
  j = map(i)/m+1 
  k = MOD(map(i),m)+1 
  count(j) = count(j)+1 
  oindex(total(j) + count(j)) = i 
  tindex(total(j) + count(j)) = k 
END DO 
 
! create origin and target datatypes for each get operation 
DO i=1,p 
  CALL MPI_TYPE_CREATE_INDEXED_BLOCK(count(i), 1, &amp; 
                                     oindex(total(i)+1:total(i)+count(i)), &amp; 
                                     MPI_REAL, otype(i), ierr) 
  CALL MPI_TYPE_COMMIT(otype(i), ierr) 
  CALL MPI_TYPE_CREATE_INDEXED_BLOCK(count(i), 1, &amp; 
                                     tindex(total(i)+1:total(i)+count(i)), &amp; 
                                     MPI_REAL, ttype(i), ierr) 
  CALL MPI_TYPE_COMMIT(ttype(i), ierr) 
END DO 
 
! this part does the assignment itself 
CALL MPI_WIN_FENCE(0, win, ierr) 
disp_aint = 0 
DO i=1,p 
  CALL MPI_GET(A, 1, otype(i), i-1, disp_aint, 1, ttype(i), win, ierr) 
END DO 
CALL MPI_WIN_FENCE(0, win, ierr) 
 
CALL MPI_WIN_FREE(win, ierr) 
DO i=1,p 
  CALL MPI_TYPE_FREE(otype(i), ierr) 
  CALL MPI_TYPE_FREE(ttype(i), ierr) 
END DO 
RETURN 
END 
</tt></pre> 
  
<P> 
<br><b> Example</b>  
  
  
A simpler version can be written that does not require that a  
datatype be built for the target buffer.  But, one then needs a  
separate get call for each entry,  
as illustrated below.  This code is much simpler, but usually much less   
efficient, for large arrays.  
<P> 
<br> 
<pre><tt>SUBROUTINE MAPVALS(A, B, map, m, comm, p) 
USE MPI 
INTEGER m, map(m), comm, p 
REAL A(m), B(m) 
INTEGER disp_int, win, ierr 
INTEGER (KIND=MPI_ADDRESS_KIND) lowerbound, size, realextent, disp_aint 
 
CALL MPI_TYPE_GET_EXTENT(MPI_REAL, lowerbound, realextent, ierr) 
disp_int = realextent 
size = m * realextent 
CALL MPI_WIN_CREATE(B, size, disp_int, MPI_INFO_NULL,  &amp; 
                    comm, win, ierr) 
 
CALL MPI_WIN_FENCE(0, win, ierr) 
DO i=1,m 
  j = map(i)/m 
  disp_aint = MOD(map(i),m) 
  CALL MPI_GET(A(i), 1, MPI_REAL, j, disp_aint, 1, MPI_REAL, win, ierr) 
END DO 
CALL MPI_WIN_FENCE(0, win, ierr) 
CALL MPI_WIN_FREE(win, ierr) 
RETURN 
END 
</tt></pre> 
  
<P> 

<P>
<hr>
<a href="node270.htm#Node270"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node268.htm#Node268"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node272.htm#Node272"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node268.htm#Node268"> Communication Calls</a>
<b>Next: </b><a href="node272.htm#Node272"> Accumulate Functions</a>
<b>Previous: </b><a href="node270.htm#Node270"> Get</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
