<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2.tex -->
<!-- with the command
tohtml -default -basedef mpi3defs.txt -numbers -indexname myindex -dosnl -htables -quietlatex -allgif -endpage mpi3-forum-tail.htm -Wnoredef -o mpi31-report.tex mpi-report.tex 
-->
<title>Synchronization Calls</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node279">254. Synchronization Calls</span></h1>
<a href="node278.htm#Node278"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="mpi31-report.htm#Node0"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node280.htm#Node280"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="mpi31-report.htm#Node0">Contents</a>
<b>Next: </b><a href="node280.htm#Node280"> Fence</a>
<b>Previous: </b><a href="node278.htm#Node278"> Memory Model</a>
<p>
  
  
  
<P> 
<font face="sans-serif"> RMA</font> communications fall in two categories:  
<ul> 
 
<li><b> active target communication</b>, where data is moved from the memory of one  
process to the memory of another, and both are explicitly involved in the  
communication.  This communication pattern is similar to message  
passing, except that all the data transfer arguments are provided by  
one process, and the second process only participates in the synchronization.  
 
<li><b> passive target communication</b>, where data is moved from the memory of one  
process to the memory of another, and only the origin process is  
explicitly involved  
in  
the transfer.  Thus, two origin processes may communicate by accessing  
the same location in a target window.  The process that owns the  
target window may be distinct from the two communicating processes,   
in which case it does not participate explicitly in the communication.  
This communication  
paradigm is closest to a shared memory model, where shared data can be  
accessed by all processes, irrespective   
of location.  
</ul> 
<br> 
<font face="sans-serif"> RMA</font> communication calls with argument <font face="sans-serif"> win</font> must occur at a process  
only within an <b> access epoch</b> for <font face="sans-serif"> win</font>.  Such an epoch  
starts with an <font face="sans-serif"> RMA</font> synchronization  
call on <font face="sans-serif"> win</font>; it proceeds with zero or more <font face="sans-serif"> RMA</font>  
communication calls (e.g., <font face="sans-serif"> MPI_PUT</font>, <font face="sans-serif"> MPI_GET</font> or  
<font face="sans-serif"> MPI_ACCUMULATE</font>) on <font face="sans-serif"> win</font>; it completes with another  
synchronization call on   
<font face="sans-serif"> win</font>. This allows users to amortize one synchronization with multiple data  
transfers and provide implementors  
more flexibility in the implementation of <font face="sans-serif"> RMA</font> operations.  
<P> 
Distinct access epochs for <font face="sans-serif"> win</font> at the same process must be disjoint.  
On the other hand, epochs pertaining to different <font face="sans-serif"> win</font> arguments  
may  
overlap.  Local operations or other <font face="sans-serif"> MPI</font> calls may also occur during  
an epoch.  
<P> 
In active target communication, a target window can be accessed by <font face="sans-serif"> RMA</font>  
operations only within an <b> exposure epoch</b>. Such an epoch is  
started and completed by <font face="sans-serif"> RMA</font> synchronization calls executed by the  
target process.  Distinct exposure epochs at a process  
on the same window must be disjoint, but such an exposure epoch  
may overlap with exposure epochs on other windows or  
with access epochs for the same or other <font face="sans-serif"> win</font> arguments.  
There is a one-to-one matching between access epochs at origin  
processes and exposure epochs on target processes:  
<font face="sans-serif"> RMA</font> operations issued by an origin process for a target window will  
access that  
target window during the same exposure epoch if and only if they were  
issued during the same access   
epoch.  
<P> 
In passive target communication the target  
process does not execute <font face="sans-serif"> RMA</font> synchronization calls, and there is no  
concept of an exposure   
epoch.   
<P> 
<font face="sans-serif"> MPI</font> provides three synchronization mechanisms:  
<ol> 
 
1. The  
<font face="sans-serif"> MPI_WIN_FENCE</font> collective synchronization call supports a  
simple synchronization pattern that is often used in parallel  
computations: namely a loosely-synchronous model, where global  
computation phases alternate with global communication phases.  
This mechanism is most useful for loosely synchronous algorithms where  
the graph of communicating processes changes very frequently, or where  
each process communicates with many   
others.  
<P> 
This call is used for active target communication.  An access epoch at an  
origin process or an exposure epoch at a target process are started  
and completed by calls to <font face="sans-serif"> MPI_WIN_FENCE</font>.  A process can  
access windows at all processes in the group of <font face="sans-serif"> win</font> during  
such an access  
epoch, and the local window can be accessed by all processes in the  
group of <font face="sans-serif"> win</font> during such an exposure epoch.  
 
<br> 
2. The four functions <font face="sans-serif"> MPI_WIN_START</font>,   
<font face="sans-serif"> MPI_WIN_COMPLETE</font>,  
<font face="sans-serif"> MPI_WIN_POST</font>, and  
<font face="sans-serif"> MPI_WIN_WAIT</font>   
can be used to restrict synchronization to the minimum: only  
pairs of communicating processes synchronize, and they do so only when  
a synchronization is needed to order correctly <font face="sans-serif"> RMA</font> accesses to a  
window with respect to local accesses to that same window.  
This mechanism may be   
more efficient when each process communicates with few (logical)  
neighbors, and the communication graph is fixed or changes  
infrequently.  
<P> 
These calls are used for   
active target communication.  An access epoch is started  
at the origin process  
by a call to <font face="sans-serif"> MPI_WIN_START</font> and is terminated by a call to  
<font face="sans-serif"> MPI_WIN_COMPLETE</font>.  The start call has a group argument  
that specifies the group of target processes for that  
epoch. An exposure epoch is started at the  
target process by a call  
to <font face="sans-serif"> MPI_WIN_POST</font> and is completed by a call to  
<font face="sans-serif"> MPI_WIN_WAIT</font>.  The post call has a group argument that  
specifies the set of origin processes for that   
epoch.  
 
<br> 
3. Finally, shared lock  
access is provided by the functions <font face="sans-serif"> MPI_WIN_LOCK</font>,  
<font face="sans-serif"> MPI_WIN_LOCK_ALL</font>, <font face="sans-serif"> MPI_WIN_UNLOCK</font>, and  
<font face="sans-serif"> MPI_WIN_UNLOCK_ALL</font>.  <font face="sans-serif"> MPI_WIN_LOCK</font> and  
<font face="sans-serif"> MPI_WIN_UNLOCK</font> also provide exclusive lock capability.   
Lock synchronization  
is useful for <font face="sans-serif"> MPI</font> applications that  
emulate a shared memory model via <font face="sans-serif"> MPI</font> calls; e.g., in a ``billboard''  
model, where processes can, at random times, access or update  
different parts of the billboard.  
<P> 
These four calls provide passive target communication.  An access epoch is  
started by a call to <font face="sans-serif"> MPI_WIN_LOCK</font> or  
<font face="sans-serif"> MPI_WIN_LOCK_ALL</font> and terminated by a call to  
<font face="sans-serif"> MPI_WIN_UNLOCK</font> or <font face="sans-serif"> MPI_WIN_UNLOCK_ALL</font>, respectively.    
</ol> 
Figure <a href="node279.htm#Figure21">21 
</a> illustrates the general synchronization  
pattern for active target   
communication.  
<div style=\"text-align:center\"><P><img width=412 height=664 src="sync15.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 21: </b><span id="Figure21">Active target communication.  Dashed arrows represent
synchronizations (ordering of events).</span><P> 
  
  
The synchronization between  <tt> post</tt> and  
<tt> start</tt> ensures that the put call of the origin process does  
not start  
until the target process exposes the window (with the <tt> post</tt> call);  
the target process will  
expose the window only after preceding local accesses to the window  
have completed.  
The synchronization between <tt> complete</tt> and <tt> wait</tt>  
ensures that the put call of the origin process completes  
before the window is unexposed (with the <tt> wait</tt> call).  
The target process will execute  
following local accesses to the target window only after the <tt> wait</tt>  
returned.  
<P> 
Figure <a href="node279.htm#Figure21">21 
</a> shows operations occurring in the natural  
temporal order implied by the synchronizations: the <tt> post</tt>  
occurs before the matching <tt> start</tt>, and <tt> complete</tt> occurs before  
the  
matching <tt> wait</tt>.  However, such <b> strong synchronization</b> is more  
than  
needed for correct ordering of window accesses.  The semantics of  
<font face="sans-serif"> MPI</font> calls allow <b> weak synchronization</b>,   
as illustrated in Figure <a href="node279.htm#Figure22">22 
</a>.  
<div style=\"text-align:center\"><P><img width=389 height=546 src="sync14.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 22: </b><span id="Figure22">Active target communication, with weak synchronization.  Dashed
arrows represent synchronizations (ordering of events)</span><P> 
  
  
The access to the target window  is delayed until the window is  
exposed, after the <tt> post</tt>. However the <tt> start</tt>  
may complete earlier; the <tt> put</tt> and   
<tt> complete</tt> may also terminate earlier, if put data is  
buffered by the implementation.  
The synchronization calls order correctly window accesses, but do not  
necessarily synchronize other operations.  This weaker synchronization  
semantic allows for more efficient   
implementations.  
<P> 
Figure <a href="node279.htm#Figure23">23 
</a> illustrates the general synchronization  
pattern for passive target   
communication.  
The first origin process communicates data to the second  
origin process, through the memory of the target process; the target  
process is not explicitly involved in the   
communication.  
<div style=\"text-align:center\"><P><img width=603 height=715 src="sync23.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 23: </b><span id="Figure23">Passive target communication.  Dashed arrows represent
synchronizations (ordering of events).</span><P> 
  
  
The  
<tt> lock</tt> and <tt> unlock</tt> calls ensure that the two <font face="sans-serif"> RMA</font>  
accesses do not occur concurrently. However, they do <em> not</em> ensure  
that the <tt> put</tt> by origin 1 will precede the <tt> get</tt> by   
origin 2.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
<font face="sans-serif"> RMA</font> does not define fine-grained mutexes in memory (only logical  
coarse-grained process locks). <font face="sans-serif"> MPI</font> provides the primitives (compare  
and swap, accumulate, send/receive, etc.) needed to implement high-level  
synchronization operations.  
 (<em> End of rationale.</em>) <br> 
<ul> 
</ul> 

<P>
<hr>
<a href="node278.htm#Node278"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="mpi31-report.htm#Node0"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node280.htm#Node280"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="mpi31-report.htm#Node0">Contents</a>
<b>Next: </b><a href="node280.htm#Node280"> Fence</a>
<b>Previous: </b><a href="node278.htm#Node278"> Memory Model</a>
<p>
<HR>
Return to <A HREF="node523.htm">MPI-3.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-3.1 of June 4, 2015<BR>
HTML Generated on June 4, 2015
</FONT>
</body>
</html>
